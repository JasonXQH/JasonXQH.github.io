<!DOCTYPE html>
<html lang="en">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"jasonxqh.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="离散概率part3Outline Expectation 期望的两种计算方法期望的定义：所有的随机变量可能的取值乘以对应的概率，然后再求和。 但是我们要知道E(X)是一个加权的平均数。E(X)不再是一个随机变量了 定义一个偏差(deviation)为随机变量减去期望 基于定义求 比如说我抛硬币100次，我们要看正面朝上的次数为多少，向上的概率为p 那么如果按照普通的算法，那么就要对每一个出现情况的">
<meta property="og:type" content="article">
<meta property="og:title" content="离散概率part3">
<meta property="og:url" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/index.html">
<meta property="og:site_name" content="Jason‘s Blog">
<meta property="og:description" content="离散概率part3Outline Expectation 期望的两种计算方法期望的定义：所有的随机变量可能的取值乘以对应的概率，然后再求和。 但是我们要知道E(X)是一个加权的平均数。E(X)不再是一个随机变量了 定义一个偏差(deviation)为随机变量减去期望 基于定义求 比如说我抛硬币100次，我们要看正面朝上的次数为多少，向上的概率为p 那么如果按照普通的算法，那么就要对每一个出现情况的">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/1.png">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/2.png">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/3.png">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/4.png">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/5.png">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/6.png">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/7.png">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/8.png">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/9.png">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/10.png">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/30.png">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/11.png">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/12.png">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/13.png">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/14.png">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/15.png">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/16.png">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/1.jpg">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/17.png">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/2.jpg">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/18.png">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/19.png">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/20.png">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/21.png">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/24.png">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/23.png">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/25.png">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/26.png">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/28.png">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/29.png">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/31.png">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/3.jpg">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/32.png">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/33.png">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/34.png">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/35.png">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/36.png">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/37.png">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/38.png">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/39.png">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/40.png">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/41.png">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/42.png">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/43.png">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/49.png">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/44.png">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/0.jpg">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/50.png">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/45.png">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/46.png">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/47.png">
<meta property="og:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/48.png">
<meta property="article:published_time" content="2020-05-22T03:21:05.000Z">
<meta property="article:modified_time" content="2020-09-06T04:19:06.000Z">
<meta property="article:author" content="Jason">
<meta property="article:tag" content="discrete mathematics">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/1.png">

<link rel="canonical" href="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>离散概率part3 | Jason‘s Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Jason‘s Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://jasonxqh.github.io/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Jason">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jason‘s Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          离散概率part3
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-05-22 11:21:05" itemprop="dateCreated datePublished" datetime="2020-05-22T11:21:05+08:00">2020-05-22</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-09-06 12:19:06" itemprop="dateModified" datetime="2020-09-06T12:19:06+08:00">2020-09-06</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="离散概率part3"><a href="#离散概率part3" class="headerlink" title="离散概率part3"></a>离散概率part3</h1><h2 id="Outline"><a href="#Outline" class="headerlink" title="Outline"></a>Outline</h2><p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/1.png" style="zoom:80%;"></p>
<h2 id="Expectation"><a href="#Expectation" class="headerlink" title="Expectation"></a>Expectation</h2><p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/2.png" style="zoom:80%;"></p>
<h3 id="期望的两种计算方法"><a href="#期望的两种计算方法" class="headerlink" title="期望的两种计算方法"></a>期望的两种计算方法</h3><p>期望的定义：所有的随机变量可能的取值乘以对应的概率，然后再求和。</p>
<p>但是我们要知道E(X)是一个加权的平均数。E(X)不再是一个随机变量了</p>
<p>定义一个偏差(deviation)为随机变量减去期望</p>
<h4 id="基于定义求"><a href="#基于定义求" class="headerlink" title="基于定义求"></a>基于定义求</h4><p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/3.png" style="zoom:80%;"></p>
<p>比如说我抛硬币100次，我们要看正面朝上的次数为多少，向上的概率为p</p>
<p>那么如果按照普通的算法，那么就要对每一个出现情况的概率进行求和，也就是对$2^{100}$个样本求和，那么我们如果对随机变量X求和，（X对应硬币朝上的个数）那么只要对0-100求和就行了。</p>
<p>只要知道分布，就知道期望了</p>
<h4 id="基于随机变量来求"><a href="#基于随机变量来求" class="headerlink" title="基于随机变量来求"></a>基于随机变量来求</h4><p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/4.png" style="zoom:80%;"></p>
<h3 id="例题"><a href="#例题" class="headerlink" title="例题"></a>例题</h3><h4 id="例一"><a href="#例一" class="headerlink" title="例一"></a>例一</h4><p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/5.png" style="zoom:80%;"></p>
<p>我们不仅仅可以算X的期望，也可以计算$X^2$ ,$X^3$的期望，直接用它的函数值带入即可 </p>
<h4 id="例二"><a href="#例二" class="headerlink" title="例二"></a>例二</h4><p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/6.png" style="zoom:80%;"></p>
<h3 id="贝努力分布和几何分布的期望"><a href="#贝努力分布和几何分布的期望" class="headerlink" title="贝努力分布和几何分布的期望"></a>贝努力分布和几何分布的期望</h3><h4 id="贝努力分布"><a href="#贝努力分布" class="headerlink" title="贝努力分布"></a>贝努力分布</h4><p>The expected number of successes when n mutually independent Bernoulli trials are performed, where p is the probability of success on each trial, is <strong>np</strong>.</p>
<p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/7.png" style="zoom:80%;"></p>
<h4 id="几何分布"><a href="#几何分布" class="headerlink" title="几何分布"></a>几何分布</h4><p>The expected number of successes when a r.v. X follows a Geometric distribution is 1 p , where p is the probability of success on each trial.</p>
<p>也就是说第一次成功之前，已经做了多少次</p>
<p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/8.png" style="zoom:80%;"></p>
<h2 id="Linearity-of-expectations"><a href="#Linearity-of-expectations" class="headerlink" title="Linearity of expectations"></a>Linearity of expectations</h2><h3 id="期望的线性性质"><a href="#期望的线性性质" class="headerlink" title="期望的线性性质"></a>期望的线性性质</h3><p>1.和的期望等于期望的和</p>
<p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/9.png" style="zoom:150%;"></p>
<p>2.具有线性运算的性质$E(aX_i+b) = aE(X_i)+b$</p>
<p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/10.png" style="zoom:170%;"></p>
<ol>
<li>线性可加性 ,比如</li>
</ol>
<p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/30.png" style="zoom:170%;"></p>
<h3 id="证明："><a href="#证明：" class="headerlink" title="证明："></a>证明：</h3><p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/11.png" style="zoom:80%;"></p>
<h3 id="贝努力实验的期望"><a href="#贝努力实验的期望" class="headerlink" title="贝努力实验的期望"></a>贝努力实验的期望</h3><p>根据期望的线性性，我们很容易就能算出n次贝努力实验的期望了</p>
<p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/12.png" style="zoom:60%;"></p>
<h3 id="例子："><a href="#例子：" class="headerlink" title="例子："></a>例子：</h3><h4 id="例一："><a href="#例一：" class="headerlink" title="例一："></a>例一：</h4><p>A new employee checks the hats of n people at a restaurant, forgetting to put claim check numbers on the hats. When customers return for their hats, the checker gives them back hats chosen at random from the remaining hats. What is the expected number of hats that are returned correctly?</p>
<p>就是说这个服务员是新来的，没有给顾客发取帽码，所以只能随便拿(帽子都一样)，问这个期望拿对的概率是多少</p>
<p>如果我们按照定义来算，那么就要算出来没有人能拿对的概率，一个人拿对的概率，。。。全部拿对的概率，也就是说先找分布，再计算期望。但这显然太麻烦了</p>
<p>所以 这样考虑：0个人拿对，那么n个人错排；1个人拿对，n-1个人错排。所以我们用期望的性质来做。我们来看第i个人是否拿对，拿对的概率 1/n,拿错的概率 n-1/n。求和即可</p>
<p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/13.png" style="zoom:80%;"></p>
<h4 id="例二："><a href="#例二：" class="headerlink" title="例二："></a>例二：</h4><p>计算一个数列中逆排列的数字对，逆排列就是说a&lt;b 但是a在b的后面，如图中所举例</p>
<p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/14.png" style="zoom:80%;"></p>
<p>那么对于一个数字对来说 $I_{i,j}$来说，他要么是逆序列，要么不是。所以说他的期望是 1/2</p>
<p>然后我们只要计算有几个这样的数字对即可，C(2,n) = n(n-1)/2 相乘得答案</p>
<h3 id="独立随机变量的期望"><a href="#独立随机变量的期望" class="headerlink" title="独立随机变量的期望"></a>独立随机变量的期望</h3><p>当X，Y相互独立的时候，期望的乘积就等于乘积的期望</p>
<p>$E(XY) = E(X)E(Y)$</p>
<p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/15.png" style="zoom:80%;"></p>
<h2 id="Average-case-computational-complexity"><a href="#Average-case-computational-complexity" class="headerlink" title="Average-case computational complexity"></a>Average-case computational complexity</h2><p>通过期望来计算平均的算法复杂度，也就是一般情况下大概是什么复杂度</p>
<p>那么他的期望就是输入一个数字的 概率，乘以其对应的比较次数</p>
<p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/16.png" style="zoom:100%;"></p>
<p>Finding the average-case computational complexity of an algorithm is usually much more diffcult than nding its worst-case computational complexity, and often involves the use of sophisticated methods.</p>
<h3 id="线性搜索算法"><a href="#线性搜索算法" class="headerlink" title="线性搜索算法"></a>线性搜索算法</h3><p><strong>Question:</strong> What is the average-case computational complexity of the linear search algorithm if the probability that x is in the list is p and it is equally likely that x is any of the n elements in the list?</p>
<p><strong>Solution:</strong> 也就是说，x和$a_i$ 去比较，那么需要比较 i 是否小于等于n 和 比较 x是否等于 $a_i$也就是说要比较两次，那么如果最终找到了，然后还要跳出循环，判断i是不是小于等于n，所以一共比较2i+1次</p>
<p>那么如果没找到，那么就是比较2n+2次</p>
<p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/1.jpg" style="zoom:80%;"></p>
<p>The probability that x equals ai ,<br>the i-th element in the list, is p/n, and the probability that x is not in the list is q = 1 - p.</p>
<p>令p指的是这个x落在这n个数中的概率。因为每个数可能是均匀分布在这个序列里面的，所以如果有5个数字，那么概率就是p/5,如果有n个数字，那么就是p/n.</p>
<p>那么我们就可以进行计算了</p>
<p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/17.png" style="zoom:60%;"></p>
<h3 id="插入排序算法"><a href="#插入排序算法" class="headerlink" title="插入排序算法"></a>插入排序算法</h3><p><strong>Question：</strong>What is the average number of comparisons used by the insertion sort to sort n distinct elements?</p>
<p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/2.jpg" style="zoom:60%;"></p>
<p><strong>Solution:</strong>We first suppose that X is the r.v. equal to # comparisons used by the insertion sort to sort a list a1, a2, … ; an of n distinct elements.<br>Then E(X) is the average number of comparisons used.</p>
<p>记作$a_k$为前j个元素中最大的元素,$1\leq k \leq j$</p>
<p>所以关键是看k落在第几个位置。如果k在第一个，那么每一个后来的都比 $a_k$ 小</p>
<p>如果是落在最后一个，那么每个都要比较一下</p>
<p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/18.png" style="zoom:70%;"></p>
<h2 id="方差"><a href="#方差" class="headerlink" title="方差"></a>方差</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>方差可以对定义求和，也可以对随机变量来求</p>
<p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/19.png" style="zoom:70%;"></p>
<h3 id="定理"><a href="#定理" class="headerlink" title="定理"></a>定理</h3><p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/20.png" style="zoom:70%;"></p>
<p>也可以这样来计算：X偏离均值的平方的期望</p>
<p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/21.png" style="zoom:70%;"></p>
<h3 id="各种分布的方差"><a href="#各种分布的方差" class="headerlink" title="各种分布的方差"></a>各种分布的方差</h3><h4 id="例一：贝努力实验的方差"><a href="#例一：贝努力实验的方差" class="headerlink" title="例一：贝努力实验的方差"></a>例一：贝努力实验的方差</h4><p><strong>Question:</strong> A coin is  flipped one time. Let $\Omega$ be the sample space of the possible outcomes, and let X be r.v. that assigns to an outcome # heads in this outcome. What is the variance of X if it is a biased coin with P({H}) = p?  </p>
<p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/24.png" style="zoom:90%;"></p>
<h4 id="例二：-二项分布的方差"><a href="#例二：-二项分布的方差" class="headerlink" title="例二： 二项分布的方差"></a>例二： 二项分布的方差</h4><p><strong>Question:</strong> Let r.v. X be the number of successes of n mutually independent Bernoulli trials, where p is the probability of success on each trial. What is the variance of X?</p>
<p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/23.png" style="zoom:90%;"></p>
<h4 id="例三：几何分布的方差"><a href="#例三：几何分布的方差" class="headerlink" title="例三：几何分布的方差"></a>例三：几何分布的方差</h4><p><strong>Question: </strong>Let r.v. X be the rst occurrence of success requires n mutually independent Bernoulli trials, where p is the probability of success on each trial. What is the variance of X?</p>
<p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/25.png" style="zoom:90%;"></p>
<p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/26.png" style="zoom:90%;"></p>
<h3 id="方差的非线性性"><a href="#方差的非线性性" class="headerlink" title="方差的非线性性"></a>方差的非线性性</h3><p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/28.png" style="zoom:90%;"></p>
<p>这说明什么道理呢？</p>
<p>说明对一列数进行平移，那么不会影响我的方差，如果对一列数进行拉伸a倍，那么方差就会扩大a的平方倍。</p>
<p>如果对一列数进行压缩，那么方差就会压缩的更厉害。</p>
<h3 id="Bienayme‘s-formula"><a href="#Bienayme‘s-formula" class="headerlink" title="Bienayme‘s formula"></a>Bienayme‘s formula</h3><p>当随机变量<strong>两两之间相互独立</strong>的时候，那么这时候方差的和就等于和的方差</p>
<p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/29.png" style="zoom:90%;"></p>
<h3 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h3><p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/31.png" style="zoom:90%;"></p>
<p>因为$X_i$ 是独立的而且是同分布的随机变量（独立且分布函数相同），这意味着所有的$X_i$的期望是一样的，$X_i$ 的方差也是一样的（比如抛筛子两次，第一次X1和第二次X2）</p>
<p>这个例子告诉我们什么呢？</p>
<p>原来$X_i$的方差是 $\sigma^2$ 那么 现在我们把 所有的$X_i $加起来后取平均数的话 方差会随着数量的增加而逐渐趋向于0</p>
<p>$\lim\limits_{n-&gt;\infty}V(\overline{X_n}) = 0$</p>
<p>也就是说，随着随机变量数量的增加，当n越来越大的时候，最后随机变量会变成一个常数。均值的方差会变得很小很小。</p>
<p>举个例子，我们 利用标记重补法来估算池塘中的鱼，那么一次的话可能说明不了问题，那么我们可以做很多次，然后取一平均值，这时候根据上面的公式，方差（波动）不会很大</p>
<h2 id="Tail-probability尾概率"><a href="#Tail-probability尾概率" class="headerlink" title="Tail probability尾概率"></a>Tail probability尾概率</h2><p>比如果我抛出100次硬币，那么50是它的期望</p>
<p>那么我们如果想要计算$P_n(X&gt;90)$和$P_n(X&lt;10)$ 这两个概率，就是一种尾概率</p>
<p>如果我们硬算，会变得很麻烦，很难计算 $\sum<em>{k=91}^{100}C</em>{100}^k \frac{1}{2}^{100} $</p>
<p>所以我们给他一个上界，估计估计，但是我又让这个上界越接近越好。那么怎么计算一下呢？</p>
<p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/3.jpg" style="zoom:90%;"></p>
<p>像上面这张图片，我们可以把这个看作抛了n次的模型，我们看到最后的概率接近0.5。这是因为Xi = {0,1},那么</p>
<p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/32.png" style="zoom:150%;"></p>
<p>当n越大的时候，方差越小，方差越小，波动就越小。</p>
<p>回到上面的问题 $P<em>n(X&gt;90) = P_n(\sum</em>{1}^nX_i&gt;=90)$</p>
<h3 id="Markovs-inequality"><a href="#Markovs-inequality" class="headerlink" title="Markovs inequality"></a>Markovs inequality</h3><h4 id="Theorem"><a href="#Theorem" class="headerlink" title="Theorem"></a>Theorem</h4><p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/33.png" style="zoom:90%;"></p>
<p>也就是说刚才的尾概率可以通过这样的方法来进行计算</p>
<h4 id="Proof"><a href="#Proof" class="headerlink" title="Proof"></a>Proof</h4><p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/34.png" style="zoom:90%;"></p>
<p>就比如说，我投n次币  ，我计算正面朝上的概率大于0.9 </p>
<p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/35.png" style="zoom:150%;"></p>
<p>但这个上界有问题，放的太宽了。n=100,n=1000，n越来越大的时候，概率应该越来越稳定才对，所以偏离p=0.5的概率会越来越小，但是根据马尔可夫不等式，却发现上界始终不变。所以不科学，不太准确</p>
<h3 id="Chebyshevs-inequality"><a href="#Chebyshevs-inequality" class="headerlink" title="Chebyshevs inequality"></a>Chebyshevs inequality</h3><p>所以我们来看切比雪夫不等式。马尔科夫不等式用的是期望，切比雪夫不等式用的是方差。这个方差会随着n的增加而慢慢减小，但是期望是不会随着n的变化而变化的，所以这就导致了两者的区别，一个和n无关，一个和n有关</p>
<h4 id="Theorem-1"><a href="#Theorem-1" class="headerlink" title="Theorem"></a>Theorem</h4><p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/36.png" style="zoom:150%;"></p>
<h4 id="Proof-1"><a href="#Proof-1" class="headerlink" title="Proof"></a>Proof</h4><p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/37.png" style="zoom:150%;"></p>
<p>马尔可夫不等式，是单尾的，只能计算&gt; 某个值的上界，但是切比雪夫不等式是双尾的，</p>
<p>双尾的肯定要比单尾的概率要大，所以我们通过这个关系把单尾转化成双尾再进行计算。</p>
<p>通过下面两个例子计算出的结果，要比马尔可夫不等式更科学，当n趋向于无穷的时候，尾概率会趋向于0，符合上面方差趋向于0的判断。</p>
<p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/38.png" style="zoom:150%;"></p>
<p>比如说我要计算刚才抛硬币的例子 </p>
<p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/39.png" style="zoom:100%;"></p>
<p>但是这样虽然符合观测结果，但也不能说切比雪夫不等式给出的上界，就是一个很好的上界，所以我们需要</p>
<p>Chernoff bound</p>
<h3 id="Chernoff-bound"><a href="#Chernoff-bound" class="headerlink" title="Chernoff bound"></a>Chernoff bound</h3><h4 id="Theorem-2"><a href="#Theorem-2" class="headerlink" title="Theorem"></a>Theorem</h4><p> <img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/40.png" style="zoom:80%;"></p>
<h4 id="Proof-2"><a href="#Proof-2" class="headerlink" title="Proof"></a>Proof</h4><p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/41.png" style="zoom:82%;"></p>
<p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/42.png" style="zoom:80%;"></p>
<p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/43.png" style="zoom:80%;"></p>
<h4 id="Theorem-for-upper-tail"><a href="#Theorem-for-upper-tail" class="headerlink" title="Theorem for upper tail"></a>Theorem for upper tail</h4><p>这是另外一个尾巴</p>
<p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/49.png" style="zoom:80%;"></p>
<p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/44.png" style="zoom:80%;"></p>
<p>关于这里分母为什么是4，我一直没搞明白</p>
<p>其实这里分母可以为大于2的任何数，3，4都可以。因为我们通过泰勒展开得到的分母为2，而</p>
<p>$\frac{-\mu\delta^2}{4}$ &gt;$\frac{-\mu\delta^2}{2}$  ,所以事实上这个界比$e^{\frac{-\mu\delta^2}{2}}$ 要松</p>
<p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/0.jpg" style="zoom: 67%;"></p>
<h4 id="example"><a href="#example" class="headerlink" title="example"></a>example</h4><p>比如说我们想要计算 $P(|x-\mu|&gt;\delta\mu)$ </p>
<p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/50.png" style="zoom:100%;"></p>
<p>这里的$\delta$ 是怎么求出来的呢？凑出来的。因为知道$\mu=\frac{n}{2}$（期望） 然后 根据我们要求的尾概率，提取出$\mu$ 来看他的系数即可</p>
<p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/45.png" style="zoom:80%;"></p>
<p>像下面这个例子，对我们理解切诺夫界更有帮助</p>
<p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/46.png" style="zoom:80%;"></p>
<p>这相当于一个不均匀的硬币，有$\frac{\pi}{4}$ 的概率正面（红色圆域） ，剩下的概率为反面（绿色部分）</p>
<p>Y就相当于抛出n次后打包在一起的一个随机变量。</p>
<p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/47.png" style="zoom:80%;"></p>
<p>那么我如果要计算$Y&gt;\frac{\pi}{2}$ 的概率（事实上这个等于0）那么我们就可以按照上面的方法计算。</p>
<p>$P(Y-\frac{\pi}{4}&gt;\frac{\pi}{4})$ 的 意思，其实就是偏移方差量大于$\frac{\pi}{4}$ 的意思，概率肯定是随着n的增加而接近于0。</p>
<p>所以根据切比雪夫不等式我们可以得到了当n=100的时候，这个概率的上界是0.0025 但这还不是最准确的</p>
<p><img src="/2020/05/22/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87part3/48.png" style="zoom:80%;"></p>
<p>当我们用切诺夫界来计算的时候，那么概率变成了e^(-75/4)^  也就是小数点后10个0的概率，而事实上的概率比这个还要小。所以说切诺夫界比切比雪夫不等式更加的准确</p>
<p>所以说我们想要达到一个精度（偏移期望的概率达到足够小） 对于切比雪夫来说，需要做的次数要远高于切诺夫界所需要的次数，因为切诺夫界是按照指数缩小的</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/discrete-mathematics/" rel="tag"># discrete mathematics</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/05/20/%E6%97%A0%E7%A9%B7%E7%BA%A7%E6%95%B0/" rel="prev" title="无穷级数">
      <i class="fa fa-chevron-left"></i> 无穷级数
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/05/22/%E6%9B%B4%E6%96%B0%E6%97%A5%E5%BF%97/" rel="next" title="更新日志">
      更新日志 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#离散概率part3"><span class="nav-number">1.</span> <span class="nav-text">离散概率part3</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Outline"><span class="nav-number">1.1.</span> <span class="nav-text">Outline</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Expectation"><span class="nav-number">1.2.</span> <span class="nav-text">Expectation</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#期望的两种计算方法"><span class="nav-number">1.2.1.</span> <span class="nav-text">期望的两种计算方法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#基于定义求"><span class="nav-number">1.2.1.1.</span> <span class="nav-text">基于定义求</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#基于随机变量来求"><span class="nav-number">1.2.1.2.</span> <span class="nav-text">基于随机变量来求</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#例题"><span class="nav-number">1.2.2.</span> <span class="nav-text">例题</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#例一"><span class="nav-number">1.2.2.1.</span> <span class="nav-text">例一</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#例二"><span class="nav-number">1.2.2.2.</span> <span class="nav-text">例二</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#贝努力分布和几何分布的期望"><span class="nav-number">1.2.3.</span> <span class="nav-text">贝努力分布和几何分布的期望</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#贝努力分布"><span class="nav-number">1.2.3.1.</span> <span class="nav-text">贝努力分布</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#几何分布"><span class="nav-number">1.2.3.2.</span> <span class="nav-text">几何分布</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Linearity-of-expectations"><span class="nav-number">1.3.</span> <span class="nav-text">Linearity of expectations</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#期望的线性性质"><span class="nav-number">1.3.1.</span> <span class="nav-text">期望的线性性质</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#证明："><span class="nav-number">1.3.2.</span> <span class="nav-text">证明：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#贝努力实验的期望"><span class="nav-number">1.3.3.</span> <span class="nav-text">贝努力实验的期望</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#例子："><span class="nav-number">1.3.4.</span> <span class="nav-text">例子：</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#例一："><span class="nav-number">1.3.4.1.</span> <span class="nav-text">例一：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#例二："><span class="nav-number">1.3.4.2.</span> <span class="nav-text">例二：</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#独立随机变量的期望"><span class="nav-number">1.3.5.</span> <span class="nav-text">独立随机变量的期望</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Average-case-computational-complexity"><span class="nav-number">1.4.</span> <span class="nav-text">Average-case computational complexity</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#线性搜索算法"><span class="nav-number">1.4.1.</span> <span class="nav-text">线性搜索算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#插入排序算法"><span class="nav-number">1.4.2.</span> <span class="nav-text">插入排序算法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#方差"><span class="nav-number">1.5.</span> <span class="nav-text">方差</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#定义"><span class="nav-number">1.5.1.</span> <span class="nav-text">定义</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#定理"><span class="nav-number">1.5.2.</span> <span class="nav-text">定理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#各种分布的方差"><span class="nav-number">1.5.3.</span> <span class="nav-text">各种分布的方差</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#例一：贝努力实验的方差"><span class="nav-number">1.5.3.1.</span> <span class="nav-text">例一：贝努力实验的方差</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#例二：-二项分布的方差"><span class="nav-number">1.5.3.2.</span> <span class="nav-text">例二： 二项分布的方差</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#例三：几何分布的方差"><span class="nav-number">1.5.3.3.</span> <span class="nav-text">例三：几何分布的方差</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#方差的非线性性"><span class="nav-number">1.5.4.</span> <span class="nav-text">方差的非线性性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Bienayme‘s-formula"><span class="nav-number">1.5.5.</span> <span class="nav-text">Bienayme‘s formula</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#例子"><span class="nav-number">1.5.6.</span> <span class="nav-text">例子</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Tail-probability尾概率"><span class="nav-number">1.6.</span> <span class="nav-text">Tail probability尾概率</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Markovs-inequality"><span class="nav-number">1.6.1.</span> <span class="nav-text">Markovs inequality</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Theorem"><span class="nav-number">1.6.1.1.</span> <span class="nav-text">Theorem</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Proof"><span class="nav-number">1.6.1.2.</span> <span class="nav-text">Proof</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Chebyshevs-inequality"><span class="nav-number">1.6.2.</span> <span class="nav-text">Chebyshevs inequality</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Theorem-1"><span class="nav-number">1.6.2.1.</span> <span class="nav-text">Theorem</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Proof-1"><span class="nav-number">1.6.2.2.</span> <span class="nav-text">Proof</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Chernoff-bound"><span class="nav-number">1.6.3.</span> <span class="nav-text">Chernoff bound</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Theorem-2"><span class="nav-number">1.6.3.1.</span> <span class="nav-text">Theorem</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Proof-2"><span class="nav-number">1.6.3.2.</span> <span class="nav-text">Proof</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Theorem-for-upper-tail"><span class="nav-number">1.6.3.3.</span> <span class="nav-text">Theorem for upper tail</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#example"><span class="nav-number">1.6.3.4.</span> <span class="nav-text">example</span></a></li></ol></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Jason</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">439</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
        <span class="site-state-item-count">68</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Jason</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

    

  

</body>
</html>
