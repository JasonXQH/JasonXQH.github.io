<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="en">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">



  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />



  <meta name="google-site-verification" content="y0-26jFM_8wn6Slpy1ahkB8ndR7w0OOGyAU6IaXjLUI" />














  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="统计方法," />










<meta name="description" content="线性回归的背景在实际问题中，感兴趣的变量y与易于获得的变量x之间存在紧密关联，但又不由变量x而唯一确定的，这种关系通常称为统计关系 若变量y与x间有统计关系，那么通常称y为因变量或者响应变量，x为自变量或者解释变量，这里x在机器学习方法中也会被称为特征。 在给定x的取值之后，y的取值是无法唯一确定的。于是，我们可以将y认为是一个随机变量，并需要通过概率分布来对其进行描述，而我们常常关心的是这个概率">
<meta property="og:type" content="article">
<meta property="og:title" content="一元线性回归">
<meta property="og:url" content="https://jasonxqh.github.io/2021/10/11/%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/index.html">
<meta property="og:site_name" content="Jason‘s Blog">
<meta property="og:description" content="线性回归的背景在实际问题中，感兴趣的变量y与易于获得的变量x之间存在紧密关联，但又不由变量x而唯一确定的，这种关系通常称为统计关系 若变量y与x间有统计关系，那么通常称y为因变量或者响应变量，x为自变量或者解释变量，这里x在机器学习方法中也会被称为特征。 在给定x的取值之后，y的取值是无法唯一确定的。于是，我们可以将y认为是一个随机变量，并需要通过概率分布来对其进行描述，而我们常常关心的是这个概率">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://jasonxqh.github.io/2021/10/11/%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/1.jpeg">
<meta property="og:image" content="https://jasonxqh.github.io/2021/10/11/%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/2.png">
<meta property="og:image" content="https://jasonxqh.github.io/2021/10/11/%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/3.png">
<meta property="og:image" content="https://jasonxqh.github.io/2021/10/11/%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/6.png">
<meta property="og:image" content="https://jasonxqh.github.io/2021/10/11/%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/4.png">
<meta property="og:image" content="https://jasonxqh.github.io/2021/10/11/%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/5.png">
<meta property="article:published_time" content="2021-10-11T13:24:56.000Z">
<meta property="article:modified_time" content="2022-01-05T06:33:18.000Z">
<meta property="article:author" content="Jason">
<meta property="article:tag" content="统计方法">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://jasonxqh.github.io/2021/10/11/%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/1.jpeg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":true,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://jasonxqh.github.io/2021/10/11/一元线性回归/"/>





  <title>一元线性回归 | Jason‘s Blog</title>
  




<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-170027658-1', 'auto');
  ga('send', 'pageview');
</script>





<meta name="generator" content="Hexo 4.2.0"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">
  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>
<a href="https://github.com/JasonXQH/JasonXQH.github.io" target="_blank" rel="noopener" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Jason‘s Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-sitemap">
          <a href="/sitemap.xml" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-sitemap"></i> <br />
            
            Sitemap
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="Searching..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://jasonxqh.github.io/2021/10/11/%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jason">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jason‘s Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">一元线性回归</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2021-10-11T21:24:56+08:00">
                2021-10-11
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  626
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  2
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="线性回归的背景"><a href="#线性回归的背景" class="headerlink" title="线性回归的背景"></a>线性回归的背景</h1><p>在实际问题中，感兴趣的变量y与易于获得的变量x之间存在紧密关联，但又不由变量x而唯一确定的，这种关系通常称为<strong>统计关系</strong></p>
<p>若变量y与x间有统计关系，那么通常称y为因变量或者响应变量，x为自变量或者解释变量，这里x在机器学习方法中也会被称为特征。</p>
<p>在给定x的取值之后，y的取值是无法唯一确定的。于是，我们可以将y认为是一个随机变量，并需要通过概率分布来对其进行描述，而我们常常关心的是这个概率分布的数字特征，如<strong>期望和方差</strong>。</p>
<p>在给定x的时候，称y的条件数学期望为 y 关于 x 的(均值)回归函数，即：</p>
<script type="math/tex; mode=display">
f(x) = E(y|x)</script><p>注意到，$f(x)$​​ 不仅是 x 的一个确定性的函数，并且从平均意义上刻画了变量y与x间统计关系的规律</p>
<p>而如何确定这个<strong>确定性</strong>的函数f是回归问题中最为核心的问题。</p>
<ul>
<li>线性回归模型可看作将这个函数f 取为x的一个线性函数模式, 如 $f(x)=\beta_0+\beta_1 x$</li>
<li>神经网络模型可看作将这个函数f 取为x的一个非线性函数的形式，如 $f(x)=\max(0,\beta_0+\beta_1x)$​ (Relu函数)</li>
<li>深度学习模型可理解为这个函数f 取为x的多个非线性函数的复合形式。</li>
</ul>
<h1 id="一元线性回归"><a href="#一元线性回归" class="headerlink" title="一元线性回归"></a>一元线性回归</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><h3 id="模型版"><a href="#模型版" class="headerlink" title="模型版"></a>模型版</h3><p>一元回归模型为：</p>
<script type="math/tex; mode=display">
y = \beta_0+\beta_1x+\epsilon</script><p>其中，$\beta_0,\beta_1$ 为两个未知参数，常称为回归系数，而$\varepsilon$​ 是随机误差。</p>
<p>一元回归模型与数据模型$y=\beta_0+\beta_1x$ 在理解上是不同的，主要的差异在于是否引入了随机误差项$\varepsilon$ :</p>
<ul>
<li>在数学模型中，两个变量之间的关系是确定性的</li>
<li>在统计模型中，两个变量之间的关系是不确定的</li>
</ul>
<p>那么，在一元线性回归模型中，确定性的部分是$\beta_0+\beta_1x$, 随机性的部分为$\varepsilon$ </p>
<p>随机误差项用来概括由于人们认识以及其他客观原因的局限而没有考虑的种种偶然因素，一般，随机误差$\epsilon$​ 没有办法被观测，但<strong>通常假定</strong>$\varepsilon$​ 满足：</p>
<script type="math/tex; mode=display">
\cases{E(\varepsilon) = 0\\Var(\varepsilon) = \sigma^2<\infty}</script><p>其中，$E(\varepsilon)$​​ 表示$\varepsilon$​​ 的数学期望设其为0是为了避免参数不可识别，$Var(\varepsilon)$​​表示$\varepsilon$​​​​的方差</p>
<p>那么因为$\varepsilon$是一个随机变量，所以$y=\beta_0+\beta_1 x+\varepsilon$ 也是随机变量，那么关于x求条件期望，即：</p>
<script type="math/tex; mode=display">
E(y|x) = \beta_0+\beta_1x</script><p>注意到$E(y|x)$​是关于x的一个函数，表示用x的信息刻画因变量y，作为y的”预测“，我们称$E(y|x)=\beta_0+\beta_1x$为回归方程。</p>
<h3 id="数据版"><a href="#数据版" class="headerlink" title="数据版"></a>数据版</h3><p>一般假定我们观测到的数据${(x<em>i,y_i)}</em>{i=1}^n$ 符合线性回归模型及其假设，即：</p>
<script type="math/tex; mode=display">
\cases{y_i= \beta_0+\beta_1x_i+\varepsilon_i,i=1,2\cdots,n\\~\\
E(\varepsilon)=0 ~~~ Var(\varepsilon_i)=\sigma^2}</script><p>同时假定n组数据是独立观测的，即$\varepsilon_1,\varepsilon_2,\cdots,\varepsilon_n$​​是独立同分布的随机变量. </p>
<p>所以，$y_1,y_2\cdots,y_n$ 的期望与方差分别为：</p>
<script type="math/tex; mode=display">
\begin{align}
&E(y_i)= \beta_0+\beta_1x_i\\
&Var(y_i) = \sigma^2, i = 1,2\cdots,n
\end{align}</script><p>这表明，随机变量$y_1,y_2\cdots,y_n$​ 服从不同的分布，方差相等，但是期望不等，且相互独立</p>
<p>模型版和数据版的差别就是，前者强调的是模型，后者侧重的是数据</p>
<h2 id="任务：预测和参数估计"><a href="#任务：预测和参数估计" class="headerlink" title="任务：预测和参数估计"></a>任务：预测和参数估计</h2><p>首先我们来说说回归的最常见的任务之一就是通过n组样本观测值$(x_i,y_i),i=1,2\cdots,n$ 对一个新的个体进行预测。具体来说，如果$x_0$ 已知，那么 $\beta_0+\beta_1x_0$ 是$y_0$的一个合理的预测值 </p>
<p>现在问题来了，这个方程里面的两个参数$\beta_0$​和$\beta_1$​怎么估呢？我们需要通过观测到的数据$(x_i,y_i),i=1,\cdots,n$​​进行估计。一般我们会用$\hat\beta_0$​ 和 $\hat\beta_1$​ 分别表示$\beta_0$​和$\beta_1$​ 的估计值。那么，y关于x的一元线性<strong>经验</strong>回归方程为:</p>
<script type="math/tex; mode=display">
\hat y = \hat\beta_0+\hat\beta_1 x</script><p>称其图形为<strong>经验回归直线</strong>，其中，$\hat\beta_0$ 表示经验回归直线的截距，$\hat\beta_1$表示经验回归直线的斜率</p>
<p>给定$x=x_0$后，称：</p>
<script type="math/tex; mode=display">
\hat y_0 = \hat \beta_0+\hat\beta_1x_0</script><p>为回归值。又是也称为拟合值或者预测值。</p>
<h3 id="最小二乘估计"><a href="#最小二乘估计" class="headerlink" title="最小二乘估计"></a>最小二乘估计</h3><p>在概率论中我们讲了估计的三种思想：似然、替换和拟合</p>
<p>拟合的方法就是配直线，也就是我们现在要讲的<strong>最小二乘</strong></p>
<p>对于每一个样本观测值$(x_i,y_i)$ ，定义偏差为观测值$y_i$ 与其回归至$E(y_i|x_i)$的差异为：</p>
<script type="math/tex; mode=display">
y_i - E(y_i|x_i) = y_i - \beta_0-\beta_1x_i</script><p>偏差平方和为：</p>
<script type="math/tex; mode=display">
Q(\beta_0,\beta_1) = \sum_{i=1}^n(y_i-E(y_i))^2\\
=\sum_{i=1}^n (y_i-\beta_0-\beta_1x_i)^2</script><p>用图形来表示，就如下图：</p>
<p><img src="/2021/10/11/%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/1.jpeg" alt="1" style="zoom:67%;"></p>
<p>我们称通过最小化偏差平方和$Q(\beta_0,\beta_1)$​​而得到的参数估计方法，为<strong>最小二乘估计</strong> ,下面给出其数学定义：</p>
<script type="math/tex; mode=display">
\begin{align}
(\hat\beta_0,\hat\beta_1)& = \arg\min_{\beta_0,\beta_1} Q(\beta_0,\beta_1)\\
&=\arg\min_{\beta_0,\beta_1}\sum_{i=1}^n(y_i-\hat\beta_0-\hat\beta_1x_i)^2
\end{align}</script><p>我们发现这其实就是一个求极值的问题，因为$Q$ 是关于$\hat\beta_0,\hat\beta_1$的非负二次函数，所以其最小值总是存在的。</p>
<p>那么要求极值，我们首先要求一阶导数，即：</p>
<script type="math/tex; mode=display">
\cases{\frac{\partial Q}{\partial \beta_0} = -2\sum_{i=1}^n(y_i-\beta_0-\beta_1x_i)=0\\~\\
\frac{\partial Q}{\partial\beta_1} = -2\sum_{i=1}^n(y_i-\beta_0-\beta_1x_i)x_i = 0
}</script><p>整理得到<strong>正规方程</strong>：</p>
<script type="math/tex; mode=display">
\cases{n\beta_0+\overline x\beta_1 = n\overline y\\~\\
n\overline x\beta_0+\sum_{i=1}^nx_i^2\beta_1=\sum_{i=1}^n x_iy_i}</script><p>于是，$\beta_0,\beta_1$的最小二乘估计为：</p>
<script type="math/tex; mode=display">
\begin{align}
&\hat\beta_0 = \overline y -\hat\beta_1\overline x\\~\\
&\hat\beta_1 = \frac{\sum_{i=1}^n(x_i-\overline x)(y_i-\overline y)}{\sum_{i=1}^n(x_i-\overline x)^2}
\end{align}</script><p>其中，</p>
<script type="math/tex; mode=display">
\overline x = \frac{1}{n} \sum_{i=1}^n x_i,\overline y = \frac{1}{n}\sum_{i=1}^n y_i</script><p>分别为$x_1,x_2\cdots,x_n$ 和 $y_1,y_2\cdots,y_n$ 的样本均值</p>
<p>我们可以用跟简单的记号来表示$\hat\beta_0$和$\hat\beta_1$ </p>
<script type="math/tex; mode=display">
\begin{align}
&l_{xx} = \sum_{i=1}^n (x_i-\overline x)^2 = \sum_{i=1}^n x_i^2-n(\overline x)^2\\~\\
&l_{xy} = \sum_{i=1}^n (x_i-\overline x)(y_i-\overline y) = \sum_{i=1}^n x_iy_i -n\overline x\cdot\overline y
\end{align}</script><p>于是，最小二乘估计简写为：</p>
<script type="math/tex; mode=display">
\cases{
\hat\beta_0 = \overline y -\hat\beta_1\overline x ,\\~\\
\hat\beta_1 = l_{xx}^{-1}l_{xy}
}</script><p>但是，我们是根据一阶导数求出的$\hat\beta$​ ，这实际上是 $Q(\beta_0,\beta_1)$​的稳定点, 但是是否为最小值点，仍需要根据其二阶导在$(\hat\beta_0,\hat\beta_1)$​上表现来判断是否为最小值点：</p>
<script type="math/tex; mode=display">
\cases{\frac{\partial Q}{\partial \beta_0} = -2\sum_{i=1}^n(y_i-\beta_0-\beta_1x_i)=0\\~\\
\frac{\partial Q}{\partial\beta_1} = -2\sum_{i=1}^n(y_i-\beta_0-\beta_1x_i)x_i = 0
}</script><p>从上式可以推得：$Q(\beta_0,\beta_1)$的二阶偏导为：</p>
<script type="math/tex; mode=display">
\begin{vmatrix} \begin{pmatrix} 2n & 2n\overline x \\ 2n\overline x & 2\sum_{i=1}^nx_i^2 \end{pmatrix} \end{vmatrix} = 4n\sum_{i=1}^nx_i^2-4n^2(\overline x)^2</script><p>我们提取出4n,发现剩下的式子就是$l_{xx}$,因此：</p>
<script type="math/tex; mode=display">
= 4n(\sum_{i=1}^nx_i^2-n(\overline x)^2) = \sum_{i-1}^n(x_i-\overline x)^2</script><p>因此，二阶导大于0，说明Q在$\hat\beta_0,\hat\beta_1$​处取最小值</p>
<h3 id="最大似然估计"><a href="#最大似然估计" class="headerlink" title="最大似然估计"></a>最大似然估计</h3><p>我们首先来回顾一下最大似然估计：</p>
<p>最大似然估计是依赖于总体的概率函数$f(x;\theta)$以及样本所提供的信息来求未知参数的估计。当总体X为连续随机变量时，其密度函数为：</p>
<script type="math/tex; mode=display">
\{f(x;\theta),\theta\in \Theta\}</script><p>假定总体X的一个独立同分布的样本为$x_1,x_2\cdots,x_n$ 参数的似然函数为：</p>
<script type="math/tex; mode=display">
L(\theta;x_1,x_2,\cdots,x_n) = \prod_{i=1}^nf(x_i;\theta)</script><p>最大似然估计指的是在参数空间 $\Theta$​ 中选取随机样本$(X_1,X_2,\cdots,X_n)$落在点$(x_1,x_2\cdots,x_n)$附近最大概率的$\hat\theta$ 为未知参数$\theta$的估计值，即$\hat\theta$ 需要满足：</p>
<script type="math/tex; mode=display">
\hat\theta = \arg \max_{\theta} L(\theta;x_1,x_2\cdots,x_n)</script><h4 id="分布假定"><a href="#分布假定" class="headerlink" title="分布假定"></a>分布假定</h4><p>那么要做极大似然估计的话，我们首先要假定分布，有了密度函数才能得到似然函数。</p>
<p>在一元线性回归模型中，最常见的假定为$\varepsilon$ 服从正态分布，即</p>
<script type="math/tex; mode=display">
\varepsilon\sim N(0,\sigma^2)</script><p>从数据角度看，由于 $\varepsilon_1,\varepsilon_2\cdots,\varepsilon_n$ 都是与$\varepsilon$独立同分布的随机变量，因而有：</p>
<script type="math/tex; mode=display">
\varepsilon_i\sim N(0,\sigma^2),i=1,2,\cdots,n</script><p>在 $\varepsilon_i$ 服从正态分布的假定下，$y_i$ 也服从正态分布 ，即</p>
<script type="math/tex; mode=display">
y_i\sim N(\beta_0+\beta_1x_i,\sigma^2),i = 1,2\cdots,n</script><p>因此，我们可以得到$y_i$的密度函数：</p>
<script type="math/tex; mode=display">
f_i(y_i) = \frac{1}{\sqrt{2\pi\sigma^2}}\exp\{-\frac{1}{2\sigma^2}[y_i-(\beta_0+\beta_1x_i)]^2 \}</script><p>因为 $y_1,y_2\cdots,y_n$​的密度函数是和i相关的，各不相同，我们用 $f_i$ 代替 $f(y_i)$ 更为合适</p>
<p>那么，似然函数为：</p>
<script type="math/tex; mode=display">
\begin{align}
L(\beta_0,\beta_1,\sigma^2) &= \prod_{i=1}^n f_i(y_i)\\
&=(2\pi\sigma^2)^{-\frac{n}{2}}\exp\{-\frac{1}{2\sigma^2}\sum_{i=1}^n[y_i-(\beta_0+\beta_1x_i)]^2 \}
\end{align}</script><p>于是，对数似然函数为：</p>
<script type="math/tex; mode=display">
\ln L (\beta_0,\beta_1,\sigma^2) = -\frac{n}{2}\ln(2\pi\sigma^2)-\frac{1}{2\sigma^2}\sum_{i=1}^n(y_i-(\beta_0+\beta_1x_i))^2</script><p>易知 L 的最大值点与 $\ln L$ 的最大值点是相同的。我们发现：</p>
<script type="math/tex; mode=display">
\arg\max_{\beta_0,\beta_1}\ln L(\beta_0,\beta_1,\sigma^2) \Leftrightarrow \min_{\beta_0,\beta_1}Q(\beta_0,\beta_1)</script><p>即：回归系数$\beta_0,\beta_1$的最大似然估计和最小二乘估计的形式是一致的。</p>
<h4 id="求解-sigma-2"><a href="#求解-sigma-2" class="headerlink" title="求解$\sigma^2$"></a>求解$\sigma^2$</h4><p>我们可以对$\ln L(\beta_0,\beta_1,\sigma^2)$关于$\sigma^2$求导，并令一阶导数为0，得到：</p>
<script type="math/tex; mode=display">
\frac{\partial \ln L}{\partial \sigma^2} =-\frac{n}{2\sigma^2}+\frac{1}{4\sigma^2}\sum_{i=1}^n(y_i-(\beta_0+\beta_1x_i))^2 = 0</script><p>那么，$\sigma^2$ 的最大似然估计为：</p>
<script type="math/tex; mode=display">
\hat\sigma^2_{ML} = \frac{1}{n}\sum_{i=1}^n(y_i-\hat y_i)^2\\
=\frac{1}{n}\sum_{i=1}^n(y_i-(\hat\beta_0+\hat\beta_1x_i))^2</script><p>$\hat\sigma_{ML}^2$是$\sigma^2$​ 的有偏估计。因为极大似然估计就是有偏的。这里我们有两个参数，因此要除以 n-2。</p>
<p>在实际应用中，更为常用的是$\sigma^2$ 的无偏估计，即：</p>
<script type="math/tex; mode=display">
\hat\sigma^2 = \frac{1}{n-2}\sum_{i=1}^n(y_i-(\hat\beta_0+\hat\beta_1x_i))^2</script><p>最大似然估计是在 $\varepsilon_i\sim N(0,\sigma^2)$ 的正态分布假设下求得的，而最小二乘估计则估计则对分布假设没有要求。所以说，极大似然估计也可以看成是最小二乘估计，只是多了一个条件。因此极大似然估计相对于最小二乘估计更为稳健</p>
<p>$y_1,y_2,\cdots,y_n$ 是独立的正态分布样本，而不是同分布的，但这并不妨碍最大似然方法去求解。因此极大似然估计只要定义出似然函数即可，不要求样本同分布。</p>
<h4 id="定理1"><a href="#定理1" class="headerlink" title="定理1"></a>定理1</h4><p>如果$y_1,y_2\cdots,y_n$ 是相互独立的且$y_i$是正态分布随机变量，即</p>
<script type="math/tex; mode=display">
y_i\sim N(\beta_0+\beta_1x_i,\sigma^2)</script><p>那么</p>
<ul>
<li><p>$\beta_0,\beta_1$ 均服从正态分布</p>
<script type="math/tex; mode=display">
\begin{align}
&\hat\beta_0\sim N(\beta_0,(\frac{1}{n}+\frac{\overline x^2}{l_{xx}})\sigma^2)\\
&\hat\beta_1\sim N(\beta_1,\frac{\sigma^2}{l_{xx}})
\end{align}</script></li>
<li><p>$\beta_0,\beta_1$两者的协方差如下：</p>
<script type="math/tex; mode=display">
Cov(\hat\beta_0,\hat\beta_1) = -\frac{\overline x}{l_{xx}}\sigma^2</script><p>从这个公式我们可以得出：只有当$\overline x=0$ 的时候，两者才不相关，要做到这一点需要对样本数据进行<strong>中心化</strong>，否则我们得到的$\beta_0$ 和 $\beta_1$ 都是相关的。</p>
</li>
</ul>
<h4 id="证明"><a href="#证明" class="headerlink" title="证明"></a>证明</h4><h5 id="步骤1：用-yi-线性表出-beta-0-beta-1"><a href="#步骤1：用-yi-线性表出-beta-0-beta-1" class="headerlink" title="步骤1：用$yi$线性表出$\beta{0},\beta_1$"></a>步骤1：用$y<em>i$线性表出$\beta</em>{0},\beta_1$</h5><ul>
<li>首先我们可以将 $\hat\beta_1$写成 $y_i$ 随机变量的一个加权求和的形式。(因为x是确定的)</li>
</ul>
<script type="math/tex; mode=display">
\begin{align}
\hat\beta_1 = l_{xx}^{-1}l_{yy} &= l_{xx}^{-1}\sum_{i=1}^n(x_i-\overline x)(y_i-\overline y)\\
&=l_{xx}^{-1}(\sum_{i=1}^m(x_i-\overline x)y_i-\sum_{i=1}^n(x_i-\overline x)\overline y)\\
&=l_{xx}^{-1}(\sum_{i=1}^n (x_i-\overline x)y_i)\\
&=\sum_{i=1}^n\frac{(x_i-\overline x)}{l_{xx}}y_i
\end{align}</script><p>第二个等式中的后者为0，因为 $\sum<em>{i=1}^n(x_i-\overline x)=\sum</em>{i=1}^n x_i-n\overline x=0$​</p>
<ul>
<li>我们可以将$\hat\beta_0$写为以下的形式：</li>
</ul>
<script type="math/tex; mode=display">
\begin{align}
\hat\beta_0& = \overline y -\hat\beta_1 \overline x\\
&=\frac{1}{n}\sum_{i=1}^n y_i -\sum_{i=1}^n\frac{(x_i-\overline x)}{l_{xx}}y_i\overline x\\
&=\sum_{i=1}^n(\frac{1}{n}-\frac{\overline x(x_i-\overline x)}{l_{xx}})y_i
\end{align}</script><p>因此$\hat\beta_0$和$\hat\beta_1$ 均可以看做是 $y_1,y_2\cdots,y_n$的线性组合。已知$y_1,y_2\cdots,y_n$是相互独立的正态随机变量，那么 $\hat\beta_0$和$\hat\beta_1$​均服从正态分布</p>
<h5 id="步骤2：考虑期望和方差"><a href="#步骤2：考虑期望和方差" class="headerlink" title="步骤2：考虑期望和方差"></a>步骤2：考虑期望和方差</h5><p>接下来，我们需要考虑这两个估计的均值与方差，从而进一步确定分布</p>
<ul>
<li>一方面，考虑 $\hat\beta_1$ 的期望与方差，即：</li>
</ul>
<script type="math/tex; mode=display">
\begin{align}
E(\hat\beta_1) &=\sum_{i=1}^n\frac{(x_i-\overline x)}{l_{xx}}E(y_i)
\\& = \sum_{i=1}^n (\frac{x_i-\overline x}{l_{xx}})(\beta_0+\beta_1x_i)\\
&=\sum_{i=1}^n \frac{(x_i-\overline x)}{l_{xx}}\beta_0+\sum_{i=1}^n\frac{x_i(x_i-\overline x)}{l_{xx}}\beta_1
\end{align}</script><p>我们可以让其减去$\sum<em>{i=1}^n\frac{\overline x(x_i-\overline x)}{l</em>{xx}}\beta_1$ 因为这个式子为0</p>
<script type="math/tex; mode=display">
=\sum_{i=1}^n \frac{(x_i-\overline x)}{l_{xx}}\beta_0+\sum_{i=1}^n\frac{x_i(x_i-\overline x)}{l_{xx}}\beta_1-\sum_{i=1}^n\frac{\overline x(x_i-\overline x)}{l_{xx}}\beta_1\\</script><p>将后两项展开，可以得到一个平方项</p>
<script type="math/tex; mode=display">
\sum_{i=1}^n\frac{(x_i-\overline x)}{l_{xx}}\beta_0+\sum_{i=1}^n\frac{(x_i-\overline x)^2}{l_{xx}}\beta_1</script><p>前面一项，因为$\sum<em>{i=1}^n(x_i-\overline x)=\sum</em>{i=1}^n x_i-n\overline x=0$​ ,因此</p>
<script type="math/tex; mode=display">
E(\hat\beta_1) = \beta_1</script><p>对于方差，就更为简单了：</p>
<script type="math/tex; mode=display">
Var(\hat\beta_1) = \sum_{i=1}^n(\frac{x_i-\overline x}{l_{xx}})^2Var(y_i)\\
= \sum_{i=1}^n \frac{(x_i-\overline x)^2}{(l_{xx})^2}\sigma^2 = \frac{\sigma^2}{l_{xx}}</script><ul>
<li>另一方面，考虑 $\hat\beta_0$ 的期望与方差，即</li>
</ul>
<script type="math/tex; mode=display">
E(\hat\beta_0) = E(\overline y)-E(\hat\beta_1)\overline x\\
~~~~~~~~~~~~~~~~~~~~~~~~=\frac{1}{n}\sum_{i=1}^n(\beta_0+\beta_1x)-\beta_1\overline x\\
~~~~~~~~~~~~~~~~~~~=\beta_0+\beta_1\overline x-\beta_1\overline x=\beta_0</script><p>方差：</p>
<script type="math/tex; mode=display">
Var(\hat\beta_0) = \sum_{i=1}^n(\frac{1}{n}-\frac{(x_i-\overline x)\overline x}{l_{xx}})^2\text{Var}(y_i)\\
=\sigma^2\sum_{i=1}^n(\frac{1}{n^2}-\frac{2(x_i-\overline x)\overline x}{nl_{xx}}+\frac{(x_i-\overline x)^2\overline x^2}{l^2_{xx}})\\
=\sigma^2(\frac{1}{n}+\frac{\overline x^2}{l_{xx}})</script><h5 id="第三步：求协方差"><a href="#第三步：求协方差" class="headerlink" title="第三步：求协方差"></a>第三步：求协方差</h5><p>因为 $y_1,y_2\cdots,y_n$相互独立，所以我们把第一步求出的$\beta_0,\beta_1$的式子带入，得到： </p>
<script type="math/tex; mode=display">
\text{Cov}(\hat\beta_0,\hat\beta_1) = \text{Cov}(\sum_{i=1}^n(\frac{1}{n}-\frac{(x_i-\overline x)\overline x}{l_{xx}})y_i~,\sum_{i=1}^n\frac{(x_i-\overline x)}{l_{xx}}y_i)</script><p>我们可以将它们看做是 $y_i$的线性组合之间的协方差。因为当$y_i$ 之间不相等，就说明他们是独立的，两个独立的协方差之间是0，因此我们只要看做是 $y_i,y_i$​即可.</p>
<p>那么，$y_i$​和$y_i$​的协方差就是$y_i$​​的方差，其方差为$\sigma^2$ ,前面$\sum$可以都看成是系数，提取出来即可，最后化简：</p>
<script type="math/tex; mode=display">
=\sum_{i=1}^n(\frac{1}{n}-\frac{(x_i-\overline x)\overline x}{l_{xx}})\sum_{i=1}^n\frac{(x_i-\overline x)}{l_{xx}}\sigma^2\\
=(\sum_{i=1}^n\frac{x_i-\overline x}{l_{xx}}-\sum_{i=1}^n\frac{(x_i-\overline x)^2\overline x}{l_{xx}} )\sigma^2\\
=-\frac{\overline x}{l_{xx}}\sigma^2</script><h5 id="第四步：给出推论"><a href="#第四步：给出推论" class="headerlink" title="第四步：给出推论"></a>第四步：给出推论</h5><ul>
<li>$\hat\beta_0,\hat\beta_1$​分别是$\beta_0,\beta_1$​​ 的无偏估计，而且这个无偏估计并不需要服从正态分布。 </li>
<li>除 $\overline x=0$ 外，$\hat\beta_0$与$\hat\beta_1$是相关的，只有当数据中心化以后才是不相关的</li>
<li><p>为了提高$\hat\beta<em>0,\hat\beta_1$的估计精度(即降低它们的方差)就要求样本量n增加，这样会使得$l</em>{xx}$增大，即要求 $x_1,\cdots,x_n$比较分散。这样会使得方差变小—数据波动更小</p>
<h4 id="tips"><a href="#tips" class="headerlink" title="tips"></a>tips</h4></li>
</ul>
<blockquote>
<ul>
<li>我提出了一个假设之后，在建模中就要以这个假设为默认条件</li>
<li>在建模的过程中，提出了很多假设，我们要用数据去验证是否符合这些假设</li>
</ul>
</blockquote>
<p>那么在这个线性回归模型中，我们提出了什么假设呢？</p>
<ul>
<li>最核心的假定为：线性性。即x是会影响y的。否则，如果x不在式子里，我们能用样本均值来预测y了。那么加了x之后，预测效果会不会提升呢？肯定是会的。因此，我们首先要检验出：x是否会对y产生影响。如果没有，我们干嘛用x去预测y呢？</li>
</ul>
<h2 id="回归方程的显著性检验"><a href="#回归方程的显著性检验" class="headerlink" title="回归方程的显著性检验"></a>回归方程的显著性检验</h2><p>首先我们要来考虑$\beta_1$是否为0，若真的为0，那么其实$y$和 $x$之间是没有必然联系的，但是，我们估出来的$\hat\beta_1$可能不是0，那么这时候怎么进行判断呢？那么在这种情况下，对一个参数的估计有点类似于假设检验的问题。 检验问题为：</p>
<script type="math/tex; mode=display">
H_0:\beta_1 =0 ~~\text{vs} ~~H_1 : \beta_1 \neq 0</script><p>如果我们的得到的结论是拒绝$H_0$ ,那么我们认为回归方程是显著的。</p>
<p>接下来我们会介绍三种估计方法</p>
<h3 id="F检验"><a href="#F检验" class="headerlink" title="F检验"></a>F检验</h3><h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><p>我们用<strong>方差分析</strong>的思想：</p>
<ul>
<li>令回归值为 $\hat y_i = \hat\beta_0+\hat\beta_1 x_i$   残差：$e_i = y_i-\hat y_i$ </li>
<li><strong>偏差平方和</strong>为 $SS<em>T = \sum</em>{i=1}^n(y<em>i-\overline y)^2 = l</em>{yy}$​ ,其中 $\overline y = \frac{1}{n}\sum_{i=1}^n y_i$​ </li>
<li>引起$y<em>i$​ 不同的原因主要是因为$H_0$​ 可能不真，即$\beta_1\neq 0$​ ，即在每一个x的观测处的回归值都不相同。因此我们可以定义<strong>回归平方和</strong>为：$SS_R = \sum</em>{i=1}^n (\hat y_i-\overline y)^2$​​​ . 也就是落在直线上的点与均值的平方和</li>
<li>引起$y<em>i$​​​ 不同还可能因为误差，因此在得到回归值之后，y的观测值与回归值之间还有差异。因此可以定义<strong>残差平方和</strong>为：$SS_E = \sum</em>{i=1}^n (y_i-\hat y_i)^2$​ </li>
</ul>
<p>那么，我们可以在一元线性回归场合下的平方和分解式：</p>
<script type="math/tex; mode=display">
\sum_{i=1}^n(y_i-\overline y)^2 = \sum_{i=1}^n(y_i-\hat y_i+\hat y_i-\overline y)^2\\
=\sum_{i=1}^n(y_i-\hat y_i)^2+\sum_{i=1}^n(\hat y_i-\overline y)^2\\</script><p>我们发现，其交叉项是0</p>
<p>最后这个式子就代表： $SS_T = SS_R+SS_E$ </p>
<h4 id="定理2"><a href="#定理2" class="headerlink" title="定理2"></a>定理2</h4><p>设 $y_i = \beta_0+\beta_1x_i+\varepsilon_i$</p>
<p>其中， $\varepsilon_i,\cdots,\varepsilon_n$ 相互独立，且：</p>
<script type="math/tex; mode=display">
E(\varepsilon_i)= 0,\text{Var} (\varepsilon_i) = \sigma^2 ,i=1,2\cdots,n</script><p>我们有：</p>
<script type="math/tex; mode=display">
E(SS_R) = \sigma^2+\beta_1^2l_{xx}\\
E(SS_E) = (n-2)\sigma^2</script><h5 id="证明-1"><a href="#证明-1" class="headerlink" title="证明"></a>证明</h5><ul>
<li>我们首先来关注$SS_R$​</li>
</ul>
<p>它可以看做是有线性回归模型下的估计($\hat y$​) 与无线性回归模型下的估计($\overline y$​)的差的平方和</p>
<p>在最小二乘估计中我们得到了 $\hat\beta_0 = \overline y -\hat\beta_1\overline x $​,从中可以获得$\beta$关于 $\overline y$ 的式子</p>
<script type="math/tex; mode=display">
SS_R = \sum_{i=1}^n(\hat y_i-\overline y) = \sum_{i=1}^n((\hat\beta_0+\hat\beta_1 x_i)-(\hat\beta_0+\hat\beta_1\overline x))^2=\hat\beta_1^2l_{xx}</script><p>然后我们对 $SS_R$​求期望，这里面$\hat \beta_1$​是随机变量，这里假定x是固定的变量。运用 $Var(x)=(E(X))^2-E(X^2)$​ 可得</p>
<script type="math/tex; mode=display">
E(SS_R) =E(\hat\beta^2_1)l_{xx} =(Var(\hat\beta_1)+(E(\hat\beta_1))^2)l_{xx}\\</script><p>又因为在定理1中证明了$E(\hat\beta_1)$​是无偏的，$E(\hat\beta_1)=\beta_1$​</p>
<p>因此</p>
<script type="math/tex; mode=display">
=(\frac{\sigma^2}{l_{xx}}+\beta_1^2)l_{xx}\\
=\sigma^2+\beta_1^2l_{xx}</script><ul>
<li>然后来关注$SS_E$​</li>
</ul>
<script type="math/tex; mode=display">
SS_E = \sum_{i=1}^n(y_i-\hat y_i)^2 = \sum_{i=1}^n(\beta_0+\beta_1 x_i+\epsilon_i-\hat\beta_0-\hat\beta_1 x_i)^2\\
=\sum_{i=1}^n((\beta_0-\hat\beta_0)+(\beta_1-\hat\beta_1)x_i+\varepsilon_i)^2\\
=\sum_{i=1}^n((\beta_0-\hat\beta_0)^2+(\beta_1-\hat\beta_1)^2x_i^2+\varepsilon_i^2+2(\beta_0-\hat\beta_0)(\beta_1-\hat\beta_1)+2(\beta_0-\hat\beta_0)\varepsilon_i+2(\beta_1-\hat\beta_1)x_i\varepsilon_i)</script><blockquote>
<p> 我们可以把 $\sum_{i=1}^nE(\beta_0-\hat\beta_0)^2$​ 看做是n倍的$Var(\hat\beta_0)$​​  因为 $\hat\beta_0$是$\beta$的无偏估计，因此$\beta$可以看做是$E(\beta_0)$​</p>
<p>同理，$\sum<em>{i=1}^nE(\beta_1-\hat\beta_1)^2x_i^2=Var(\hat\beta_1)\sum</em>{i=1}^n x_i^2$​ </p>
<p>$2E(\sum_{i=1}^n(\beta_0-\hat\beta_0)(\beta_1-\hat\beta_1))=2nE(\beta_0-\hat\beta_0)(\beta_1-\hat\beta_1) = 2nCov(\hat\beta_1,\hat\beta_0)$​</p>
<p>又因为$\beta_0,\varepsilon_i$是独立的，因此：$E(\beta_0\varepsilon_i)=E(\beta_0)E(\varepsilon_i) = 0$​</p>
</blockquote>
<p>因此，</p>
<script type="math/tex; mode=display">
\begin{align}
E(SS_E) = &nVar(\hat\beta_0)+Var(\hat\beta_1)\sum_{i=1}^nx_i^2+nVar(\varepsilon_i)+2n\text{Cov}(\hat\beta_1,\hat\beta_0) \\
&-2\sum_{i=1}^nE(\hat\beta_0\varepsilon_i)-2\sum_{i=1}^nx_iE(\hat\beta_1\varepsilon_i)
\end{align}</script><p>在这个式子中，我们已知的是$nVar(\hat\beta_0),Var(\hat\beta_1),Var(\varepsilon_i),2nCov(\hat\beta_1,\hat\beta_0)$ 因此我们现在要算 $E(\hat\beta_0\varepsilon_i),E(\hat\beta_1\varepsilon_i)$​</p>
<p>首先我们要把$\hat\beta_0,\hat\beta_1$​​ 写成是$y_1,\cdots,y_n$的线性组合</p>
<script type="math/tex; mode=display">
\hat\beta_0 = \sum_i (\frac{1}{n}-\frac{(x_i-\overline x)\overline x}{l_{xx}})y_i\\
\hat\beta_1 = \sum_i \frac{(x_i-\overline x)}{l_{xx}}y_i</script><ul>
<li>对于 $E(\hat\beta_0\varepsilon_i)$,我们知道$y_i$之间是独立的 </li>
</ul>
<script type="math/tex; mode=display">
E(\hat\beta_0\varepsilon_i) =E(\varepsilon_i\sum_{j}(\frac{1}{n}-\frac{(x_j-\overline x)\overline x}{l_{xx}})y_i)\\

=E(\varepsilon_i\sum_{j}(\frac{1}{n}-\frac{(x_j-\overline x)\overline x}{l_{xx}})(\beta_0+\beta_1x_j+\varepsilon_j))\\</script><p>因此当 $j\neq i$ 的时候，期望可以写成 $E(\varepsilon_i)\cdot E(\cdots) = 0$,因此，只有当 $i=j$ 的时候才需要被留下：</p>
<script type="math/tex; mode=display">
\begin{align}
&E(\varepsilon_i\sum_{j}(\frac{1}{n}-\frac{(x_j-\overline x)\overline x}{l_{xx}})(\beta_0+\beta_1x_i+\varepsilon_i))\\
&= E(\varepsilon^2_i(\frac{1}{n}-\frac{(x_i-\overline x)\overline x}{l_{xx}}))\\
&=(\frac{1}{n}-\frac{(x_i-\overline x)\overline x}{l_{xx}})\sigma^2
\end{align}</script><ul>
<li>对于$E(\hat\beta_1\varepsilon_i)$,同样用类似的思路证明：</li>
</ul>
<script type="math/tex; mode=display">
\begin{align}
E(\hat\beta_1\varepsilon_i) &= E(\varepsilon_i\sum_{j}\frac{x_j-\overline x}{l_{xx}}y_j)\\
&=E(\varepsilon_i\sum_{j}\frac{(x_j-\overline x)}{l_{xx}}(\beta_0+\beta_1x_j+\varepsilon_i))\\
&=\frac{(x_i-\overline x)}{l_{xx}}\sigma^2
\end{align}</script><p>因此：</p>
<script type="math/tex; mode=display">
\sum_{i=1}^nE(\hat\beta_0\varepsilon_i) = \sum_{i=1}^n(\frac{1}{n}-\frac{(x_i-\overline x)\overline x}{l_{xx}})\sigma^2= \sigma^2\\
\sum_{i=1}^n x_iE(\hat\beta_1\varepsilon_i) = \sum_{i=1}^n x_i\frac{(x_i-\overline x)}{l_{xx}}\sigma^2</script><p>已知 $l<em>{xx}=\sum</em>{i=1}^n(x<em>i-\overline x)^2 = \sum</em>{i=1}^n x<em>i^2-2\sum</em>{i=1}^nx<em>i\overline x+n(\overline x)^2=\sum</em>{i=1}^n x_i^2-n\overline x$​.  因此原式 $ = \sigma^2$</p>
<p>综上，</p>
<script type="math/tex; mode=display">
\begin{align}
E(SS_E ) &= n(\frac{1}{n}+\frac{\overline x^2}{l_{xx}})\sigma^2+\frac{\sigma^2}{l_{xx}}\sum_ix_i^2+n\sigma^2-2n\frac{\overline x^2}{l_{xx}}\sigma^2-2\sigma^2-2\sigma^2\\
&=\sigma^2(1+\frac{\sum x_i^2}{l_{xx}}-\frac{n\overline x^2}{l_{xx}}+n-4)\\
&=(n-2)\sigma^2
\end{align}</script><h4 id="定理3"><a href="#定理3" class="headerlink" title="定理3"></a>定理3</h4><p>设 $y_1,\cdots,y_n$ 相互独立，且：</p>
<script type="math/tex; mode=display">
y_i\sim N(\beta_0+\beta_1x_i,\sigma^2),i = 1,2\cdots,n\\</script><p>则有：</p>
<ul>
<li>$SS_E/\sigma^2\sim\mathcal X^2(n-2)$</li>
<li>若$H_0$ 成立，则有 $SS_R/\sigma^2\sim \mathcal X^2(1)$</li>
<li>$SS_R$​​与 $SS_E$​​，$\overline y$​​ 独立 </li>
</ul>
<p>这三点在回归里面是非常核心的，其重要性在于其构造出了F检验。</p>
<h5 id="证明-1"><a href="#证明-1" class="headerlink" title="证明-1"></a>证明-1</h5><p>首先，我们需要构造一个<strong>正交矩阵A</strong>，形如：</p>
<p><img src="/2021/10/11/%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/2.png" alt="1" style="zoom:67%;"></p>
<p>根据正交矩阵的性质$AA’=I$​, 则A需要满足：</p>
<script type="math/tex; mode=display">
\sum_k  a_{i,k}a_{j,k} =0,1\leq i<j\leq n-2\\
\frac{1}{\sqrt n} \sum_j a_{i,j} = 0\\
\sum_j a_{i,j}\frac{x_j-\overline x}{\sqrt{l_{xx}}}\\
\sum_{j}(a_{i,j})^2 = 1</script><blockquote>
<p>第一个条件是说，如果i和j不相等的话，那么第i行和第j行对应元素的乘积的和是要等于0的</p>
<p>第二个条件是：前面n-2行与倒数第二行的对应元素的乘积的和要等于0，因为不再对角线上</p>
<p>第三个条件是：前面n-2行与最后一行的对应元素的乘积的和要等于0，因为也不再对角线上</p>
<p>第四个条件是: 对角线上要满足都是1，因此每一行各个元素的平方和为1</p>
</blockquote>
<p>在这个矩阵中，前面 n-2行是不确定的，因此有 n(n-2)的未知数。然后第一个条件有$\pmatrix{n-2\2}$​个方程，后面三个条件每一个都有$n-2$​个方程，因此一共有 $\frac{(n-2)(n-3)}{2}$个方程。​</p>
<p>因此，只要 $n\geq 3$​ ，未知参数个数不少于方程个数，因此，正交矩阵A一定是存在的</p>
<p>接下来，我们令 $z=Ay$, 其中 $z=(z_1,z_2\cdots,z_n)’$ 满足</p>
<script type="math/tex; mode=display">
z_i = \sum_ja_{ij}y_j, ~~i = 1,\cdots,n-2\\
z_{n-1} = \frac{\sum_{j}(x_j-\overline x)y_j}{\sqrt{l_{xx}}} = \frac{\sum_{j} (x_j-\overline x)(y_j-\overline y)}{\sqrt{l_{xx}}} = \frac{l_{xy}}{\sqrt{l_{xx}}} = \sqrt{l_{xx}} \cdot  \frac{l_{xy}}{l_{xx }} = \sqrt {l_{xx }}\hat\beta_1\\
z_n = \frac{1}{\sqrt n}\sum_j y_j = \sqrt n \overline y</script><blockquote>
<p>第二个式子是因为：$l<em>{xy} = \sum</em>{i=1}^n x_iy_i-n\overline x\cdot \overline y$</p>
<p>又： $\sum<em>{i=1}^n (x_i-\overline x)y_i = \sum</em>{i=1}^nx<em>iy_i-\sum</em>{i=1}^n y<em>i\overline x= \sum</em>{i=1}^n x_iy_i-n\overline y\cdot\overline x$ </p>
<p>两者是等价的</p>
</blockquote>
<p>我们看到z也是正态随机变量的线性组合，因此可以很方便的记录其均值和方差：</p>
<script type="math/tex; mode=display">
E(z_i) = E(\sum_j a_{ij}y_j) = \sum_j a_{ij}(\beta_0+\beta_1x_j)\\
=\beta_0\sum_j a_{ij} +\beta_1\sum_ja_{ij}x_j = 0,i=1,\cdots,n\\
E(z_{n-1}) = \sqrt{l_{xx}}\beta_1\\
E(z_n) = \sqrt n (\beta_0+\beta_1\hat x)\\
Var(z) = Var(Ay) = \bold{A}Var(y)\bold{A}' = \bold{A}\sigma^2\bold{I_n}\bold{A'} = \sigma^2\bold{I_n}</script><blockquote>
<p>$\sum<em>ja</em>{ij}=0$​,因此 第一个式子等于0</p>
</blockquote>
<p>由上面的结论，可以得出以下结论：</p>
<ul>
<li>我们知道Z是服从正态分布的，又z的方差为对角矩阵，是不存在协方差的。因此，$z_1,z_2\cdots,z_n$是相互独立的。</li>
<li>前n-2个分量$z_1,z_2\cdots,z_n$是独立同分布的，且分布为$N(0,\sigma^2)$</li>
<li>$z<em>{n-1}$的分布为$N(\sqrt{l</em>{xx}}\beta_1,\sigma^2 )$</li>
<li>$z_n$ 的分布为$N(\sqrt n(\beta_0+\beta_1\overline x),\sigma^2)$</li>
</ul>
<p>最后，我们要用$z$去表示 $SS_T,SS_R,SS_E$</p>
<script type="math/tex; mode=display">
\sum_{i=1}^n z_i^2 = z'z = \bold{y'A'Ay} = \bold{y'y} = \sum_{i}y_i^2 =l_{yy}+n\overline y^2= SS_T +n\overline y^2\\
z_{n-1} = \sqrt{l_{xx}}\hat\beta_1 = \sqrt {SS_R}\\
z_n = \sqrt n\overline y</script><p>然后我们可以整理为：</p>
<script type="math/tex; mode=display">
SS_T+n\overline y^2 =\sum_{i=1}^n z_i^2 =  \sum_{i=1}^{n-2} z_i^2+SS_R+n\overline y^2\\</script><p>即 $SS<em>T = \sum</em>{i=1}^{n-2}z_i^2+SS_R$</p>
<p>因为 $SS_T = SS_R+SS_E$,所以 $SS_E$的分布就得到了：是一些列正态随机变量的平方和，是一个卡方分布</p>
<script type="math/tex; mode=display">
SS_E = \sum_{i=1}^{n-2}z_i^2\sim \mathcal X^2(n-2)</script><h5 id="证明-2"><a href="#证明-2" class="headerlink" title="证明-2"></a>证明-2</h5><p>若$H_0$成立,则$\beta_1= 0$, 可以得到：</p>
<script type="math/tex; mode=display">
\sqrt {SS_R} = z_{n-1}\sim N(0,\sigma^2)</script><p>所以，变换得到：</p>
<script type="math/tex; mode=display">
\frac{SS_R}{\sigma^2} = (\frac{z_{n-1}}{\sigma})^2\sim \mathcal X^2(1)</script><h5 id="证明-3"><a href="#证明-3" class="headerlink" title="证明-3"></a>证明-3</h5><p>因为$SS<em>E$与前 $n-2$个$z_i$有关，$SS_R$仅与 $z</em>{n-1}$有关，$\overline y$仅与$z_n$有关，因此$SS_R$和 $SS_E,\overline y$相互独立</p>
<p>因为$\hat\beta_1$ 仅与$SS_R$有关，所以$\hat\beta_1$与$SS_E,\overline y$​相互独立</p>
<h4 id="检验统计量"><a href="#检验统计量" class="headerlink" title="检验统计量"></a>检验统计量</h4><p>现在我们来进行假设检验：</p>
<p>构造形如</p>
<script type="math/tex; mode=display">
F_0 = \frac{SS_R}{SS_E/(n-2)}</script><p>的检验统计量来检验。那么，在$\beta_1 = 0$时，$F\sim F(1,n-2)$，对于给定的显著性水平$\alpha$,其拒绝域为：</p>
<script type="math/tex; mode=display">
F_0\geq F_{1-\alpha}(1,n-2)</script><p>即大于临界值，SSR就越大，说明$\beta_1$是起作用的，我们就拒绝原假设</p>
<p>这就是F检验</p>
<p><img src="/2021/10/11/%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/3.png" style="zoom:67%;"></p>
<h3 id="t检验"><a href="#t检验" class="headerlink" title="t检验"></a>t检验</h3><p>如果说F检验的方法的内核是方差分析，那么t检验的方法的内核就是参数估计了——我通过去找到点估计，找到枢轴量，构造检验统计量然后去做检验。</p>
<h4 id="检验统计量-1"><a href="#检验统计量-1" class="headerlink" title="检验统计量"></a>检验统计量</h4><p><img src="/2021/10/11/%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/6.png" style="zoom:67%;"></p>
<h3 id="相关系数的检验"><a href="#相关系数的检验" class="headerlink" title="相关系数的检验"></a>相关系数的检验</h3><h4 id="概述-1"><a href="#概述-1" class="headerlink" title="概述"></a>概述</h4><p>现在我们来聊第三个问题，一个模型中$\beta_1$ 如果不起作用的话，就说明x，y之间是没有线性关系的。</p>
<p>那么，由于一元线性回归方差可以反映出两个随机变量x与y间的相关关系时，它的显著性检验还可以通过对二维总体相关系数$\rho$​的检验进行。</p>
<p>假设为：</p>
<script type="math/tex; mode=display">
H_0:\rho = 0~~~vs~~~H_1:\rho\neq 0</script><p>如果样本相关系数很小，很有理由认为总体均值为0，接受原假设，反之，我们拒绝原假设。</p>
<p>我们将样本相关系数作为检验统计量：</p>
<script type="math/tex; mode=display">
r = \frac{\sum_{i=1}^n(x_i-\overline x)(y_i-\overline y)}{\sqrt{\sum_{i=1}^n(x_i-\overline x)^2\sum_{i=1}^n(y_i-\overline y)^2}} = \frac{l_{xy}}{\sqrt{l_{xx}l_{yy}}}</script><p>下面我们用具体的图来理解样本相关系数的大小：</p>
<p><img src="/2021/10/11/%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/4.png" style="zoom: 50%;"></p>
<p>对于a、b两张图，直线是确定的，所有点都在直线上面。因此我们算出来的样本相关系数的绝对值算出来一定是1</p>
<p>对于c，我们发现这个点的分布基本是随机地，散乱的，此时其相关系数接近于0</p>
<p>对于d，我们发现点复合某个函数，并不是线性的，但是其相关系数也不等于0</p>
<p>对于e、f，状态是比较理想的。</p>
<h4 id="检验统计量-2"><a href="#检验统计量-2" class="headerlink" title="检验统计量"></a>检验统计量</h4><p>当$H_0$为真时，$|r|$应该比较小；当 $|r|$​  比较大的时候，应该拒绝原假设</p>
<p>因此，拒绝域为${|r|\geq c}$ ，其中，临界值c可以由$H_0$成立时的样本相关系数的分布确定，该分布与自由度$n-2$有关。</p>
<p>对给定的显著性水平$\alpha$ ,由$P(W) = P(|r|\geq c)=\alpha$ 可知，临界值c应该是$H<em>0:\rho = 0$成立下r的分布的$1-\alpha/2$ 分位数，故我们记为：$c = r</em>{1-\alpha/2}(n-2)$</p>
<p>那么，这个临界值的式子给出了，怎么获得呢? 因此我们要考虑三个检验之间的关系</p>
<h2 id="三种检验之间的关系"><a href="#三种检验之间的关系" class="headerlink" title="三种检验之间的关系"></a>三种检验之间的关系</h2><h3 id="t检验与F检验统计量的关系"><a href="#t检验与F检验统计量的关系" class="headerlink" title="t检验与F检验统计量的关系"></a>t检验与F检验统计量的关系</h3><script type="math/tex; mode=display">
t_0^2=(\frac{\hat\beta_1}{\hat\sigma/\sqrt{l_{xx}}})^2 = \frac{\hat\beta_1^2l_{xx}}{\sqrt{SS_E/(n-2)}} = \frac{SS_R}{SS_E/(n-2)} = F_0</script><p>其中，第三个等式成立是因为回归平方和$SS_R$与$\hat\beta_1$之间存在如下关系：</p>
<script type="math/tex; mode=display">
SS_R = \sum_{i=1}^n(\hat y_i-\overline y)^2 = \sum_{i=1}^n(\hat\beta_0+\hat\beta_1x_i-\overline y)^2\\
=\sum_{i=1}^n[\overline y+\hat\beta_1(x_i-\overline x)-\overline y]^2 \\
=\sum_{i=1}^n[\hat\beta_1(x_i-\overline x)]^2= \beta_1^2l_{xx}</script><p>因此，实际上F检验和t检验是等价的。</p>
<h3 id="F检验统计量与r的关系"><a href="#F检验统计量与r的关系" class="headerlink" title="F检验统计量与r的关系"></a>F检验统计量与r的关系</h3><script type="math/tex; mode=display">
r^2 = (\hat\beta_1\sqrt{\frac{l_{xx}}{l_{yy}}})^2 = \hat\beta_1^2\frac{l_{xx}}{l_{yy}} = \frac{SS_R}{SS_T} = \frac{SS_R}{SS_R+SS_E}</script><p>分子分母同除以 $SS_E/(n-2)$可以得到:</p>
<script type="math/tex; mode=display">
=\frac{SS_R/(SS_E/(n-2))}{SS_R/(SS_E/(n-2))+n-2}=\frac{F_0}{F_0+(n-2)}</script><p>这表明了 $|r|$ 是 $F<em>0$ 的严格单调增函数，因此可以从F分布的$1-\alpha$ 分位数 $F</em>{1-\alpha}(1,n-2)$ 得到相关系数检验 所需要确定的临界值 $r_{1-\alpha/2}(n-2)$, 即</p>
<script type="math/tex; mode=display">
r_{1-\alpha/2}(n-2) = \sqrt{\frac{F_{1-\alpha}(1,n-2)}{F_{1-\alpha}(1,n-2)+(n-2)}}</script><p>因此，$r^2$ 会常常作为回归分析中一项重要的指标。我们定义<strong>样本决定系数</strong>为<strong>回归平方和</strong>与<strong>总偏差平方和</strong>之比，即：</p>
<script type="math/tex; mode=display">
r^2 = \frac{SS_R}{SS_T}</script><p>样本决定系数$r^2$是一个回归直线与样本观测值拟合优度的相对指标，反应因变量的波动中能用自变量解释的比例。$r^2$ 的取值在0到1之前。 $r^2$​越接近1，拟合度越好</p>
<blockquote>
<p>通常来说我们更看中$R^2$​ 其定义是 $\frac{SS_R}{SS_T}$ ，在一元线性回归中，刚好其等于样本方差的平方即 $R^2 =r^2$​</p>
</blockquote>
<h3 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h3><ul>
<li>三种检验方法在一元线性回归模型下是等价的</li>
<li>但在多元线性回归场合，经推广F检验仍然可用，另两个检验就无法使用了</li>
<li>如果无法拒绝原假设，则可以认为回归方程不是显著的，导致这种情况可能有如下几种原因<ul>
<li>误差与正态假设严重偏离</li>
<li>Y与X无关</li>
<li>Y与X虽然相关，但不是线性关系</li>
<li>Y与X以外的因素有更密切的关系</li>
</ul>
</li>
</ul>
<h2 id="估计与预测"><a href="#估计与预测" class="headerlink" title="估计与预测"></a>估计与预测</h2><p>之前我们所说的都是建模，然后确定模型是否有效。现在我们终于要来做预测了。那么，我们对什么来做预测呢？——随机变量。</p>
<p>当$x=x_0$时，我们关心的是 $y_0 = \beta_0+\beta_1x_0+\epsilon_0$ </p>
<p>注意到，$y_0$是本身一个随机变量。 对于一个随机变量，在掌握了单个数值信息的情况下是很难刻画y的分布的，因此我们可以构造一个区间，使得$y_0$ 落在区间的概率为$1-\alpha$,即确定一个常数$\var$ 使得$P(|y_0-\hat y_0|\leq \var) = 1-\alpha$ ，称区间$[\hat y_0-\var,\hat y_0+\var]$ 为$y_0$的概率为$1-\alpha$ 的预测区间，这是一个<strong>预测问题</strong></p>
<h3 id="关于-E-y-0-​的估计"><a href="#关于-E-y-0-​的估计" class="headerlink" title="关于$E(y_0)$​的估计"></a>关于$E(y_0)$​的估计</h3><h4 id="点估计"><a href="#点估计" class="headerlink" title="点估计"></a>点估计</h4><p>我们只能通过期望。在$x=x_0$时，我们需要考虑$E(y_0) = \beta_0+\beta_1x_0$​ 一个直观的估计为：</p>
<script type="math/tex; mode=display">
\hat E(y_0) = \hat\beta_0+\hat\beta_1x_0</script><p>通常记为$\hat y_0$​ , 表示在 $x=x_0$ 时响应变量的估计值</p>
<h4 id="定理-4"><a href="#定理-4" class="headerlink" title="定理 4"></a>定理 4</h4><p>如果 $y_1,y_2\cdots,y_n$ 是相互独立的且$y_i$ 是正态分布随机变量，即 $y_i\sim N(\beta_0+\beta_1x_i,\sigma^2)$,那么，对给定的$x_0$</p>
<script type="math/tex; mode=display">
\hat y_0 = \hat\beta_0+\hat\beta_1x_0 \sim N(\beta_0+\beta_1x_0,(\frac{1}{n}+\frac{(x_0-\overline x)^2}{l_{xx}})\sigma^2)</script><h5 id="证明-2"><a href="#证明-2" class="headerlink" title="证明"></a>证明</h5><p>根据定理1可得：</p>
<script type="math/tex; mode=display">
\hat\beta_0\sim N(\beta_0,(\frac{1}{n}+\frac{\overline x^2}{l_{xx}})\sigma^2)\\
\hat\beta_1\sim N(\beta_1,\frac{\sigma^2}{l_{xx}})</script><p>因此在给定$x_0$的时候，$\hat y_0$ 也是 $y_1\cdots,y_n$的线性组合，因此$\hat y_0$ 也服从正态分布。其均值和方差为：</p>
<script type="math/tex; mode=display">
\begin{align}
E(\hat y_0)&= E(\hat\beta_0)+E(\hat\beta_1)x_0 = \beta_0+\beta_1x_0\\
Var(\hat y_0)& = Var(\hat\beta_0+\hat\beta_1x_0)\\
&=Var(\hat\beta_0)+Var(\hat\beta_1)x_0^2+2Cov(\hat\beta_0,\hat\beta_1)x_0\\
&=(\frac{1}{n}+\frac{\overline x^2}{l_{xx}})\sigma^2+\frac{x_0^2\sigma^2}{l_{xx}}-\frac{2\overline xx_0}{l_{xx}}\sigma^2\\
&=(\frac{1}{n}+\frac{(x_0-\overline x)^2}{l_{xx}})\sigma^2
\end{align}</script><h4 id="区间估计"><a href="#区间估计" class="headerlink" title="区间估计"></a>区间估计</h4><p>已知$\hat y_0$的分布为</p>
<script type="math/tex; mode=display">
\hat y_0 = \hat\beta_0+\hat\beta_1x_0 \sim N(\beta_0+\beta_1x_0,(\frac{1}{n}+\frac{(x_0-\overline x)^2}{l_{xx}})\sigma^2)</script><p>现在要构造枢轴量，其中，$\sigma^2$ 可以用其估计代替</p>
<p>于是，我们有：</p>
<script type="math/tex; mode=display">
\frac{(\hat y_0-E(y_0))/\sqrt{\frac{1}{n}+\frac{x_0-\overline x}{l_{xx}}\sigma^2}}{\sqrt{\frac{SS_E}{\sigma^2}/(n-2)}} =\frac{\hat y_0-E(y_0)}{\hat\sigma\sqrt{\frac{1}{n}+\frac{(x_0-\overline x)^2}{l_{xx}}}}\sim t(n-2)</script><p>因此，$E(y_0)$的置信水平为$1-\alpha$的置信区间为：</p>
<script type="math/tex; mode=display">
[\hat y_0-\var,\hat y_0+\var]</script><p>其中，</p>
<script type="math/tex; mode=display">
\var = t_{1-\alpha/2}(n-2)\hat\sigma\sqrt{\frac{1}{n}+\frac{(x_0-\overline x)^2}{l_{xx}}}</script><h3 id="关于-y-0-​​-的预测"><a href="#关于-y-0-​​-的预测" class="headerlink" title="关于$y_0 $​​ 的预测"></a>关于$y_0 $​​ 的预测</h3><h4 id="点预测"><a href="#点预测" class="headerlink" title="点预测"></a>点预测</h4><p>在预测$y_0$的时候，我们如果考虑点预测，那么通常我们还是取这个随机变量的均值，于是$y_0$的点预测也是$\hat y_0$</p>
<p>但是，由于$y_0$是一个连续随机变量，恰好取到一个点的概率为0，因此在实际应用中，对$y_0$进行区间预测更为合理。</p>
<h4 id="区间预测"><a href="#区间预测" class="headerlink" title="区间预测"></a>区间预测</h4><p>事实上 $y_0 = E(y_0)+\varepsilon_0$ ，因为通常假定$\varepsilon_0\sim N(0,\sigma^2)$ ，所以$y_0$的最有可能的取值仍然是$\hat y_0$ </p>
<p>因此，我们可以使用一个以$\hat y_0$为中心的区间：</p>
<script type="math/tex; mode=display">
[\hat y_0-\var,\hat y_0+\var]</script><p>作为$y_0$的取值范围，如何确定$\var$的值是需要进一步讨论的。</p>
<p>和$E(y_0)$的去测过程一样，我们要构造一个枢轴量</p>
<p>一方面，我们知道：</p>
<script type="math/tex; mode=display">
y_0\sim N(\beta_0+\beta_1x_0,\sigma^2)</script><p>其点预测我们之前已经推出：</p>
<script type="math/tex; mode=display">
\hat y_0 = \hat\beta_0+\hat\beta_1x_0 \sim N(\beta_0+\beta_1x_0,(\frac{1}{n}+\frac{(x_0-\overline x)^2}{l_{xx}})\sigma^2)</script><p>又因为 $y_0$ 与$\hat y_0$ 独立，所以：</p>
<script type="math/tex; mode=display">
y_0-\hat y_0 \sim N(0,(1+\frac{1}{n}+\frac{(x_0-\overline x)^2}{l_{xx}})\sigma^2)</script><p>另一方面，因为 ${(n-2)\hat\sigma^2}/{\sigma^2}\sim \mathcal{X^2}(n-2)$​​，而且$y_0,\hat y_0,\hat\sigma^2$相互独立，所以有：</p>
<script type="math/tex; mode=display">
\frac{y_0-\hat y_0}{\hat\sigma\sqrt{1+\frac{1}{n}+\frac{(x_0-\overline x)^2}{l_{xx}}}}\sim t(n-2)</script><p>因此，预测区间为：</p>
<script type="math/tex; mode=display">
[\hat y_0-\var,\hat y_0+\var]</script><p>其中，$\var$ 为：</p>
<script type="math/tex; mode=display">
\var = \var(x_0) = t_{1-\alpha/2}(n-2)\hat\sigma\sqrt{1+\frac{1}{n}+\frac{(x_0-\overline x)^2}{l_{xx}}}</script><p>我们发现，估计区间中的$\var$和预测区间中的$\var$ 是不一样的，预测区间中的$\var$会更加宽一点。因此我们发现，当预测的时候，波动更大，因为我们会引入新样本。</p>
<p><img src="/2021/10/11/%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/5.png"></p>
<p>观察上图，我们发现预测区间呈现一个喇叭口的形状，越接近$\overline x$ 越窄，越两变越宽。说明数据波动的越大，会导致$\sigma$的估计越大，最终导致$\var$越大。</p>
<p>此外我们还要知道，这个区间是和样本量有关系的，如果样本量越大，$n$越大，因此区间会越窄</p>
<p>此外，如果我们要预测的新样本和训练集的均值离得非常远，那么预测区间就越大，预测效果就越差。在一元线性回归中，表现为离均值$\overline x$越远预测效果越差。</p>

      
    </div>
    
    
    
    <div>
      
        <div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">-------------本文结束，感谢您的阅读-------------</div>
    
</div>

      
    </div>
    

    

    
      <div>
        <ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>Post author:</strong>
    Jason
  </li>
  <li class="post-copyright-link">
    <strong>Post link:</strong>
    <a href="https://jasonxqh.github.io/2021/10/11/%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/" title="一元线性回归">https://jasonxqh.github.io/2021/10/11/%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</a>
  </li>
  <li class="post-copyright-license">
    <strong>Copyright Notice: </strong>
    All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0</a> unless stating additionally.
  </li>
</ul>

      </div>
    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/%E7%BB%9F%E8%AE%A1%E6%96%B9%E6%B3%95/" rel="tag"><i class="fa fa-tag"></i> 统计方法</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2021/10/07/%E5%A4%9A%E9%87%8D%E6%AF%94%E8%BE%83%E5%92%8C%E5%8F%8C%E5%9B%A0%E5%AD%90%E6%96%B9%E5%B7%AE%E5%88%86%E6%9E%90/" rel="next" title="多重比较和双因子方差分析">
                <i class="fa fa-chevron-left"></i> 多重比较和双因子方差分析
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2021/10/16/Nodejs%E5%9F%BA%E7%A1%805%E6%B5%8B%E8%AF%95/" rel="prev" title="Nodejs基础5测试">
                Nodejs基础5测试 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="lv-container" data-id="city" data-uid="MTAyMC80OTgyMC8yNjMxMQ=="></div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Jason</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives%7C%7C%20archive">
              
                  <span class="site-state-item-count">429</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">11</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">60</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/JasonXQH" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:10195501423@stu.ecnu.edu.cn" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-block">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                Links
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="https://yanghong.tech/" title="友链:杨弘的博客" target="_blank">友链:杨弘的博客</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://ankate.github.io/" title="友链:赵奕轲的博客" target="_blank">友链:赵奕轲的博客</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://github.com/JasonXQH/JasonXQH.github.io" title="Like it, STAR ME" target="_blank">Like it, STAR ME</a>
                  </li>
                
              </ul>
            </div>
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#线性回归的背景"><span class="nav-number">1.</span> <span class="nav-text">线性回归的背景</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#一元线性回归"><span class="nav-number">2.</span> <span class="nav-text">一元线性回归</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#概述"><span class="nav-number">2.1.</span> <span class="nav-text">概述</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#模型版"><span class="nav-number">2.1.1.</span> <span class="nav-text">模型版</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#数据版"><span class="nav-number">2.1.2.</span> <span class="nav-text">数据版</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#任务：预测和参数估计"><span class="nav-number">2.2.</span> <span class="nav-text">任务：预测和参数估计</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#最小二乘估计"><span class="nav-number">2.2.1.</span> <span class="nav-text">最小二乘估计</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#最大似然估计"><span class="nav-number">2.2.2.</span> <span class="nav-text">最大似然估计</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#分布假定"><span class="nav-number">2.2.2.1.</span> <span class="nav-text">分布假定</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#求解-sigma-2"><span class="nav-number">2.2.2.2.</span> <span class="nav-text">求解$\sigma^2$</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#定理1"><span class="nav-number">2.2.2.3.</span> <span class="nav-text">定理1</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#证明"><span class="nav-number">2.2.2.4.</span> <span class="nav-text">证明</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#步骤1：用-yi-线性表出-beta-0-beta-1"><span class="nav-number">2.2.2.4.1.</span> <span class="nav-text">步骤1：用$yi$线性表出$\beta{0},\beta_1$</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#步骤2：考虑期望和方差"><span class="nav-number">2.2.2.4.2.</span> <span class="nav-text">步骤2：考虑期望和方差</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#第三步：求协方差"><span class="nav-number">2.2.2.4.3.</span> <span class="nav-text">第三步：求协方差</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#第四步：给出推论"><span class="nav-number">2.2.2.4.4.</span> <span class="nav-text">第四步：给出推论</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#tips"><span class="nav-number">2.2.2.5.</span> <span class="nav-text">tips</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#回归方程的显著性检验"><span class="nav-number">2.3.</span> <span class="nav-text">回归方程的显著性检验</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#F检验"><span class="nav-number">2.3.1.</span> <span class="nav-text">F检验</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#定义"><span class="nav-number">2.3.1.1.</span> <span class="nav-text">定义</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#定理2"><span class="nav-number">2.3.1.2.</span> <span class="nav-text">定理2</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#证明-1"><span class="nav-number">2.3.1.2.1.</span> <span class="nav-text">证明</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#定理3"><span class="nav-number">2.3.1.3.</span> <span class="nav-text">定理3</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#证明-1"><span class="nav-number">2.3.1.3.1.</span> <span class="nav-text">证明-1</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#证明-2"><span class="nav-number">2.3.1.3.2.</span> <span class="nav-text">证明-2</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#证明-3"><span class="nav-number">2.3.1.3.3.</span> <span class="nav-text">证明-3</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#检验统计量"><span class="nav-number">2.3.1.4.</span> <span class="nav-text">检验统计量</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#t检验"><span class="nav-number">2.3.2.</span> <span class="nav-text">t检验</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#检验统计量-1"><span class="nav-number">2.3.2.1.</span> <span class="nav-text">检验统计量</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#相关系数的检验"><span class="nav-number">2.3.3.</span> <span class="nav-text">相关系数的检验</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#概述-1"><span class="nav-number">2.3.3.1.</span> <span class="nav-text">概述</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#检验统计量-2"><span class="nav-number">2.3.3.2.</span> <span class="nav-text">检验统计量</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#三种检验之间的关系"><span class="nav-number">2.4.</span> <span class="nav-text">三种检验之间的关系</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#t检验与F检验统计量的关系"><span class="nav-number">2.4.1.</span> <span class="nav-text">t检验与F检验统计量的关系</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#F检验统计量与r的关系"><span class="nav-number">2.4.2.</span> <span class="nav-text">F检验统计量与r的关系</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#说明"><span class="nav-number">2.4.3.</span> <span class="nav-text">说明</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#估计与预测"><span class="nav-number">2.5.</span> <span class="nav-text">估计与预测</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#关于-E-y-0-​的估计"><span class="nav-number">2.5.1.</span> <span class="nav-text">关于$E(y_0)$​的估计</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#点估计"><span class="nav-number">2.5.1.1.</span> <span class="nav-text">点估计</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#定理-4"><span class="nav-number">2.5.1.2.</span> <span class="nav-text">定理 4</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#证明-2"><span class="nav-number">2.5.1.2.1.</span> <span class="nav-text">证明</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#区间估计"><span class="nav-number">2.5.1.3.</span> <span class="nav-text">区间估计</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#关于-y-0-​​-的预测"><span class="nav-number">2.5.2.</span> <span class="nav-text">关于$y_0 $​​ 的预测</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#点预测"><span class="nav-number">2.5.2.1.</span> <span class="nav-text">点预测</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#区间预测"><span class="nav-number">2.5.2.2.</span> <span class="nav-text">区间预测</span></a></li></ol></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      
        <div class="back-to-top">
          <i class="fa fa-arrow-up"></i>
          
            <span id="scrollpercent"><span>0</span>%</span>
          
        </div>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart" aria-hidden="true"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Jason</span>
 <!--
  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">Site words total count&#58;</span>
    
    <span title="Site words total count">1273.5k</span>
  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>



-->
        







        
      </div>
    </footer>

    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  
    <script type="text/javascript">
      (function(d, s) {
        var j, e = d.getElementsByTagName(s)[0];
        if (typeof LivereTower === 'function') { return; }
        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;
        e.parentNode.insertBefore(j, e);
      })(document, 'script');
    </script>
  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('-1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  


  

  

</body>
</html>
