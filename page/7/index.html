<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="en">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">



  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />






















<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=">


  <link rel="mask-icon" href="/images/logo.svg?v=" color="#222">














<meta property="og:type" content="website">
<meta property="og:title" content="Jason‘s Blog">
<meta property="og:url" content="https://jasonxqh.github.io/page/7/index.html">
<meta property="og:site_name" content="Jason‘s Blog">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Jason">
<meta name="twitter:card" content="summary">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '',
    sidebar: {"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},
    fancybox: false,
    tabs: ,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: 'undefined',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>







  <title>Jason‘s Blog</title>
  




<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', '[object Object]', 'auto');
  ga('send', 'pageview');
</script>





<meta name="generator" content="Hexo 4.2.0"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">
  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>
<a href="https://github.com/JasonXQH/JasonXQH.github.io" target="_blank" rel="noopener" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Jason‘s Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/%20" rel="section">
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/%20" rel="section">
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/%20" rel="section">
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/%20" rel="section">
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/%20" rel="section">
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://jasonxqh.github.io/2022/01/01/OLAP/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jason">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/%5Bobject%20Object%5D">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jason‘s Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2022/01/01/OLAP/" itemprop="url">OLAP</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2022-01-01T10:48:36+08:00">
                2022-01-01
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified&#58;</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2022-01-02T16:17:28+08:00">
                2022-01-02
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="OLAP"><a href="#OLAP" class="headerlink" title="OLAP"></a>OLAP</h1><p>参考 ：<a href="https://www.zhihu.com/question/24110442/answer/851671343" target="_blank" rel="noopener">https://www.zhihu.com/question/24110442/answer/851671343</a></p>
<p>OLTP（on-line transaction processing）翻译为联机事务处理， OLAP（On-Line Analytical Processing）翻译为联机分析处理，从字面上来看OLTP是做事务处理，OLAP是做分析处理。从对数据库操作来看，OLTP主要是对数据的增删改，OLAP是对数据的查询。 </p>
<p>这里我们在多介绍一下OLAP</p>
<h2 id="数据仓库系统"><a href="#数据仓库系统" class="headerlink" title="数据仓库系统"></a>数据仓库系统</h2><p><strong>OLAP分析的分类：ROLAP与MOLAP</strong><br>OLAP分析 分为关系型联机分析处理（<strong>ROLAP</strong>）、多维联机分析处理（<strong>MOLAP</strong>）两种，他们的设计理念以及解决场景不一样，各有优劣。</p>
<h3 id="ROLAP"><a href="#ROLAP" class="headerlink" title="ROLAP"></a>ROLAP</h3><p>以ROLAP为代表的有<strong>传统关系型数据库</strong>、<strong>MPP分布式数据库</strong>以及<strong>基于Hadoop的Spark/Impala</strong>，它们是将数据块存储在关系型数据库当中的。</p>
<ul>
<li>优点<ul>
<li>是能<strong>同时连接明细数据和汇总数据</strong>，实时根据用户提出的需求对数据进行计算后返回给用户，所以用户使用相对比较灵活，可以随意选择维度组合来进行实时计算。</li>
<li>对高维数据、超大数据集有很好的扩展性</li>
<li>技术成熟</li>
</ul>
</li>
<li>正因为采用的实时计算技术，所以ROLAP的缺点也比较明显<ul>
<li>当计算的数据量达到一定级别或并发数达到一定级别的时候，<strong>一定会出现性能问题</strong>(就好比如果领导一次性给你安排非常多的工作，你一个人是无法马上将所有事情做完答复领导的)。</li>
<li>需要构建明确的索引</li>
</ul>
</li>
</ul>
<p>以传统关系型数据库为代表的如Teradata、Oracle等，由于传统架构可扩展性较差，所以<strong>对硬件的要求非常高</strong>，当计算的数据量达到千万，亿级别时，数据库的计算就会出现延时，使得用户不能及时得到响应，更别提高并发了。</p>
<p>MPP 分布式数据库则解决了一部分可扩展性问题，对硬件设备的要求也稍稍下降了（还是有一定的硬件要求)，在支持的数据体量（GB，TB级别）上有了很大的提升。当集群有几百、上千节点时，会出现性能瓶颈(增加再多节点，性能提升也不会很明显)，扩容成本同样不菲。</p>
<p>基于Hadoop的Spark/Impala，则对部署硬件的要求很低(常见服务器即可，只是其主要依靠内存计算来缩短响应时间，所以对内存要求较高)，在节点扩容上成本上相对较低，但当计算量达到一定级别或并发达到一定级别后，<strong>无法秒级响应</strong>，且<strong>容易出现内存溢出</strong>等问题。</p>
<h3 id="MOLAP"><a href="#MOLAP" class="headerlink" title="MOLAP"></a>MOLAP</h3><p>以MOLAP分析为代表的有Cognos，SSAS，Kylin等，设计理念<strong>是预先将客户的需求计算好以结果的形式存下来</strong>（比如一张表分为10个维度，5个度量，那客户提出的需求会有2的10次方种可能，然后将这么多种可能提前计算好存储下来)，<strong>当客户提出需求后，找到对应结果返回即可</strong>（好比你提前一天将领导明天会布置的任务先做好，明天领导布置对应任务后你直接告知他已做好）</p>
<ul>
<li>优点是当命中需求后返回非常快（所以MOLAP非常适合常见固定的分析场景），同等资源下支持的数据体量更大，支持的并发更多</li>
<li>缺点则是当表的维度越多，越复杂，其所需的磁盘存储空间则越大，构建cube也需要一定的时间。</li>
</ul>
<p>Cognos和SSAS是早期比较传统的产品，Cognos限制了Cube的大小(即限制了表的复杂度大小)，而SSAS的cube则受限于单机的容量，即需要专用的服务器来进行存储。</p>
<p>Apache Kylin则是目前技术较为先进的一款成熟产品，也是第一个由中国人贡献给Apache社区的顶级开源项目，它基于hadoop框架，Cube以分片的形式存储在不同节点上，Cube大小不受服务器配置限制，所以具备很好的可扩展性和对服务器要求很低，在扩容成本上就非常低廉。另外为了控制整体Cube的大小，Kylin给客户提供了建模的能力，即用户可以根据自身需要，对模型种的维度以及维度组合进行预先的构建，把一些不需要的维度和组合筛选掉，从而达到降低维度的目的，减少磁盘空间的占用。</p>
<p>Kylin的企业版产品，即Kyligence的产品，除了在性能、功能上做了很多优化之外，稳定性上也做了很大提升，还提供了智能建模功能，在满足用户需求的前提下，很大程度上减小了磁盘空间的浪费。</p>
<p>综上而言</p>
<ul>
<li><p>从可扩展性上看：Kylin=Impala/Spark&gt;MPP数据库&gt;传统数据库</p>
</li>
<li><p>从对硬件要求上看，传统数据库&gt;MPP数据库&gt;Impala/Spark&gt;=Kylin；</p>
</li>
<li>从响应效率上来看，不同的数据量、并发数，响应效率差别不一，但可以确定的是，要计算的数据量越大，并发的用户数越多，同等资源情况下预计算的响应效率会越发明显。</li>
</ul>
<h2 id="数据仓库模型"><a href="#数据仓库模型" class="headerlink" title="数据仓库模型"></a>数据仓库模型</h2><h3 id="Star-schema"><a href="#Star-schema" class="headerlink" title="Star schema"></a>Star schema</h3><p>在星型模型当中，<strong>一张事实表被若干张维度表所包围</strong>。每一个维度代表了一张表，有主键关联事实表当中的外键。</p>
<ul>
<li>所有的事实都必须保持同一个粒度</li>
<li>不同的维度之间没有任何关联</li>
</ul>
<p><img src="/2022/01/01/OLAP/1.png"></p>
<h3 id="雪花模型"><a href="#雪花模型" class="headerlink" title="雪花模型"></a>雪花模型</h3><p> 雪花模型是在基于星型模型之上拓展来的，<strong>每一个维度可以再扩散出更多的维度</strong>，根据维度的层级拆分成颗粒度不同的多张表。</p>
<ul>
<li>优点是减少维度表的数据量，在进行join查询时有效提升查询速度</li>
<li>缺点是需要额外维护维度表的数量</li>
</ul>
<p><img src="/2022/01/01/OLAP/2.png"></p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>在规范化方面：</p>
<ul>
<li><strong>雪花模型</strong>比较符合数据库范式的理念设计方式比较正规，数据冗余少</li>
<li>非规范化的数据模型可能会违反完整性和一致性</li>
</ul>
<p>在查询复杂度方面：</p>
<ul>
<li><strong>雪花模型</strong>在查询的时候可能需要join多张表从而导致查询效率下降，此外规范化操作在后期维护比较复杂。</li>
<li><strong>星型模型</strong>能够提升查询效率，因为生成的事实表已经经过预处理，主要的数据都在事实表里面，所以只要扫描实时表就能够进行大量的查询，而不必进行大量的join。而且维表数据一般比较少，可直接放入内存进行join以提升效率，</li>
</ul>
<p>在可读性方面：</p>
<ul>
<li><strong>星型模型</strong>的事实表可读性比较好，不用关联多个表就能获取大部分核心信息，设计维护相对比较简答。</li>
</ul>
<p>数据仓库大多数时候是比较适合<strong>使用星型模型构建底层数据Hive表</strong>，通过大量的冗余来提升查询效率，星型模型对OLAP的分析引擎支持比较友好，这一点在Kylin中比较能体现。</p>
<p>而雪花模型在关系型数据库中如MySQL，Oracle中非常常见，尤其像电商的数据库表。在数据仓库中雪花模型的应用场景比较少，但也不是没有，所以在具体设计的时候，可以考虑是不是能结合两者的优点参与设计，以此达到设计的最优化目的。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>属性</th>
<th>星型模型</th>
<th>雪花模型</th>
</tr>
</thead>
<tbody>
<tr>
<td>数据总量</td>
<td>多</td>
<td>少</td>
</tr>
<tr>
<td>可读性</td>
<td>容易</td>
<td>差</td>
</tr>
<tr>
<td>表个数</td>
<td>少</td>
<td>多</td>
</tr>
<tr>
<td>查询速度</td>
<td>快</td>
<td>慢</td>
</tr>
<tr>
<td>冗余度</td>
<td>高</td>
<td>低</td>
</tr>
<tr>
<td>对实时表的情况</td>
<td>增加宽度</td>
<td>字段比较少，冗余低</td>
</tr>
<tr>
<td>扩展性</td>
<td>差</td>
<td>好</td>
</tr>
</tbody>
</table>
</div>

          
        
      
    </div>
    
    
    
    <div>
      
    </div>
    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://jasonxqh.github.io/2022/01/01/%E6%95%B0%E6%8D%AE%E5%BA%93%E6%89%A9%E5%B1%95%E6%80%A7%E9%97%AE%E9%A2%98/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jason">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/%5Bobject%20Object%5D">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jason‘s Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2022/01/01/%E6%95%B0%E6%8D%AE%E5%BA%93%E6%89%A9%E5%B1%95%E6%80%A7%E9%97%AE%E9%A2%98/" itemprop="url">数据库扩展性问题</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2022-01-01T10:48:27+08:00">
                2022-01-01
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified&#58;</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2022-06-24T10:00:46+08:00">
                2022-06-24
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="数据库扩展性问题"><a href="#数据库扩展性问题" class="headerlink" title="数据库扩展性问题"></a>数据库扩展性问题</h1><h2 id="NoSQL"><a href="#NoSQL" class="headerlink" title="NoSQL"></a>NoSQL</h2><p>NoSQL数据库有四大分类：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>分类</th>
<th>Examples</th>
<th>典型应用场景</th>
<th>数据模型</th>
<th>优点</th>
<th>缺点</th>
</tr>
</thead>
<tbody>
<tr>
<td>键值 key-value</td>
<td>Riak,Redis,Voldmort</td>
<td>内容缓存，用于处理大量数据的高访问负载，也用于一些日志系统等</td>
<td>Key指向Value的键值对，通常用哈希表实现</td>
<td>查找速度快</td>
<td>数据无结构化，通常只被当做字符串或者二进制数据</td>
</tr>
<tr>
<td>列存储数据库 wide-column</td>
<td>Cassandra,HBase</td>
<td>分布式的文件系统</td>
<td>以列簇式存储，将同一列数据存在一起</td>
<td>查找速度快，可扩展性强，更容易进行分布式扩展</td>
<td>功能相对局限</td>
</tr>
<tr>
<td>文档型数据 document</td>
<td>MongoDB, CouchDB</td>
<td>web应用</td>
<td>Key-Value对应的键值对，Value为结构化数据</td>
<td>数据结构要求不严格，表结构可变，不需要像关系型数据库一样，需要预先定义表结构</td>
<td>查询性能不高，而且缺乏统一查询语法</td>
</tr>
<tr>
<td>图形数据库 Graph</td>
<td>Neo4J,HyperGraphDB</td>
<td>社交网络，推荐系统。专注于构建关系图谱</td>
<td>图结构</td>
<td>利用图结构相关算法</td>
<td>很多时候需要对整个图做计算才能得出需要的信息。不太好做分布式扩展</td>
</tr>
</tbody>
</table>
</div>
<h3 id="NoSQL和SQL不同的开发过程"><a href="#NoSQL和SQL不同的开发过程" class="headerlink" title="NoSQL和SQL不同的开发过程"></a>NoSQL和SQL不同的开发过程</h3><ul>
<li>传统的SQL数据库设计流程</li>
</ul>
<p>概念模型(Conceptual Model) ——&gt; 模式(Schema) ——&gt; 物理设计优化(Physical Design) ——&gt; 分库分表(Sharding)</p>
<ul>
<li>NoSQL的数据库设计流程</li>
</ul>
<p>应用功能 (App Operation) ——&gt; 模式(Schema) ——&gt; 横向扩展(Scaling)</p>
<h3 id="NOSQL的优势"><a href="#NOSQL的优势" class="headerlink" title="NOSQL的优势"></a>NOSQL的优势</h3><ul>
<li><p><strong>易扩展</strong><br>NoSQL数据库种类繁多，但是一个共同的特点都是去掉关系数据库的关系型特性。数据之间无关系，这样就非常容易扩展。也无形之间，在架构的层面上带来了可扩展的能力。</p>
</li>
<li><p><strong>大数据量，高性能</strong><br>NoSQL数据库都具有非常高的读写性能，尤其在大数据量下，同样表现优秀。这得益于它的无关系性，数据库的结构简单。一般MySQL使用Query Cache，每次表的更新Cache就失效，是一种大粒度的Cache，在针对web2.0的交互频繁的应用，Cache性能不高。而NoSQL的Cache是记录级的，是一种细粒度的Cache，所以NoSQL在这个层面上来说就要性能高很多了。</p>
</li>
<li><p><strong>灵活的数据模型</strong><br>NoSQL无需事先为要存储的数据建立字段，随时可以存储自定义的数据格式。而在关系数据库里，增删字段是一件非常麻烦的事情。如果是非常大数据量的表，增加字段简直就是一个噩梦。</p>
</li>
<li><p><strong>高可用</strong><br>NoSQL在不太影响性能的情况，就可以方便的实现高可用的架构。比如Cassandra，HBase模型，通过复制模型也能实现高可用。</p>
</li>
</ul>
<h3 id="SQL-的劣势"><a href="#SQL-的劣势" class="headerlink" title="SQL 的劣势"></a>SQL 的劣势</h3><ul>
<li><p><strong>大数据场景下I/O较高</strong></p>
<p>因为数据是按行存储，即使只针对其中某一列进行运算，关系型数据库也会将整行数据从存储设备中读入内存，导致I/O较高</p>
</li>
<li><p><strong>存储的是行记录，无法存储数据结构</strong> </p>
</li>
<li><p><strong>表结构schema扩展不方便</strong><br> 如要需要修改表结构，需要执行执行DDL(data definition language)，语句修改，修改期间会导致锁表，部分服务不可用</p>
</li>
<li><p><strong>全文搜索功能较弱</strong><br> 关系型数据库下只能够进行子字符串的匹配查询，当表的数据逐渐变大的时候，like查询的匹配会非常慢，即使在有索引的情况下。况且关系型数据库也不应该对文本字段进行索引</p>
</li>
<li><p><strong>存储和处理复杂关系型数据功能较弱</strong><br> 许多应用程序需要了解和导航高度连接数据之间的关系，才能启用社交应用程序、推荐引擎、欺诈检测、知识图谱、生命科学和 IT/网络等用例。然而传统的关系数据库并不善于处理数据点之间的关系。它们的表格数据模型和严格的模式使它们很难添加新的或不同种类的关联信息。</p>
</li>
</ul>
<h2 id="CAP"><a href="#CAP" class="headerlink" title="CAP"></a>CAP</h2><p>CAP理论非常重要，在分布式数据库的设计中起了很关键的理论支持(包括区块链)。我们先对CAP进行定义：</p>
<ul>
<li>C（一致性 Consistency）：所有节点访问同一份最新的数据副本。(副本既可以是备份数据，也可以是冗余数据，比如索引)</li>
<li>A（可用性 Availability）：每次请求都能获取到非错的响应——但是不保证获取的数据是否为最新的数据</li>
<li>P（分区容错 Partitioning Tolerance）：通信故障的时候，系统的任意节点都可以正常工作。(以实际效果而言，分区就相当于对通信的时限要求，系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择)</li>
</ul>
<p>任何一个分布式数据库只能在C、A和P三者中兼顾两个</p>
<h3 id="一致性"><a href="#一致性" class="headerlink" title="一致性"></a>一致性</h3><p><strong>这里指的是强一致性，而最终一致性后续讨论</strong><br>在写操作完成后开始的任何读操作都必须返回该值，或者后续写操作的结果<br>也就是说，在一致性系统中，一旦客户端将值写入任何一台服务器并获得响应，那么之后client从其他任何服务器读取的都是刚写入的数据</p>
<p><strong>用如下系统进行解释</strong></p>
<p><img src="/2022/01/01/%E6%95%B0%E6%8D%AE%E5%BA%93%E6%89%A9%E5%B1%95%E6%80%A7%E9%97%AE%E9%A2%98/1.png"></p>
<ol>
<li>客户端向G1写入数据v1，并等待响应</li>
<li>此时，G1服务器的数据为v1，而G2服务器的数据为v0，两者不一致</li>
<li>接着，在返回响应给客户端之前，G2服务器会自动同步G1服务器的数据，使得G2服务器的数据也是v1</li>
<li>一致性保证了不管向哪台服务器（比如这边向G1）写入数据，其他的服务器（G2）能实时同步数据</li>
<li>G2已经同步了G1的数据，会告诉G1，我已经同步了</li>
<li>G1接收了所有同步服务器的已同步的报告，才将“写入成功”信息响应给client</li>
<li>client再发起请求，读取G2的数据</li>
<li>此时得到的响应是v1，即使client从未写入数据到G2</li>
</ol>
<h3 id="可用性"><a href="#可用性" class="headerlink" title="可用性"></a>可用性</h3><p>系统中非故障节点收到的每个请求都必须有响应<br>在可用系统中，如果我们的客户端向服务器发送请求，并且服务器未崩溃，则服务器必须最终响应客户端，不允许服务器忽略客户的请求</p>
<h3 id="分区容错性"><a href="#分区容错性" class="headerlink" title="分区容错性"></a>分区容错性</h3><p><strong>允许网络丢失从一个节点发送到另一个节点的任意多条消息，即不同步 </strong><br>也就是说，G1和G2发送给对方的任何消息都是可以放弃的，也就是说G1和G2可能因为各种意外情况，导致无法成功进行同步，分布式系统要能容忍这种情况。</p>
<p><img src="/2022/01/01/%E6%95%B0%E6%8D%AE%E5%BA%93%E6%89%A9%E5%B1%95%E6%80%A7%E9%97%AE%E9%A2%98/2.png"></p>
<h3 id="CAP三者不可能同时满足"><a href="#CAP三者不可能同时满足" class="headerlink" title="CAP三者不可能同时满足"></a>CAP三者不可能同时满足</h3><p>假设确实存在三者能同时满足的系统</p>
<ul>
<li>那么我们要做的第一件事就是分区我们的系统，由于满足分区容错性，也就是说可能因为通信不佳等情况，G1和G2之间是没有同步</li>
</ul>
<p><img src="/2022/01/01/%E6%95%B0%E6%8D%AE%E5%BA%93%E6%89%A9%E5%B1%95%E6%80%A7%E9%97%AE%E9%A2%98/3.png"></p>
<ul>
<li>接下来，我们的客户端将v1写入G1，但G1和G2之间是不同步的，所以如下G1是v1数据，G2是v0数据。</li>
</ul>
<p><img src="/2022/01/01/%E6%95%B0%E6%8D%AE%E5%BA%93%E6%89%A9%E5%B1%95%E6%80%A7%E9%97%AE%E9%A2%98/4.png"></p>
<ul>
<li>由于要满足可用性，即一定要返回数据，所以G1必须在数据没有同步给G2的前提下返回数据给client，如下</li>
</ul>
<p><img src="/2022/01/01/%E6%95%B0%E6%8D%AE%E5%BA%93%E6%89%A9%E5%B1%95%E6%80%A7%E9%97%AE%E9%A2%98/5.png"></p>
<ul>
<li>接下去，client请求的是G2服务器，由于G2服务器的数据是v0，所以client得到的数据是v0</li>
</ul>
<p><img src="/2022/01/01/%E6%95%B0%E6%8D%AE%E5%BA%93%E6%89%A9%E5%B1%95%E6%80%A7%E9%97%AE%E9%A2%98/6.png"></p>
<p>很明显，G1返回的是v1数据，G2返回的是v0数据，两者不一致。<br>其余情况也有类似推导，也就是说CAP三者不能同时出现。</p>
<h3 id="CAP三者如何权衡"><a href="#CAP三者如何权衡" class="headerlink" title="CAP三者如何权衡"></a>CAP三者如何权衡</h3><h4 id="三选二利弊如何"><a href="#三选二利弊如何" class="headerlink" title="三选二利弊如何"></a>三选二利弊如何</h4><ul>
<li>CA (Consistency + Availability)：关注一致性和可用性，它需要非常严格的全体一致的协议，比如“两阶段提交”（2PC）。CA 系统不能容忍网络错误或节点错误，一旦出现这样的问题，整个系统就会拒绝写请求，因为它并不知道对面的那个结点是否挂掉了，还是只是网络问题。唯一安全的做法就是把自己变成只读的。<ul>
<li>注意：redis 和 MongoDB 均满足CP原则。</li>
</ul>
</li>
<li>CP (consistency + partition tolerance)：关注一致性和分区容忍性。它关注的是系统里大多数人的一致性协议，比如：Paxos 算法 (Quorum 类的算法)。这样的系统只需要保证大多数结点数据一致，而少数的结点会在没有同步到最新版本的数据时变成不可用的状态。这样能够提供一部分的可用性。</li>
<li>AP (availability + partition tolerance)：这样的系统关心可用性和分区容忍性。因此，这样的系统不能达成一致性，需要给出数据冲突，给出数据冲突就需要维护数据版本。Dynamo 就是这样的系统。</li>
</ul>
<p><img src="/2022/01/01/%E6%95%B0%E6%8D%AE%E5%BA%93%E6%89%A9%E5%B1%95%E6%80%A7%E9%97%AE%E9%A2%98/7.png"></p>
<h4 id="如何进行三选二"><a href="#如何进行三选二" class="headerlink" title="如何进行三选二"></a>如何进行三选二</h4><p><strong>权衡三者的关键点取决于业务</strong><br>放弃了一致性，满足分区容错，那么节点之间就有可能失去联系，为了高可用，每个节点只能用本地数据提供服务，而这样会容易导致全局数据不一致性。对于互联网应用来说（如新浪，网易），机器数量庞大，节点分散，网络故障再正常不过了，那么此时就是保障AP，放弃C的场景，而从实际中理解，像门户网站这种偶尔没有一致性是能接受的，但不能访问问题就非常大了。</p>
<p>对于银行来说，就是<strong>必须保证强一致性</strong>，也就是说C必须存在，那么就只用CA和CP两种情况。</p>
<ul>
<li>当保障强一致性和可用性（CA），那么一旦出现通信故障，系统将完全不可用。</li>
<li>另一方面，如果保障了强一致性和分区容错（CP），那么就具备了部分可用性。</li>
</ul>
<p>实际究竟应该选择什么，是需要通过业务场景进行权衡的（并不是所有情况都是CP好于CA，只能查看信息但不能更新信息有时候还不如直接拒绝服务）</p>
<h2 id="NewSQL"><a href="#NewSQL" class="headerlink" title="NewSQL"></a>NewSQL</h2><p>newSQL 提供了与 noSQL 相同的可扩展性，而且仍基于关系模型，还保留了极其成熟的 SQL 作为查询语言，保证了ACID事务特性。</p>
<p>简单来讲，newSQL 就是在传统关系型数据库上集成了 noSQL 强大的可扩展性。</p>
<p>传统的SQL架构设计基因中是没有分布式的，而 newSQL 生于云时代，天生就是分布式架构。</p>
<p>newSQL 的主要特性：</p>
<ul>
<li>SQL 支持，支持复杂查询和大数据分析。</li>
<li>支持 ACID 事务，支持隔离级别。</li>
<li>弹性伸缩，扩容缩容对于业务层完全透明。</li>
<li>高可用，自动容灾。</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th>SQL</th>
<th>NoSQL</th>
<th>NewSQL</th>
</tr>
</thead>
<tbody>
<tr>
<td>关系模型</td>
<td>Yes</td>
<td>No</td>
<td>Yes</td>
</tr>
<tr>
<td>SQL语句</td>
<td>Yes</td>
<td>No</td>
<td>Yes</td>
</tr>
<tr>
<td>ACID</td>
<td>Yes</td>
<td>No</td>
<td>Yes</td>
</tr>
<tr>
<td>水平扩展</td>
<td>No</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>大数据</td>
<td>No</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>无结构化</td>
<td>No</td>
<td>Yes</td>
<td>No</td>
</tr>
</tbody>
</table>
</div>
<h3 id="CAP再探"><a href="#CAP再探" class="headerlink" title="CAP再探"></a>CAP再探</h3><p>当在分布式系统上发生通信故障的时候(Partitioning)，由于P是必须要有的，因此只有CP和AP两种选择。</p>
<p>对于A，也有两种方式： Node Avalability 和 Service Availability</p>
<ul>
<li>Node Availability (nA)<ul>
<li>通信故障发生时，任一节点都可用。 </li>
</ul>
</li>
<li>Service Availability (sA)<ul>
<li>通信故障发生时，部分节点不可用。但是，总有一部分节点可用。系统可以将用户自动切换到可用的节点。使得服务不中断。</li>
</ul>
</li>
</ul>
<p>因此，对于 CnAP来说，只能在CP和nAP中二选一，但是对于CsAP，在某种条件下，可以兼顾(使用Raft.Paxos)</p>
<h3 id="Spanner数据库"><a href="#Spanner数据库" class="headerlink" title="Spanner数据库"></a>Spanner数据库</h3><p>Spanner 就是利用 CsAP的NewSQL数据库。Spanner最重要的设计点就是做全球数据库，要求可扩展性、多数据版本、多replica数据一致性和事务。是第一个款能实现全球数据分布而且还能实现分布式事务的数据库系统，从他的架构图来看底层也是基于Colossus(GFS二代)来存储文件，只不过上层的tablet还通过Paxos协议在做数据的replica。这点和HBase当前1.1版本引进的region高可用有点类似，但看起来又不全是。 </p>
<h4 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h4><p>Spanner 是由一系列的 zone 组成, zone 是 Spanner 中的部署的单元, 一般会在某 datacenter 部署一个 zone, 但是也可以有多个 zone。数据副本就是存放在这一系列的 zone 中, zone 之间的物理距离越大, 数据的安全性越高。</p>
<p><img src="/2022/01/01/%E6%95%B0%E6%8D%AE%E5%BA%93%E6%89%A9%E5%B1%95%E6%80%A7%E9%97%AE%E9%A2%98/8.jpeg" style="zoom:150%;"></p>
<blockquote>
<p>universemaster：是一个控制台, 监控universe里所有zone状态信息, 用于debug；</p>
<p>placement driver：帮助维持特定副本数量，自动搬迁数据，实现负载均衡；</p>
<p>zonemaster：管理 spanserver 上的数据；</p>
<p>location proxy：作用不详, 可能是为 client 提供数据的位置信息, client 要先访问它来定位需要访问的 spanserver；</p>
<p>spanserver：对 client 提供服务, 包括读写数据。</p>
</blockquote>
<p> <strong>Spanserver 架构</strong></p>
<p><img src="/2022/01/01/%E6%95%B0%E6%8D%AE%E5%BA%93%E6%89%A9%E5%B1%95%E6%80%A7%E9%97%AE%E9%A2%98/9.jpeg" style="zoom:150%;"></p>
<p>在Spanner中，tablet的概念和Bigtable类似，都是B-tree的存储结构，和HBase的region对等关系。只不过在Spanner中创造了目录的概念，把不同表中相同rowkey前缀的数据放入到同一个directory中。这也是之所有能在几十TB数据量情况下做到多表关联的必要条件(而并非现在传说的遵循标准关系型数据库的schema模式可以随意来设计) </p>
<p>同时，Spanner引入了Group概念，这个和HBase当前的Region Group类似，不同的Dir归属于不同的Group，数据以Group为单位进行逻辑上的存储。Group内数据被同一个Paxos管理起来，而不同的Group间Paxos不同。当然目录可以在Group之间来回移动，以达到负载均衡和容灾的目的。 </p>
<p>为了实现分布式事务，除了Paxos协议和两阶段提交。还有一个非常重要的前提，就是不同客户端提交的<strong>事务时间戳需要非常精确</strong>，因为这个决定了究竟哪个事务在前，哪个事务在后。这个时间戳的概念比较容易被误读成数据时间戳。在这里Spanner定义了读写事务、只读事务、快照读。读写事务对时间精确性要求较高，也许在10ms内会同时有客户端在读写同一条数据，谁先谁后对最终结果影响很大。只读事务和快照读目前还没分太清楚，大概是指定时间戳版本的读，读当前最新还是读一个历史版本 </p>
<h4 id="Timestamps-Based-Protocals"><a href="#Timestamps-Based-Protocals" class="headerlink" title="Timestamps-Based Protocals"></a>Timestamps-Based Protocals</h4><p><a href="https://blog.csdn.net/weixin_45583158/article/details/100143234" target="_blank" rel="noopener">https://blog.csdn.net/weixin_45583158/article/details/100143234</a></p>
<p>每个事务在进入系统时都会被授予一个时间戳。如果一个旧的事务 $T_i$有时间戳 $TS(T_i)$，一个新的交易$T_j$被分配时间戳$TS(T_j)$，使$TS(T_i)&lt;TS(T_j)$。</p>
<p>该协议管理并发的执行，使时间戳决定可序列化的顺序。</p>
<p>为了保证这种行为，协议为每个数据Q保持两个时间戳值。</p>
<ul>
<li>W-timestamp(Q)是任何成功执行<strong>write(Q)</strong> 的事务的最大时间戳。</li>
<li>R-timestamp(Q)是任何成功执行<strong>read(Q)</strong> 的事务的最大时间戳。</li>
</ul>
<h4 id="Multiversion-Schemes"><a href="#Multiversion-Schemes" class="headerlink" title="Multiversion Schemes"></a>Multiversion Schemes</h4><p>Multiversion Schemes 保留数据项的旧版本，以增加并发性。</p>
<ul>
<li>Multiversion Timestamp Ordering</li>
<li>Multiversion Two-Phase Locking</li>
</ul>
<p>每一次成功的写入都会导致所写数据项的新版本的产生。</p>
<p>我们使用时间戳来标记版本。</p>
<p>当一个read(Q)操作被发出时，根据事务的时间戳选择Q的适当版本，并返回所选版本的值。 </p>
<p>执行读取操作时不必等待，因为适当的版本会立即返回。</p>
<h4 id="Multiversion-Timestamp-Ordering"><a href="#Multiversion-Timestamp-Ordering" class="headerlink" title="Multiversion Timestamp Ordering"></a>Multiversion Timestamp Ordering</h4><p>每个数据项Q都有一连串的版本<Q1, q2,...., qm>。每个版本$Q_k$包含三个数据字段。</Q1,></p>
<ul>
<li>Content — 版本$Q_k$的值。</li>
<li>W-timestamp($Q_k$) — 创建(写) 版本$Q_k$的事务的时间戳</li>
<li>R-timestamp($Q_k$) — 成功读取版本$Q_k$的事务的最大时间戳</li>
</ul>
<p>当一个事务$T_i$创建了Q的新版本$Q_k$，$Q_k$的 W-timestamp和R-timestamp 被初始化为$TS(T_i)$。<br>每当一个事务$T_j$读取$Q_k$，并且$TS(T_j)&gt;R-timestamp(Q_k)$时，$Q_k$的R-timestamp被更新。</p>
<p>假设事务$T_i$发出一个<strong>read(Q)</strong>或<strong>write(Q)</strong>操作。 让$Q_k$表示$Q$的版本，其写入时间戳是小于或等于$TS(T_i)$的最大写入时间戳。</p>
<ol>
<li>如果事务$T_i$发出 read(Q)，那么返回的值就是版本$Q_k$的内容。</li>
<li>如果事务$T_i$发出一个 write(Q)<ol>
<li>如果$TS(T_i)&lt; R-timestamp(Q_k)$，则事务$T_i$被回滚。</li>
<li>如果$TS(T_i) = W-timestamp(Q_k)$，$Q_k$的内容被覆盖。</li>
<li>否则将创建一个新的Q版本。</li>
</ol>
</li>
</ol>
<p>请注意</p>
<ul>
<li>读取总是成功的</li>
<li>如果其他事务$T_j$（在由时间戳值定义的序列化顺序中）应该读取$T_i$的写，但已经读取了比$T_i$更早的事务创建的版本，那么$T_i$的写就会被拒绝。</li>
<li>协议保证可序列化</li>
</ul>
<h4 id="Reads-in-spanner"><a href="#Reads-in-spanner" class="headerlink" title="Reads in spanner"></a>Reads in spanner</h4><h5 id="Snapshot-read"><a href="#Snapshot-read" class="headerlink" title="Snapshot read"></a>Snapshot read</h5><p>Snapshot read 指的是读取过去时间的某个快照, 无需加锁。</p>
<p>client可以指定一个 timestamp t, 或者时间范围，Spanner 会寻找一个数据充分更新好的 replica 来提供读服务。</p>
<p>所谓数据充分更新好, 是指 t &lt;= tsafe，其中 tsafe 定义如下:</p>
<script type="math/tex; mode=display">
t_{safe} = \min(t_{safe}^{paxos},t_{safe}^{TM})</script><p>前者指的已经提交的事务 timestamp, 后者指的是正在 2PC 过程中未决的事务 timestamp - 1。</p>
<p>如果 t &gt; tsafe，Spanner 需要等待 replica 一段时间, 待 tsafe 推进后再进行读操作。</p>
<p>基于 External Consistency 特性，Spanner 可以感知操作的先后顺序, 给定一个时间戳 t, Spanner 能够明确哪些是历史数据, 并提供一致的快照。 </p>
<h4 id="Read-only-transactions"><a href="#Read-only-transactions" class="headerlink" title="Read-only transactions"></a>Read-only transactions</h4><ul>
<li><p>Assign timestamp sread and do snapshot read at sread</p>
</li>
<li><p>$s_{read}  = TT.now().latest() $ 保证外部一致性（线性化）。</p>
</li>
<li><p>应该分配最古老的时间戳，保持外部一致性，以避免阻塞。</p>
<ul>
<li>For read at single paxos group: <ul>
<li>Let LastTS() = timestamp of the last committed write at the Paxos group. </li>
<li>如果没有准备好的事务，让 $s_{read} = LastTS()$很容易满足外部一致性：事务将看到最后一次写入的结果。</li>
</ul>
</li>
<li>在一般情况下，选择TT.now().latest()更简单。</li>
</ul>
</li>
</ul>
<h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>Spanner 的 TureTime API 设计非常巧妙, 保证了绝对时间一定是落在 TT.now() 返回的区间之中。基于这个保证, 使得分布在全球的 spanserver 分配的 timestamp 都是基于同一参考系, 具有可比性。进而让 Spanner 能够感知分布式系统中的事件的先后顺序, 保证了 External Consistency。</p>
<p>但是 TureTime API 要求对误差的测量具有非常高的要求, 如果实际误差 &gt; 预计的误差, 那么绝对时间很可能就飘到了区间之外, 后续的操作都无法保证宣称的 External Consistency。另外, Spanener 的大部分响应时间与误差的大小是正相关的。</p>
<p>自 Spanner 在 OSDI12 发表论文后, Spanner 一直在努力减少误差, 并提高测量误差的技术[3], 但是并没有透露更多细节。</p>
<p>在一个大规模的分布式系统中，集中分配时间戳是不可行的。解决方案: TrueTime设备</p>
<ul>
<li>GPS时钟</li>
<li>原子钟</li>
</ul>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul>
<li>分布式多版本数据库<ul>
<li>General-Purpose Transactions（ACID）</li>
<li>SQL查询语言</li>
<li>模式化的表(Schematized Tables)</li>
<li>半关系型数据模型（F1 is more relational/SQL）</li>
</ul>
</li>
<li>重点：管理跨数据中心的复制</li>
<li>特点：提供外部一致的读写。<ul>
<li>提供外部一致的读和写。</li>
<li>全局一致的跨数据库读取 </li>
</ul>
</li>
</ul>
<blockquote>
<p>F1最初定位是一个SQL查询引擎，本来是架构在Mysql的分布式集群上。由于Mysql本身的reshared以及分布式事务上的冲突几乎是无解，最终放弃Mysql分布式存储，而转而使用Spanner。单独的F1并不能称为一款数据库。这点在F1论文题目有所误导，更准确的来讲F1是一款SQL执行引擎，包含了二级索引等一些常见的传统数据库功能。和Spanner结合起来才完成了Nosql+Sql=newSQL的壮举。</p>
</blockquote>
<p>Spanner/F1似乎是第一个能称得上可真正扩展的分布式SQL系统。</p>

          
        
      
    </div>
    
    
    
    <div>
      
    </div>
    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://jasonxqh.github.io/2022/01/01/%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jason">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/%5Bobject%20Object%5D">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jason‘s Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2022/01/01/%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1/" itemprop="url">分布式数据库事务</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2022-01-01T10:48:16+08:00">
                2022-01-01
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified&#58;</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2022-06-23T21:40:02+08:00">
                2022-06-23
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="分布式数据库事务"><a href="#分布式数据库事务" class="headerlink" title="分布式数据库事务"></a>分布式数据库事务</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>对于部署在云上的服务，仅仅由一台服务器来承载流量是不够的，因此数据库会被扩展到多台主机上。主要有两种扩展模式：</p>
<ul>
<li>分库/分表的扩展模式。这意思就是，在每一个节点(服务器)上，运行一套独立的数据库，然后在上面铺一层中间件，在收到了用户的请求之后，由中间件分发给节点来处理。运用这种模式，数据需要划分得特别干净</li>
</ul>
<p><img src="/2022/01/01/%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1/2.png" style="zoom:67%;"></p>
<ul>
<li>很多时候我们无法做到划分出这么干净的数据，因此还有一种拓展方式是：并行/分布式数据库。 就是我们不把数据划分的任务交给中间件，而是直接构建一个分布式数据库系统，比如说 OceanBase。如下：</li>
</ul>
<p><img src="/2022/01/01/%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1/1.png" style="zoom:67%;"></p>
<p>对于分布式数据库，电脑间的交互肯定是需要的，但是我们尽量要减少这种交互，因为网络交互存在带宽限制。</p>
<p>我们要了解三种 数据库构架设计： Shared Everthting、Shared Nothing、和Shared Disk：</p>
<ol>
<li>Shared Everthting:一般是针对单个主机，完全透明共享CPU/MEMORY/IO，并行处理能力是最差的，典型的代表SQLServer</li>
<li>Shared Disk：各个处理单元使用自己的私有 CPU和Memory，共享磁盘系统。典型的代表Oracle Rac， 它是数据共享，可通过增加节点来提高并行处理的能力，扩展能力较好。其类似于SMP（对称多处理）模式，但是当存储器接口达到饱和的时候，增加节点并不能获得更高的性能 。</li>
<li>Shared Nothing：各个处理单元都有自己私有的CPU/内存/硬盘等，不存在共享资源，类似于MPP（大规模并行处理）模式，各处理单元之间通过协议通信，并行处理和扩展能力更好。典型代表DB2 DPF和Hadoop ，<strong>各节点相互独立，各自处理自己的数据</strong>，处理后的结果可能向上层汇总或在节点间流转。</li>
</ol>
<p>我们常说的 Sharding 其实就是Share Nothing架构，它是把某个表从物理存储上被水平分割，并分配给多台服务器（或多个实例），每台服务器可以独立工作，具备共同的schema，比如MySQL Proxy和Google的各种架构，只需增加服务器数就可以增加处理能力和容量。</p>
<p>但是，一旦网络的带宽和IO带宽达到相同数量级的时候，就相当于电脑访问自己硬盘中的数据和访问其他节点中的数据所花费的开销类似，这时候share nothing的优势就不明显了。</p>
<h1 id="分布式事务的ACID"><a href="#分布式事务的ACID" class="headerlink" title="分布式事务的ACID"></a>分布式事务的ACID</h1><p>那么，如果使用Share nothing的话，我们该如何对数据进行切分? 可以使用哈希</p>
<p>在分布式数据库中，我们又该如何维持数据的正确性呢？</p>
<p>说到数据库事务就不得不说，数据库事务中的四大特性，ACID:</p>
<ul>
<li>A:原子性(Atomicity)</li>
</ul>
<p>一个事务(transaction)中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。</p>
<p>就像你买东西要么交钱收货一起都执行，要么要是发不出货，就退钱。</p>
<ul>
<li>C:一致性(Consistency)</li>
</ul>
<p>事务的一致性指的是在一个事务执行之前和执行之后数据库都必须处于一致性状态。如果事务成功地完成，那么系统中所有变化将正确地应用，系统处于有效状态。如果在事务中出现错误，那么系统中的所有变化将自动地回滚，系统返回到原始状态。</p>
<ul>
<li>I:隔离性(Isolation)</li>
</ul>
<p>指的是在并发环境中，当不同的事务同时操纵相同的数据时，每个事务都有各自的完整数据空间。由并发事务所做的修改必须与任何其他并发事务所做的修改隔离。事务查看数据更新时，数据所处的状态要么是另一事务修改它之前的状态，要么是另一事务修改它之后的状态，事务不会查看到中间状态的数据。</p>
<p>打个比方，你买东西这个事情，是不影响其他人的。</p>
<ul>
<li>D:持久性(Durability)</li>
</ul>
<p>指的是只要事务成功结束，它对数据库所做的更新就必须永久保存下来。即使发生系统崩溃，重新启动数据库系统后，数据库还能恢复到事务成功结束时的状态。</p>
<p>打个比方，你买东西的时候需要记录在账本上，即使老板忘记了那也有据可查。 </p>
<h2 id="隔离性"><a href="#隔离性" class="headerlink" title="隔离性"></a>隔离性</h2><p>首先我们来讲分布式数据库事务的隔离性。</p>
<p>在两个节点分别处理两个子事务的情况下，是否只要保证了单个节点的原子性，就可以保证整体的原子性呢？</p>
<p>显然不是，我们以两个节点为例。</p>
<p>现在有两个事务，交给两个节点去处理，可以有以下两种处理方式</p>
<p><img src="/2022/01/01/%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1/3.jpg"></p>
<p>第一种方式，是序列化的，在每个节点上，都是先运行T1，再运行T2，而且T1、T2都符合原子性的标准。假设X=Y=0，那么最后它们都等于200</p>
<p>第二种方式，是非序列化的，在Node X上先执行T1.在Node Y上先执行T2。那那么这时候，由于二者是同步进行的，没有序列化，因此会互相造成干扰。如果X=Y=0, 那么，最后X = 200,Y=100</p>
<p>因此，当在分布式数据库中考虑序列化，我们要注意更多，不能依靠单个节点上的事务机制来保证所有事务的原子性。</p>
<p>在分布式数据库执行事务，我们需要考虑两类schedule：</p>
<ul>
<li>Local schedule</li>
<li>Global schedule</li>
</ul>
<p>因此，对于 Global Transaction，如果我们要将其序列化执行，也需要满足两个条件：</p>
<ul>
<li>每一个 Local Schedule 都必须是 可序列化的 (基本条件)</li>
<li>对于 Global Transaction 的所有 sub-transactions ，都以相同的顺序出现在所有站点的等效串行时间表中，不能出现在X 节点上顺序是 T1-&gt;T2，在Y节点上顺序是 T2-&gt;T1的情况</li>
</ul>
<h3 id="Lock"><a href="#Lock" class="headerlink" title="Lock"></a>Lock</h3><h4 id="两阶段锁"><a href="#两阶段锁" class="headerlink" title="两阶段锁"></a>两阶段锁</h4><p>在介绍分布式两阶段锁之前，我们先来学习两阶段锁，它用于单机事务中的一致性和隔离性</p>
<p>在一个事务操作中，分为<code>加锁阶段</code>和<code>解锁阶段</code>，且所有的加锁操作在解锁操作之前，具体如下图所示：</p>
<p><img src="/2022/01/01/%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1/8.png"></p>
<ul>
<li>加锁时机</li>
</ul>
<p>当对记录进行更新操作或者<code>select for update(X锁)、lock in share mode(S锁)</code>时，会对记录进行加锁，锁的种类很多，不在此赘述。</p>
<ul>
<li>何时解锁</li>
</ul>
<p>在一个事务中，只有在<code>commit</code>或者<code>rollback</code>时，才是解锁阶段。</p>
<ul>
<li>二阶段加锁最佳实践</li>
</ul>
<p>下面举个具体的例子，来讲述二段锁对应用性能的影响，我们举个库存扣减的例子：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">方案一：</span><br><span class="line"><span class="keyword">start</span> <span class="keyword">transaction</span>;</span><br><span class="line">// 锁定用户账户表</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> t_accout <span class="keyword">where</span> acount_id=<span class="number">234</span> <span class="keyword">for</span> <span class="keyword">update</span></span><br><span class="line">//生成订单</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t_trans;</span><br><span class="line">// 减库存</span><br><span class="line"><span class="keyword">update</span> t_inventory <span class="keyword">set</span> <span class="keyword">num</span>=<span class="keyword">num</span><span class="number">-3</span> <span class="keyword">where</span> <span class="keyword">id</span>=$&#123;<span class="keyword">id</span>&#125; <span class="keyword">and</span> <span class="keyword">num</span>&gt;=<span class="number">3</span>;</span><br><span class="line"><span class="keyword">commit</span>;</span><br><span class="line"></span><br><span class="line">方案二：</span><br><span class="line"><span class="keyword">start</span> <span class="keyword">transaction</span>;</span><br><span class="line">// 减库存</span><br><span class="line"><span class="keyword">update</span> t_inventory <span class="keyword">set</span> <span class="keyword">num</span>=<span class="keyword">num</span><span class="number">-3</span> <span class="keyword">where</span> <span class="keyword">id</span>=$&#123;<span class="keyword">id</span>&#125; <span class="keyword">and</span> <span class="keyword">num</span>&gt;=<span class="number">3</span>;</span><br><span class="line">// 锁定用户账户表</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> t_accout <span class="keyword">where</span> acount_id=<span class="number">234</span> <span class="keyword">for</span> <span class="keyword">update</span></span><br><span class="line">//生成订单</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t_trans;</span><br><span class="line"><span class="keyword">commit</span>;</span><br></pre></td></tr></table></figure>
<p>我们的应用通过<code>JDBC</code>操作数据库时，底层本质上还是走<code>TCP</code>进行通信，<code>MySQL协议</code>是一种<code>停-等式协议</code>(和<code>http</code>协议类似，每发送完一个分组就停止发送，等待对方的确认,在收到确认后再发送下一个分组)，既然通过网络进行通信，就必然会有延迟，两种方案的网络通信时序图如下：</p>
<p><img src="/2022/01/01/%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1/6.jpeg"></p>
<p>由于商品库存往往是最致命的热点，是整个服务的热点。如果采用第一种方案的话，<code>TPS</code>理论上可以提升<code>3rt/rt=3</code>倍。而这是在一个事务中只有3条SQL的情况，理论上多一条SQL就多一个rt时间。</p>
<p>另外，当<strong>更新操作到达数据库的那个点</strong>，才算加锁成功。<code>commit</code>到达数据库的时候才算解锁成功。所以，更新操作的前半个<code>rt</code>和<code>commit</code>操作的后半个<code>rt</code>都不计算在整个锁库存的时间内。</p>
<ul>
<li>性能优化</li>
</ul>
<p>从上面的例子可以看出，在一个事务操作中，将对最热点记录的操作放到事务的最后面，这样可以显著地提高服务的<code>吞吐量</code>。</p>
<ul>
<li>select for update 和 update where的最优选择</li>
</ul>
<p>我们可以将一些简单的判断逻辑写到update操作的谓词里面，这样可以减少加锁的时间，如下：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">方案一：</span><br><span class="line"><span class="keyword">start</span> <span class="keyword">transaction</span></span><br><span class="line"><span class="keyword">num</span> = <span class="keyword">select</span> <span class="keyword">count</span> <span class="keyword">from</span> t_inventory <span class="keyword">where</span> <span class="keyword">id</span>=<span class="number">234</span> <span class="keyword">for</span> <span class="keyword">update</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">count</span> &gt;= <span class="number">3</span>:</span><br><span class="line">    <span class="keyword">update</span> t_inventory <span class="keyword">set</span> <span class="keyword">num</span>=<span class="keyword">num</span><span class="number">-3</span> <span class="keyword">where</span> <span class="keyword">id</span>=<span class="number">234</span></span><br><span class="line">    <span class="keyword">commit</span> </span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">rollback</span></span><br></pre></td></tr></table></figure>
<p>方案二：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">start</span> <span class="keyword">transaction</span>:</span><br><span class="line">    <span class="built_in">int</span> affectedRows = <span class="keyword">update</span> t_inventory <span class="keyword">set</span> <span class="keyword">num</span>=<span class="keyword">num</span><span class="number">-3</span> <span class="keyword">where</span> <span class="keyword">id</span>=<span class="number">234</span> <span class="keyword">and</span> <span class="keyword">num</span>&gt;=<span class="number">3</span></span><br><span class="line">    <span class="keyword">if</span> affectedRows &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">commit</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">rollback</span></span><br></pre></td></tr></table></figure>
<p>延时图如下：</p>
<p><img src="/2022/01/01/%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1/7.jpeg"></p>
<p>从上图可以看出，加了update谓词以后，一个事务少了1rt的锁记录时间（update谓词和select for update对记录加的都是X锁，所以效果是一样的）。</p>
<h4 id="Centralized-2PL"><a href="#Centralized-2PL" class="headerlink" title="Centralized 2PL"></a>Centralized 2PL</h4><p>Centralized 2PL 是一种将锁的管理责任只委托给一个节点的方法, 也叫做 Primary 2PL 算法. </p>
<p>首先我们要了解一下 Centralized 2PL中的一些名词：</p>
<ul>
<li>Coordinating TM (Transaction Manager) </li>
<li>Participating sites : 那些要进行数据库操作的地方</li>
<li>LM (Lock Manager)</li>
</ul>
<h5 id="流程示意图"><a href="#流程示意图" class="headerlink" title="流程示意图"></a>流程示意图</h5><p><img src="/2022/01/01/%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1/9.png"></p>
<p><img src="/2022/01/01/%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1/10.png"></p>
<ul>
<li>首先，Coordinating TM 代理站点向 Centralized LM发送请求加个锁</li>
<li>LM 同意TM的请求，帮其加锁</li>
<li>TM告诉目标站点：帮你请求到锁了，你可以进行数据库操作了</li>
<li>站点结束数据操作之后，告诉TM</li>
<li>TM向LM汇报：操作完成了，现在你可以释放锁了</li>
</ul>
<p>Centrailized 2PL 主要有以下特点：</p>
<ul>
<li>有一个维护所有锁信息的<strong>单一节点</strong></li>
<li>一个锁管理器(LM)适用于整个DDBMS。</li>
<li>参与全局事务的Local transaction managers(TM) 从 LM中请求和释放锁。或者Transaction Coordinator(可以理解为总代理) 可以代表Participating Sites提出所有的锁请求。</li>
<li>优点：容易发现死锁</li>
<li>劣势：可扩展性差</li>
</ul>
<h4 id="Distributed-2PL"><a href="#Distributed-2PL" class="headerlink" title="Distributed 2PL"></a>Distributed 2PL</h4><p>Distributed 2PL 和 Centralized 2PL 不同，它在每个站点都有一个LM，同时，只有一个TM。它们的通讯逻辑也发生了变化</p>
<p><img src="/2022/01/01/%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1/11.png"></p>
<p><img src="/2022/01/01/%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1/12.png"></p>
<p>由于现在每个站点都有一个 LM，因此站点中的LM不再和数据操作隔离，可以直接对本站点的数据库进行操作。</p>
<p>它们之间的交互逻辑如下：</p>
<ul>
<li>TM 告诉 某一个站点的LM: 哥，你们数据库中有个操作，请你加个锁呗</li>
<li>LM 回答：得嘞，没问题，这就给他加，就不麻烦你了哈</li>
<li>当前站点的数据库操作完成后，比较害羞，对TM说：哥哥，我好了，你和LM说让他把锁松开</li>
<li>TM然后再对 LM说，差不多得了，可以释放锁了</li>
</ul>
<p>分布式二阶段锁的特点是：</p>
<ul>
<li>每个站点都有一个LM。因此每一个站点都有一个 时序表(scheduler)</li>
<li>每个LM处理该站点的数据的锁请求。</li>
<li>并发控制是<strong>通过 Participating sites 的 LMs 的合作</strong> 来完成的</li>
<li>优点：更好的扩展性</li>
<li>缺点：难以探测到死锁的发生 </li>
</ul>
<h2 id="原子性和持久性"><a href="#原子性和持久性" class="headerlink" title="原子性和持久性"></a>原子性和持久性</h2><p>分布式数据库事务的原子性和持久性是通过多阶段提交来实现的。</p>
<p><a href="https://blog.csdn.net/skyie53101517/article/details/80741868" target="_blank" rel="noopener">https://blog.csdn.net/skyie53101517/article/details/80741868</a></p>
<h3 id="2PC"><a href="#2PC" class="headerlink" title="2PC"></a>2PC</h3><p>二阶段提交(Two-phaseCommit)是指，在计算机网络以及数据库领域内，为了使基于分布式系统架构下的所有节点在进行事务提交时保持一致性而设计的一种算法(Algorithm)。通常，二阶段提交也被称为是一种协议(Protocol)。在分布式系统中，每个节点虽然可以知晓自己的操作时成功或者失败，却无法知道其他节点的操作的成功或失败。当一个事务跨越多个节点时，为了保持事务的ACID特性，需要引入一个作为<strong>协调者(coordinator)</strong>的组件来统一掌控所有节点(称作<strong>参与者(participant)</strong>)的操作结果并最终指示这些节点是否要把操作结果进行真正的提交(比如将更新后的数据写入磁盘等等)。因此，<strong>二阶段提交的算法思路可以概括为：参与者将操作成败通知协调者，再由协调者根据所有参与者的反馈情报决定各参与者是否要提交操作还是中止操作。</strong></p>
<h4 id="准备阶段-voting-phase"><a href="#准备阶段-voting-phase" class="headerlink" title="准备阶段 voting phase"></a>准备阶段 voting phase</h4><p>事务协调者(事务管理器)给每个参与者(资源管理器)发送Prepare消息，每个参与者要么直接返回失败(如权限验证失败)，要么在本地执行事务，写本地的redo和undo日志，但不提交，到达一种“万事俱备，只欠东风”的状态。</p>
<p>可以进一步将准备阶段分为以下三个步骤：</p>
<blockquote>
<p>1）协调者节点向所有参与者节点询问是否可以执行提交操作(vote)，并开始等待各参与者节点的响应。</p>
<p>2）参与者节点执行询问发起为止的所有事务操作，并将Undo信息和Redo信息写入日志。（注意：若成功这里其实每个参与者已经执行了事务操作）</p>
<p>3）各参与者节点响应协调者节点发起的询问。如果参与者节点的事务操作实际执行成功，则它返回一个”同意”消息；如果参与者节点的事务操作实际执行失败，则它返回一个”中止”消息。</p>
</blockquote>
<h4 id="提交阶段-decision-phase"><a href="#提交阶段-decision-phase" class="headerlink" title="提交阶段 decision phase"></a>提交阶段 decision phase</h4><p>如果协调者收到了参与者的失败消息或者超时，<strong>直接给每个参与者发送回滚(Rollback)消息</strong>；否则，<strong>发送提交(Commit)消息</strong>；参与者根据协调者的指令执行提交或者回滚操作，释放所有事务处理过程中使用的锁资源。(注意:必须在最后阶段释放锁资源)</p>
<p>接下来分两种情况分别讨论提交阶段的过程。</p>
<ul>
<li>当协调者节点从<strong>所有参与者节点获得的相应消息都为”同意”</strong>时:</li>
</ul>
<blockquote>
<p>1）协调者节点向所有参与者节点发出”正式提交(commit)”的请求。</p>
<p>2）参与者节点正式完成操作，并释放在整个事务期间内占用的资源。</p>
<p>3）参与者节点向协调者节点发送”完成”消息。</p>
<p>4）协调者节点受到所有参与者节点反馈的”完成”消息后，完成事务。</p>
</blockquote>
<p><img src="/2022/01/01/%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1/13.png"></p>
<p>如果任一参与者节点在第一阶段返回的响应消息为”中止”，或者 协调者节点在第一阶段的询问超时之前无法获取所有参与者节点的响应消息时：</p>
<blockquote>
<p>1）协调者节点向所有参与者节点发出”回滚操作(rollback)”的请求。</p>
<p>2）参与者节点利用之前写入的Undo信息执行回滚，并释放在整个事务期间内占用的资源。</p>
<p>3）参与者节点向协调者节点发送”回滚完成”消息。</p>
<p>4）协调者节点受到所有参与者节点反馈的”回滚完成”消息后，取消事务。</p>
</blockquote>
<p><img src="/2022/01/01/%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1/14.png"></p>
<p>不管最后结果如何，第二阶段都会结束当前事务。</p>
<p>二阶段提交看起来确实能够提供原子性的操作，但是不幸的事，二阶段提交还是有几个<strong>缺点</strong>的：</p>
<blockquote>
<p>1、<strong>同步阻塞问题</strong>。执行过程中，<strong>所有参与节点都是事务阻塞型的</strong>。当参与者占有公共资源时，其他第三方节点访问公共资源不得不处于阻塞状态。</p>
<p>2、<strong>单点故障</strong>。由于协调者的重要性，<strong>一旦协调者发生故障, 参与者会一直阻塞下去</strong>。尤其在第二阶段，协调者发生故障，那么所有的参与者还都处于锁定事务资源的状态中，而无法继续完成事务操作。（如果是协调者挂掉，可以重新选举一个协调者，但是无法解决因为协调者宕机导致的参与者处于阻塞状态的问题）</p>
<p>3、<strong>数据不一致</strong>。在提交阶段中，当协调者向参与者发送commit请求之后，发生了局部网络异常或者在发送commit请求过程中协调者发生了故障，这回导致只有一部分参与者接受到了commit请求。而在这部分参与者接到commit请求之后就会执行commit操作。但是其他部分未接到commit请求的机器则无法执行事务提交。于是整个分布式系统便出现了数据部一致性的现象。</p>
<p>4、二阶段无法解决的问题：协调者再发出commit消息之后宕机，而唯一接收到这条消息的参与者同时也宕机了。那么即使协调者通过选举协议产生了新的协调者，这条事务的状态也是不确定的，没人知道事务是否被已经提交。</p>
</blockquote>
<p>由于二阶段提交存在着诸如同步阻塞、单点问题、脑裂等缺陷，所以，研究者们在二阶段提交的基础上做了改进，提出了三阶段提交。</p>
<h3 id="3PC"><a href="#3PC" class="headerlink" title="3PC"></a>3PC</h3><blockquote>
<p>三阶段提交（Three-phase commit），也叫三阶段提交协议（Three-phase commit protocol），是二阶段提交（2PC）的改进版本。</p>
</blockquote>
<p>与两阶段提交不同的是，三阶段提交有两个改动点。</p>
<ol>
<li><p>引入超时机制。同时在协调者和参与者中都引入超时机制。</p>
</li>
<li><p>在第一阶段和第二阶段中插入一个准备阶段。<strong>保证了在最后提交阶段之前各参与节点的状态是一致的</strong></p>
</li>
</ol>
<p>也就是说，除了引入超时机制之外，3PC把2PC的准备阶段再次一分为二，这样三阶段提交有 <code>CanCommit</code> 、 <code>PreCommit</code> 、 <code>DoCommit</code>三个阶段。</p>
<h4 id="CanCommit阶段"><a href="#CanCommit阶段" class="headerlink" title="CanCommit阶段"></a>CanCommit阶段</h4><p>3PC的CanCommit阶段其实和2PC的准备阶段很像。协调者向参与者发送commit请求，参与者如果可以提交就返回Yes响应，否则返回No响应。</p>
<blockquote>
<p><strong>1.事务询问</strong> 协调者向参与者发送CanCommit请求。询问是否可以执行事务提交操作。然后开始等待参与者的响应。</p>
<p><strong>2.响应反馈</strong> 参与者接到CanCommit请求之后，正常情况下，如果其自身认为可以顺利执行事务，则返回Yes响应，并进入预备状态。否则反馈No</p>
</blockquote>
<p>优点：不像2pc 第一个阶段就开始锁表，3pc的阶段一是为了先排除个别参与者不具备提交事务能力的前提下，而避免锁表。</p>
<h4 id="PreCommit阶段"><a href="#PreCommit阶段" class="headerlink" title="PreCommit阶段"></a>PreCommit阶段</h4><p>协调者根据参与者的反应情况来决定是否可以执行事务的PreCommit操作。根据响应情况，有以下两种可能。</p>
<p><strong>假如协调者从所有的参与者获得的反馈都是Yes响应，那么就会执行事务的预执行。</strong></p>
<blockquote>
<p><strong>1.发送预提交请求</strong> 协调者向参与者发送PreCommit请求，并进入Prepared阶段。</p>
<p><strong>2.事务预提交</strong> 参与者接收到PreCommit请求后，会执行事务操作，并将undo和redo信息记录到事务日志中。</p>
<p><strong>3.响应反馈</strong> 如果参与者成功的执行了事务操作，则返回ACK响应，同时开始等待最终指令。</p>
</blockquote>
<p><strong>假如有任何一个参与者向协调者发送了No响应;  或者等待超时之后，协调者都没有接到参与者的响应，那么就执行事务的中断。</strong></p>
<blockquote>
<p><strong>1.发送中断请求</strong> 协调者向所有参与者发送abort请求。</p>
<p><strong>2.中断事务</strong> 参与者收到来自协调者的abort请求之后（或超时之后，仍未收到协调者的请求），执行事务的中断。</p>
</blockquote>
<h4 id="doCommit阶段"><a href="#doCommit阶段" class="headerlink" title="doCommit阶段"></a>doCommit阶段</h4><p>该阶段进行真正的事务提交，也可以分为以下两种情况。</p>
<p><strong>执行提交</strong></p>
<blockquote>
<p><strong>1.发送提交请求</strong> 协调接收到参与者发送的ACK响应，那么他将从预提交状态进入到提交状态。并向所有参与者发送doCommit请求。</p>
<p><strong>2.事务提交</strong> 参与者接收到doCommit请求之后，执行正式的事务提交。并在完成事务提交之后释放所有事务资源。</p>
<p><strong>3.响应反馈</strong> 事务提交完之后，向协调者发送Ack响应。</p>
<p><strong>4.完成事务</strong> 协调者接收到所有参与者的ack响应之后，完成事务。</p>
</blockquote>
<p><strong>中断事务</strong> 协调者没有接收到参与者发送的ACK响应（可能是接受者发送的不是ACK响应，也可能响应超时），那么就会执行中断事务。</p>
<blockquote>
<p><strong>1.发送中断请求</strong> 协调者向所有参与者发送abort请求</p>
<p><strong>2.事务回滚</strong> 参与者接收到abort请求之后，利用其在阶段二记录的undo信息来执行事务的回滚操作，并在完成回滚之后释放所有的事务资源。</p>
<p><strong>3.反馈结果</strong> 参与者完成事务回滚之后，向协调者发送ACK消息</p>
<p><strong>4.中断事务</strong> 协调者接收到参与者反馈的ACK消息之后，执行事务的中断。</p>
</blockquote>
<p><img src="/2022/01/01/%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1/15.png"></p>
<h3 id="2PC与3PC的区别"><a href="#2PC与3PC的区别" class="headerlink" title="2PC与3PC的区别"></a>2PC与3PC的区别</h3><p>相对于2PC，3PC<strong>主要解决的单点故障问题</strong>，并减少阻塞。在2PC中，只有协调者有超时机制；但是在3PC中，协调者和参与者都有超时机制，因此即使因为网络原因协调者与参与者断开通信， 参与者在超时后也会自动提交commit，这样防止了一直锁表的风险，而不会一直持有事务资源并处于阻塞状态。</p>
<p>但是这种机制也会导致数据一致性问题，因为，由于网络原因，协调者发送的abort响应没有及时被参与者接收到，那么参与者在等待超时之后执行了commit操作。这样就和其他接到abort命令并执行回滚的参与者之间存在数据不一致的情况。</p>
<hr>
<p>了解了2PC和3PC之后，我们可以发现，无论是二阶段提交还是三阶段提交都无法彻底解决分布式的一致性问题。Google Chubby的作者Mike Burrows说过， <code>there is only one consensus protocol, and that’s Paxos” – all other approaches are just broken versions of Paxos.</code> 意即<strong>世上只有一种一致性算法，那就是Paxos</strong>，所有其他一致性算法都是Paxos算法的不完整版</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><img src="/2022/01/01/%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1/16.png"></p>

          
        
      
    </div>
    
    
    
    <div>
      
    </div>
    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://jasonxqh.github.io/2021/12/23/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%86%E5%89%B2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jason">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/%5Bobject%20Object%5D">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jason‘s Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/12/23/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%86%E5%89%B2/" itemprop="url">计算机视觉-检测和分割</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2021-12-23T13:12:16+08:00">
                2021-12-23
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified&#58;</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2022-06-25T23:31:00+08:00">
                2022-06-25
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="计算机视觉-检测和分割"><a href="#计算机视觉-检测和分割" class="headerlink" title="计算机视觉-检测和分割"></a>计算机视觉-检测和分割</h1><p>在第一章我们了解过常见的CV任务，主要有：图像分类、语义分割、分类+定位、目标检测、实例分割</p>
<p><img src="/2021/12/23/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%86%E5%89%B2/1.jpg" style="zoom:80%;"></p>
<h2 id="图像分类"><a href="#图像分类" class="headerlink" title="图像分类"></a>图像分类</h2><p>CV最常见的就是图像分类了，比如说利用AlexNet对图像进行分类，最后输出对图像的预测分数</p>
<p><img src="/2021/12/23/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%86%E5%89%B2/2.jpg" style="zoom:80%;"></p>
<p>在图像分类的基础上，延伸出来几个其他作用，下面一一介绍</p>
<h2 id="语义分割"><a href="#语义分割" class="headerlink" title="语义分割"></a>语义分割</h2><p>语义分割就是对于输入的图片，将每一个像素划分成一个类别。如下：</p>
<p><img src="/2021/12/23/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%86%E5%89%B2/3.jpg" style="zoom:80%;"></p>
<h4 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h4><p>那么语义分割怎么做呢？</p>
<p>对于图像分类，是对图像整体进行类别预测，而对于语义分割，是对每一个像素进行分类。同时，不区分相同类别的个体。</p>
<h4 id="Naive-Idea-滑窗"><a href="#Naive-Idea-滑窗" class="headerlink" title="Naive Idea: 滑窗"></a>Naive Idea: 滑窗</h4><p><img src="/2021/12/23/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%86%E5%89%B2/7.png" style="zoom:80%;"></p>
<p>我们可以拿一个窗口再图像上滑动，每次滑动一个像素点，然后用CNN去判断这个滑窗属于什么类别，然后将滑窗的中心点划为这个类。</p>
<p>虽然利用滑窗可以达到比较好的效果，但是这个方法的计算代价及其昂贵</p>
<h4 id="对所有像素点同时进行预测"><a href="#对所有像素点同时进行预测" class="headerlink" title="对所有像素点同时进行预测"></a>对所有像素点同时进行预测</h4><p>我们可以对整个图像进行卷积</p>
<p><img src="/2021/12/23/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%86%E5%89%B2/8.png" style="zoom:80%;"></p>
<p>将损失函数定义为 对所有像素点进行分类的交叉熵之和，然后最小化损失函数得到预测结果。这个方法相比于滑窗效率有所提升，但是对内存的要求很大，卷积计算依然昂贵。</p>
<p>因此我们要在中间过程中对feature map 进行下采样，得到隐层向量，然后再进行上采样复原图片，进行损失函数的计算。</p>
<p><img src="/2021/12/23/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%86%E5%89%B2/9.png" style="zoom:80%;"></p>
<h4 id="上采样"><a href="#上采样" class="headerlink" title="上采样"></a>上采样</h4><p>下采样是池化和卷积，上采样就是下采样的逆转方法——反池化和反卷积。</p>
<p>比如说，反池化有几种选择：我们可以将一个元素的邻居都赋相同的值，也可以将只赋值给区域中的固定位置，其他位置设为0</p>
<p><img src="/2021/12/23/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%86%E5%89%B2/10.png" style="zoom:80%;"></p>
<p>当然，还有一种就是借鉴池化反向传播的方法，将值赋给池化时的对应位置</p>
<p><img src="/2021/12/23/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%86%E5%89%B2/11.png" style="zoom:80%;"></p>
<p>不管是max unpooling, nearest neigbor 还是Bed of Nails，都和池化一样是没有参数的。 还有一种上采样方法：deconvolution,则需要用参数，而且是可学习的。</p>
<p>如下图， 我们将输入值乘以一个 $3\times 3$的”反卷积核” ，就相当于”扩张”了。如下图所示：</p>
<p><img src="/2021/12/23/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%86%E5%89%B2/12.png" style="zoom:80%;"></p>
<p>然后，对每个输入值乘以卷积核，并对重叠的位置进行累积(当然平均也可以)，得到上采样后的结果，可以得到如下图所示：</p>
<p><img src="/2021/12/23/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%86%E5%89%B2/13.png" style="zoom:80%;"></p>
<h2 id="分类-定位"><a href="#分类-定位" class="headerlink" title="分类+定位"></a>分类+定位</h2><p>分类加定位(单目标检测)，就是识别出一张图片最主要的对象，然后框起来。如下</p>
<p><img src="/2021/12/23/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%86%E5%89%B2/4.jpg" style="zoom:80%;"></p>
<h3 id="方法-1"><a href="#方法-1" class="headerlink" title="方法"></a>方法</h3><p><img src="/2021/12/23/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%86%E5%89%B2/14.png" style="zoom:80%;"></p>
<p>和图像分类的区别就在于，经过卷积之后，需要做两个全连接层，一个全连接层做的工作是分类，另一个则是输出一个长度为4向量，代表了这个框的四个坐标。这样就完成了分类的预测和定位的预测。</p>
<p>分类的预测用softmax 损失函数，定位的预测用L2损失函数(回归)，将这两个损失函数相加，共同优化，得到最终的结果。</p>
<p>因此，理论上只要有固定数量的点位，我们都可以对其进行预测。这项技术可以用于姿态估计</p>
<p><img src="/2021/12/23/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%86%E5%89%B2/15.png" style="zoom:80%;"></p>
<h2 id="目标检测"><a href="#目标检测" class="headerlink" title="目标检测"></a>目标检测</h2><p>将分类+定位中的单个物体拓展为多个物体，就变成了目标检测任务</p>
<p><img src="/2021/12/23/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%86%E5%89%B2/5.png" style="zoom: 50%;"></p>
<h3 id="方法-2"><a href="#方法-2" class="headerlink" title="方法"></a>方法</h3><p>在进行分类+定位任务的时候，我们可以将问题简化为预测5个值(类别以及框的定位)；但是对于目标检测任务，由于一张图片中存在多个目标，我事先是不知道有多少物体的，因此需要预测很多数值以及很多类别。</p>
<h4 id="Naive-idea"><a href="#Naive-idea" class="headerlink" title="Naive idea"></a>Naive idea</h4><p>一个朴素的额方法就是，用不同的大小、位置、长宽比的矩形区域对图片进行卷积计算，用来预测类别以及框框位置。但很显然这种方法的代价极其昂贵。</p>
<p><img src="/2021/12/23/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%86%E5%89%B2/16.png" style="zoom: 100%;"></p>
<h4 id="R-CNN"><a href="#R-CNN" class="headerlink" title="R-CNN"></a>R-CNN</h4><p>因此我们设想，可不可以预先寻找一些可能存在物体的区域？ 这就是 Region Proposals(RP)</p>
<p>我们可以用 Selective Search 这种传统的图形学算法，来找到几个很可能存在物体的区域。通常速度为 2000区域/秒</p>
<p><img src="/2021/12/23/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%86%E5%89%B2/17.png" style="zoom: 100%;"></p>
<p>在一张图片中经过RP之后，会在图片上标记出一些区域，我们称其为(Regions of Interest,ROI) 由于区域大小存在差异，因此会先转换成大小统一的feature map</p>
<p>然后经过CNN 对每一个区域进行分类以及利用回归来校正 ROI 的坐标</p>
<p><img src="/2021/12/23/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%86%E5%89%B2/18.png" style="zoom: 100%;"></p>
<p>虽然这个算法效果非常好，肯定包含了我们需要检测的目标，但是，这种方法也很慢，需要对至少好几千个ROI分别做卷积。</p>
<h4 id="Fast-R-CNN"><a href="#Fast-R-CNN" class="headerlink" title="Fast R-CNN"></a>Fast R-CNN</h4><p>为了优化上面这个算法，我们可以先卷积，后RP，这就是所谓的 Fast R-CNN . 示意图如下：</p>
<p><img src="/2021/12/23/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%86%E5%89%B2/19.png" style="zoom: 100%;"></p>
<h4 id="Faster-R-CNN"><a href="#Faster-R-CNN" class="headerlink" title="Faster R-CNN"></a>Faster R-CNN</h4><p>比 Fast R-CNN更快的，是Faster R-CNN。 这种方法优化了RP方法，使用RPN来进行物体检测。其示意图如下：</p>
<p><img src="/2021/12/23/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%86%E5%89%B2/20.png" style="zoom: 100%;"></p>
<p>该方法使用了4个损失函数：</p>
<ul>
<li>RPN 是否包含物体</li>
<li>RPN 边框坐标</li>
<li>物体的最终类别</li>
<li>边框的额最终目标</li>
</ul>
<p>RPN 不同于传统的图像算法，<strong>是基于数据驱动、会不断优化自己的</strong>。训练完成以后，当RPN得到了feature map，它会去<strong>预测</strong>到底哪些区域是存在目标物体的，而不是使用selective search的方法去检索。</p>
<p>因此，到最后PR会被优化成一个线性计算，效率会非常高。</p>
<p>那么，RPN 是怎么被训练的呢？</p>
<p>首先，得到了一个 20x15 的feature map，我们就将其划分为20x15个block. </p>
<p>接着，我们把每一个block 为中心，构建一个 anchor box. 如下图所示</p>
<p><img src="/2021/12/23/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%86%E5%89%B2/23.png" style="zoom: 100%;"></p>
<p>然后，我们去预测每个anchor box 里面是否包含物体。也就是输出 $1\times20\times15$ 个预测数据</p>
<p>在预测是否包含物体的时候，还需要预测每一个anchor box的真是坐标，因此又要输出$4\times20\times15$个数据</p>
<p>通常，每一个像素点，有k 个大小不同的anchor box 需要我们去预测，因此，还要在原来的基础上乘以 $K$ </p>
<p>最后，我们会选取<strong>含物体概率最高</strong>的100个区域作为 Region  Proposal</p>
<p><img src="/2021/12/23/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%86%E5%89%B2/22.png" style="zoom: 100%;"></p>
<p>整个训练一共分为两个阶段</p>
<ul>
<li>第一阶段<ul>
<li>CNN 提取 feature</li>
<li>RPN</li>
</ul>
</li>
<li>第二阶段<ul>
<li>ROI Pooling</li>
<li>分类</li>
<li>回归(校正 ROI)</li>
</ul>
</li>
</ul>
<p><img src="/2021/12/23/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%86%E5%89%B2/21.png" style="zoom: 100%;"></p>
<h4 id="YOLO"><a href="#YOLO" class="headerlink" title="YOLO"></a>YOLO</h4><p>YOLO 是 You Only Look Once 的缩写。</p>
<p>YOLO 是直接在图片上划分出base boxes(类似于anchor boxes),对每个base box进行回归，并预测这个框有多大概率真的包含目标物体(背景)。</p>
<p>YOLO在实际项目中的效果是很好的，比faster R-CNN更快。但是由于没有提取feature map，所以精度会差一点</p>
<p><img src="/2021/12/23/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%86%E5%89%B2/24.png" style="zoom: 100%;"></p>
<p><a href="https://arxiv.org/pdf/1512.02325.pdf" target="_blank" rel="noopener">SSD: Single-Shot MultiBox Detector</a></p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul>
<li><p>Feature 提取网络</p>
<ul>
<li>VGG 16</li>
<li>ResNet-101</li>
<li>Inception V2</li>
<li>Inception V3</li>
<li>Mobile Net</li>
</ul>
</li>
<li><p>主体结构</p>
<ul>
<li>两阶段： Faster R-CNN</li>
<li>一阶段: YOLO/SSD</li>
<li>混合：R-FCN</li>
</ul>
</li>
<li><p>经验总结</p>
<ul>
<li><p>Faster R-CNN 相对较慢但精度较高</p>
</li>
<li><p>YOLO/SSD 速度更快，但精度较低</p>
</li>
<li><p>Feature 提取可以使用更深更大的模型</p>
</li>
</ul>
</li>
</ul>
<h2 id="实例分割"><a href="#实例分割" class="headerlink" title="实例分割"></a>实例分割</h2><p>在实例分割任务中，需要将检测到的目标用不同的颜色标注出来。但在语义分割里面，可能这些目标都是一个颜色的。</p>
<p><img src="/2021/12/23/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%86%E5%89%B2/26.png"></p>
<h3 id="方法-3"><a href="#方法-3" class="headerlink" title="方法"></a>方法</h3><p>实例分割就是将前面的一些方法整合起来。其中最经典的一个模型就是Mask R-CNN</p>
<h4 id="Mask-R-CNN"><a href="#Mask-R-CNN" class="headerlink" title="Mask R-CNN"></a>Mask R-CNN</h4><p>Mask R-CNN前面的结构和Faster R-CNN 非常像</p>
<p>先利用目标检测的方法，检测图片中那些区域可能存在物体</p>
<p>再利用语义分割的方法，将这个区域里面的像素点进行分类</p>
<p><img src="/2021/12/23/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%86%E5%89%B2/25.png"></p>
<p><a href="https://openaccess.thecvf.com/content_ICCV_2017/papers/He_Mask_R-CNN_ICCV_2017_paper.pdf" target="_blank" rel="noopener">https://openaccess.thecvf.com/content_ICCV_2017/papers/He_Mask_R-CNN_ICCV_2017_paper.pdf</a></p>
<h2 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h2><p><img src="/2021/12/23/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%86%E5%89%B2/27.png"></p>

          
        
      
    </div>
    
    
    
    <div>
      
    </div>
    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://jasonxqh.github.io/2021/12/22/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jason">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/%5Bobject%20Object%5D">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jason‘s Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/12/22/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/" itemprop="url">计算机视觉-图像分类</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2021-12-22T22:26:57+08:00">
                2021-12-22
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified&#58;</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2022-03-07T22:56:50+08:00">
                2022-03-07
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="计算机视觉-图像分类"><a href="#计算机视觉-图像分类" class="headerlink" title="计算机视觉-图像分类"></a>计算机视觉-图像分类</h1><p>在上一节课我们主要讲了计算机视觉的最主要的几个任务：图像分类、定位+分割、目标检测、语义分割、实例分割。现在我们来着重看计算机视觉中最基础的任务——图像分类。有了图像分类，我们才可以做定位+分割、目标检测等更高阶的任务。</p>
<h2 id="图像分类任务"><a href="#图像分类任务" class="headerlink" title="图像分类任务"></a>图像分类任务</h2><p>图像分类任务，顾名思义，就是对于一张输入的图片，通过某种方法让计算机算出这张图片属于什么类型。比如说一张狗图，对于人脑而言，可以很简单的辨别出它是狗；但是对计算机来说，它只能给出一组概率，比如说狗的概率0.8, 猫的概率0.1,狼的概率0.1，最终判断它是狗</p>
<p><img src="/2021/12/22/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/1.png" alt="1" style="zoom:67%;"></p>
<h3 id="对计算机的挑战"><a href="#对计算机的挑战" class="headerlink" title="对计算机的挑战"></a>对计算机的挑战</h3><h4 id="语义鸿沟"><a href="#语义鸿沟" class="headerlink" title="语义鸿沟"></a>语义鸿沟</h4><p>其实，这任务对计算机来说是比较困难的，因为涉及到<strong>语义鸿沟</strong>，对于计算机来说，图片对他来说只是有一个一个像素组成的，每个像素都是一组 $[0,255]$的数字。如下所示：</p>
<p><img src="/2021/12/22/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/2.png" style="zoom:67%;"></p>
<h4 id="尺度、视角差异"><a href="#尺度、视角差异" class="headerlink" title="尺度、视角差异"></a>尺度、视角差异</h4><p>当对一个物体的拍摄距离或者拍摄角度产生变化的时候，对人脑而言可能很快就能意识到只是尺度发生了变化，但是物体还是一样的。但是对于计算机来说，他所看到的像素点可能发生了天翻地覆的变化，因此这也是一大难题</p>
<h4 id="类内差异"><a href="#类内差异" class="headerlink" title="类内差异"></a>类内差异</h4><p>因为狗有很多品种，不同品种的狗可能样貌、体型、颜色会有很大的变化，大脑可以马上明白过来这虽然是不同的品种，但都属于狗这一类。但对于计算机来说，就可能将它们划归为不同的类去了。</p>
<h4 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h4><p><img src="/2021/12/22/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/3.png" alt="1" style="zoom:67%;"></p>
<h2 id="传统方法"><a href="#传统方法" class="headerlink" title="传统方法"></a>传统方法</h2><p>传统方法是利用边缘检测方法，将图片转换成边和线。然后，我们需要在这些边和线中找出可以被捕获到的特征，比如眼睛、鼻子、毛发等。根据这些特征去判断图片中的物体是否属于狗。            </p>
<p><img src="/2021/12/22/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/4.png" style="zoom:67%;"></p>
<p>但是这种算法，存在很大的缺陷：</p>
<ol>
<li>鲁棒性很差，对于不同的光线、角度、背景，可能会失效</li>
<li>可扩展性很差(延展性较差)，需要为每一种物体设计专门的算法。</li>
<li>需要我们 Hard code</li>
</ol>
<h2 id="数据驱动的方法"><a href="#数据驱动的方法" class="headerlink" title="数据驱动的方法"></a>数据驱动的方法</h2><p>传统方法的局限性迫使我们找到高效的，基于数据驱动的方法。构建一个模型的的基本步骤如下：</p>
<p><img src="/2021/12/22/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/5.png" style="zoom:67%;"></p>
<h3 id="NN-Nearest-Neighbor"><a href="#NN-Nearest-Neighbor" class="headerlink" title="NN(Nearest Neighbor)"></a>NN(Nearest Neighbor)</h3><p>我们 现在来介绍第一个算法：NN。 它是一个<strong>香草分类器</strong>，也就是最简单的分类器。</p>
<p>在训练阶段，它会存储下所有的图像和标签。在测试阶段，对于每一个样本，都会遍历所有的类，计算样本和类之间的距离，然后使用距离最近的图像的标签来预测新图像的标签。</p>
<p>我们常常用的是 L1距离(曼哈顿距离)</p>
<p><img src="/2021/12/22/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/6.png" style="zoom:67%;"></p>
<p>效果展示，我们根据像素之间的距离将其分为了不同的颜色，代表了不同的类。我们发现，几个红点很明显被紫色包围了，但是分类器还是将其分成了红色的点。这些离群值会导致整个分类器并不是很稳定。</p>
<p><img src="/2021/12/22/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/7.png" style="zoom:67%;"></p>
<p>我们发现，</p>
<h3 id="KNN"><a href="#KNN" class="headerlink" title="KNN"></a>KNN</h3><p>KNN 和NN 不同，NN是只计算最近的邻居是谁，而 KNN 是计算K个距离最近的邻居，并从中找到占据多数的类别作为预测结果</p>
<p><img src="/2021/12/22/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/8.png" style="zoom:67%;"></p>
<p>我们发现，使用KNN的方法中间会有空白部分。这可能是因为，这一块区域里。到相邻几类的距离事项等的，因此分类器没办法判别到底是哪一类。</p>
<h3 id="距离选择"><a href="#距离选择" class="headerlink" title="距离选择"></a>距离选择</h3><p>除了L1距离，我们还可以用L2距离(欧氏距离)：</p>
<p><img src="/2021/12/22/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/9.png"></p>
<p><img src="/2021/12/22/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/10.png"></p>
<h4 id="超参数"><a href="#超参数" class="headerlink" title="超参数"></a>超参数</h4><p>那么，对于K-NN中的超参数K，我们又该怎么去选择呢？</p>
<ul>
<li>猜想1：我们可以是模型在整个数据集上表现最好</li>
</ul>
<p>这是不行的，这会导致超参数在现有数据集上完美分类，造成过拟合。举一个极端的例子，我们如果去k=1，那么对于所有点来说，都属于同一类，那么k=1在这个情况下是完美的超参，但这显然是很荒唐的</p>
<ul>
<li>猜想2：使模型在测试集上表现最好</li>
</ul>
<p>这也是不行的，因为这就相当于看到了答案反推模型，我调参的目的就是服务于测试集，这会污染我们的模型，是一种<strong>作弊行为</strong>。可想而知，用这种方法做出来的模型在测试集上会有很好的表现，但是，在其他数据集上的表现会很拉跨。</p>
<ul>
<li>猜想3：如下图所示</li>
</ul>
<p><img src="/2021/12/22/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/12.png"></p>
<p>我们将数据划分为训练集、验证集和测试集，三者隔离开来。我们在验证集上找到最好的表现，然后将模型应用于测试集，查看最终表现。这样test中的数据就不会对算法本身造成影响，在接触到测试集前，模型对其一无所知，这样才能”毫无干扰“得做出预测。</p>
<ul>
<li>猜想4：交叉验证(cross validation), 这是在第三种方法基础上的衍生，我们可以将数据集拆分成更多块，并获得更好的泛化性能。如下图所示，我们将每一块成为一个Fold。对于每一个Fold，我们都会有一次机会把它作为验证器，其他Folds作为训练集，对于每一次训练，都会获得一组最好的超参数组合。最后我们取其所长，获得最后的超参搭配</li>
</ul>
<p><img src="/2021/12/22/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/11.png"></p>
<p>但是对于大型数据和深度学习较少使用这种方法。因为训练起来会比较麻烦。</p>
<h4 id="超参选择可视化"><a href="#超参选择可视化" class="headerlink" title="超参选择可视化"></a>超参选择可视化</h4><p><img src="/2021/12/22/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/13.png"></p>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>(K)NN 方法的优点很简洁明了：简单</p>
<p>同时，KNN也存在很多缺点：</p>
<ul>
<li><p>训练阶段时简单的标签记忆</p>
<ul>
<li>预测效率低下(20%左右)，训练时需要$O(N)$的复杂度</li>
<li>lazy learner,在训练阶段并不会做任何泛化；而图片分类需要具备一定的泛化能力的分类器</li>
</ul>
</li>
<li><p>像素距离和图像信息之间存在语义鸿沟</p>
<ul>
<li>图像像素相近(颜色相近)并不等于 图像包含的信息接近</li>
</ul>
</li>
<li><p>对训练集数据分布要求会很高、</p>
<ul>
<li>首先我们要知道，只要点够多，KNN在训练的时候可以近似于任何曲线(可以推广到平面)。但是点不够平均的话，KNN模拟出来的函数会误差很大。</li>
</ul>
<p><img src="/2021/12/22/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/14.png"></p>
<p><img src="/2021/12/22/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/15.png"></p>
<ul>
<li>为了提高模型预测的准确率，我们的训练集需要在整个像素空间中均匀分布，导致维度诅咒(curse of dimensionality)。也就是说只要增加一个维度，就需要对数据集扩大指数倍才能满足训练的需要。</li>
</ul>
</li>
</ul>
<h3 id="Linear-classifier"><a href="#Linear-classifier" class="headerlink" title="Linear classifier"></a>Linear classifier</h3><p><img src="/2021/12/22/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/16.png"></p>
<p>当然，线性分类器也有很难应用的数据分布：</p>
<p><img src="/2021/12/22/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/17.png"></p>

          
        
      
    </div>
    
    
    
    <div>
      
    </div>
    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://jasonxqh.github.io/2021/12/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%92%8C%E4%BC%98%E5%8C%96/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jason">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/%5Bobject%20Object%5D">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jason‘s Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/12/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%92%8C%E4%BC%98%E5%8C%96/" itemprop="url">计算机视觉-损失函数和优化</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2021-12-20T21:05:51+08:00">
                2021-12-20
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified&#58;</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2021-12-27T12:24:44+08:00">
                2021-12-27
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="损失函数和优化"><a href="#损失函数和优化" class="headerlink" title="损失函数和优化"></a>损失函数和优化</h1><h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><p>对于线性分类器，常常需要定义一个衡量输出分数好坏的函数——<strong>损失函数</strong>。然后，我们可以通过这个损失函数，去反推参数，最终让损失函数达到最小值，这就是<strong>优化</strong>的过程。</p>
<p>我们来举一个例子：</p>
<p>我们令训练集为 ${(x<em>i,y_i )}</em>{i=1}^N$ , $x_i$ 为第i个图片，$y_i\in Z$ 为它的类别标签；$f(\boldsymbol W,\boldsymbol x_i)$ 为第i个图片的输出分数, $\boldsymbol W$ 是权重矩阵，计算公式如下所示：</p>
<p><img src="/2021/12/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%92%8C%E4%BC%98%E5%8C%96/5.png"></p>
<p>由此，我们可以计算损失函数</p>
<ul>
<li>第 i 条数据的损失函数 $L_i = l(f(\boldsymbol W,\boldsymbol x_i),y_i)$</li>
<li>训练样本总体损失 $L = \frac{1}{N}\sum_{i=1}^N L_i$ </li>
</ul>
<p>接下来我们来介绍两种线性分类器常用的损失函数 </p>
<h3 id="SVM-Loss"><a href="#SVM-Loss" class="headerlink" title="SVM Loss"></a>SVM Loss</h3><p>SVM loss 也叫做 multiclass SVM loss, 首先我们给出定义：</p>
<ol>
<li><p>训练集为 ${(x<em>i,y_i )}</em>{i=1}^N$ , $x_i$ 为第i个图片，$y_i\in Z$ 为它的类别标签</p>
</li>
<li><p>我们令 $\boldsymbol s = f(\boldsymbol W,\boldsymbol x_i)$, 即图片i的所有类别分数</p>
</li>
<li><p>然后，我们令 SVM loss为： $L<em>i = \sum</em>{j\neq y<em>i}\max(0,s_j-s</em>{y_i}+1)$ </p>
<ul>
<li>$s_j$ 代表第 $i$ 张图片在第 $j$ 个分类上的分数</li>
<li>$s_{y_i}$ 代表这张图片原来类别的分数 </li>
</ul>
</li>
</ol>
<p>为什么要加上1这个常数呢？</p>
<p>答：如果不加上1，想得到0损失的话，那么只要正确类别的分数比其他所有错误类别的分数大就可以了，具体大多少不用管。因此可能出现两个类的分数很接近，正确的类别并不突出。如果加上1以后，至少要让正确类别的分数比其他类别的分数大1。也就是<strong>进一步拉大正确类别与错误类别的差距</strong>，让模型更加高效。</p>
<p>如果全部正确得对图片进行分类，此时对所有的 $s<em>j$ 肯定是远小于 $s</em>{y<em>i}$ 的。因此此时$L_i = \sum</em>{j\neq y_i}0= 0$ </p>
<p>画出图像后我们发现，SVM loss的函数形状就像一个铰链一样，因此也被称为 Hinge Loss</p>
<p><img src="/2021/12/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%92%8C%E4%BC%98%E5%8C%96/2.png" style="zoom:67%;"></p>
<h4 id="实例计算"><a href="#实例计算" class="headerlink" title="实例计算"></a>实例计算</h4><p>现在，我们可以通过一个具体的例子来计算svm loss</p>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th>狗图片1</th>
<th>猫图片1</th>
<th>狼图片1</th>
<th>狗图片1</th>
</tr>
</thead>
<tbody>
<tr>
<td>狗</td>
<td><strong>7.9</strong></td>
<td>3.3</td>
<td>-1.1</td>
<td><strong>2.3</strong></td>
</tr>
<tr>
<td>猫</td>
<td>5.8</td>
<td><strong>-0.8</strong></td>
<td>3.4</td>
<td>1.5</td>
</tr>
<tr>
<td>狼</td>
<td>-1.9</td>
<td>6.5</td>
<td><strong>2.5</strong></td>
<td>4.4</td>
</tr>
</tbody>
</table>
</div>
<p>图片1-4的loss:</p>
<script type="math/tex; mode=display">
\begin{align}
&L_1 = \max(0,5.8-7.9+1)+\max(0,-1.9-7.9+1)=0\\
&L_2 = \max(0,3.3-(-0.8)+1)+\max(0,6.5-(-0.8)+1)=13.4\\
&L_3 = \max(0,-1.1-2.5+1)+\max(0,3.4-2.5+1)=1.9\\
&L_4 = \max(0,1.5-2.3+1)+\max(0,4.4-2.3+1)=3.3\\
\end{align}</script><p>总的loss:</p>
<script type="math/tex; mode=display">
L = \frac{1}{N}\sum_{i=1}^N L_i = \frac{1}{4}(0+13.4+1.9+3.3) = 4.65</script><h5 id="QA"><a href="#QA" class="headerlink" title="QA"></a>QA</h5><p>Q : 如果输出分数发生微小改变(比如$\pm0.001$)，对SVM loss的计算会造成什么影响</p>
<p>A : $s<em>j-s</em>{y_i}&lt;-1$ 时，没有影响。反之，会略为改变损失函数的值</p>
<hr>
<p>Q: SVM 损失函数的最大值和最小值分别为多少</p>
<p>A: 最小值为0(全分对)，最大值为正无穷(理论上)，可用于代码 正确性检查</p>
<hr>
<p>Q: 加入初始化 $\boldsymbol W$ 接近0，导致所有输出分数都$\approx 0$,那么$L_i$ 约等于多少？</p>
<p>A: 由公式可得：$L<em>i = \sum</em>{j\neq y_i}\max(0-0+1)$ 。 因此此时 $L_i$ 的分数为 $C-1$， $C$ 为类别数，这里为 $3-1=2$ 。此问题也可以用于代码检测</p>
<hr>
<p>Q: 加入去掉$j\neq y_i$ 的限制，损失函数该如何变化？</p>
<p>A: 损失函数会增加1</p>
<hr>
<p>Q: 加入在$L<em>i$中使用$\max(s_j-s</em>{y<em>i}+2)$ 代替 $\max(s_j-s</em>{y_i}+1)$ ，有什么影响？</p>
<p>A: 不会改变分类的结果，SVM loss 只关注输出分数之间的差异，这里的常数只起到scale参数的作用，会导致权重矩阵的变化。</p>
<hr>
<p>Q: 加入 $\boldsymbol W$ 使得 $L=0$ (完美)，轻微 $\boldsymbol W$ 是否唯一？</p>
<p>A: 不唯一，因为$\boldsymbol W\times c $ 也可以使得$L=0$, $c$ 为任意正整数。因为权重矩阵的整体放大是不会影响到结果的。我们可以通过添加正则项来选取更好的 $\boldsymbol W $ ,增强模型的泛化能力</p>
<h3 id="Softmax-Loss"><a href="#Softmax-Loss" class="headerlink" title="Softmax Loss"></a>Softmax Loss</h3><p>第二个常用的损失函数是 softmax loss(cross-entropy loss). 用这个损失函数构造的分类器也被称为是Softmax分类器(多类别逻辑回归)</p>
<p>我们同样给出定义：</p>
<ol>
<li><p>训练集为 ${(x<em>i,y_i )}</em>{i=1}^N$ , $x_i$ 为第i个图片，$y_i\in Z$ 为它的类别标签</p>
</li>
<li><p>我们令 $\boldsymbol s = f(\boldsymbol W,\boldsymbol x_i)$, 即图片i的所有类别分数</p>
</li>
<li><p>softmax loss ：</p>
<script type="math/tex; mode=display">
L_i = -\log (\frac{e^{s_{y_i}}}{\sum_j e^{s_j}})</script><ul>
<li>同样的，$s_{y_i}$ 代表这张图片原来类别的分数 </li>
<li>$s_j$ 代表第 $i$ 张图片在第 $j$ 个分类上的分数</li>
</ul>
</li>
</ol>
<p>如果是正确分类的话，$s<em>{y_i}$是特别大的，因此 $(\frac{e^{s</em>{y_i}}}{\sum_j e^{s_j}})$ 接近于1，$L_i$ 就接近于0</p>
<h4 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h4><h5 id="交叉熵"><a href="#交叉熵" class="headerlink" title="交叉熵"></a>交叉熵</h5><p>首先我们要了解交叉熵的概念</p>
<p>我们知道熵(entropy) 是用来衡量概率<strong>分布Q</strong>的不确定性的:</p>
<script type="math/tex; mode=display">
H(Q) = -\sum_i q_i \log q_i</script><p>那么交叉熵(Cross-entropy) 则是用来衡量概率<strong>分布P</strong>服从概率<strong>分布Q</strong>的不确定性,就是把对数后面的q改为p：</p>
<script type="math/tex; mode=display">
H(Q,P) = -\sum_{i}q_i\log p_i</script><p>比如说这里有个例子：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th>晴天</th>
<th>多云</th>
<th>下雨</th>
</tr>
</thead>
<tbody>
<tr>
<td>真实天气</td>
<td>50%</td>
<td>30%</td>
<td>20%</td>
</tr>
<tr>
<td>天气预报</td>
<td>40%</td>
<td>30%</td>
<td>30%</td>
</tr>
</tbody>
</table>
</div>
<p>可以计算真实天气的不确定性：</p>
<script type="math/tex; mode=display">
H(\text{真实}) = -(0.5\log(0.5)+0.3\log(0.3)+0.2\log(0.2))=0.45</script><p>当只有一种天气的时候，可知： $H(真实) = -(1\log 1) = 0$ </p>
<p>利用交叉熵，可以计算天气预报服从真是天气的不确定性：</p>
<script type="math/tex; mode=display">
H(真实,预报) = -(0.5\log(0.4)+0.3\log(0.3)+0.2\log(0.3)) = 0.46</script><p>正常情况下，我们是利用 KL 散度(相对熵)来衡量两者分布的差异性：</p>
<script type="math/tex; mode=display">
D_{KL} (Q||P) = H(Q,P)-H(Q) = -\sum q_i\log p_i-(-\sum_i q_i\log q_i) =\sum_i q_i\log\frac{q_i}{p_i}</script><p>但在计算softmax loss时，我们只考虑交叉熵的计算即可。因为在图像分类场景下，真实的分类是确定的, $H(\text{真实})=0$ , 所以说交叉熵和KL散度在图像分类情况下是等价的</p>
<h5 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h5><p>首先，我们可以将分数通过 softmax 函数转换为概率，即：</p>
<script type="math/tex; mode=display">
\begin{align}
&\text{分数}: \boldsymbol s = f(\boldsymbol W,\boldsymbol x_i)\\
&\text{概率}: P(y=k|x_i) = \frac{e^{s_k}}{\sum_j e^{s_j}}
\end{align}</script><p><img src="/2021/12/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%92%8C%E4%BC%98%E5%8C%96/3.png"></p>
<p>接着，我们利用交叉熵，计算第i个图片的损失：</p>
<script type="math/tex; mode=display">
L_i = -\log P(y=y_i|x_i) = -\log (\frac{e^{s_{y_1}}}{\sum_j e^{s_j}})</script><ul>
<li>其中，$y_i$ 代表正确的标签</li>
</ul>
<h4 id="实例计算-1"><a href="#实例计算-1" class="headerlink" title="实例计算"></a>实例计算</h4><p>我们还是那 SVM loss的那个例子来计算，得到了分数以后我们先计算预测的每个类别的概率，得到蓝色框框。</p>
<p>然后通过计算cross entropy 来得到 $L_1$ </p>
<p><img src="/2021/12/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%92%8C%E4%BC%98%E5%8C%96/7.png"></p>
<h5 id="QA-1"><a href="#QA-1" class="headerlink" title="QA"></a>QA</h5><p>Q: 如果有输出分数发生微小改变(比如 $\pm 0.1$)，损失函数是否发生改变？</p>
<p>A: 使得，正确类别和错误类别输出分数差距越大，损失函数就越小</p>
<hr>
<p>Q: 损失函数$L_i$ 的最大值和最小值分别是多少？</p>
<p>A: 最小值为0(理论上)，最大值为正无穷(理论上)</p>
<hr>
<p>Q: 加入初始化 $\boldsymbol W$ 接近0，导致所有输出分数都$\approx 0$ ，那么$L$ 约等于多少？</p>
<p>A: $L<em>i = -\log (\frac{e^{s</em>{y_1}}}{\sum_j e^{s_j}})$ , 当输出分数都约等于0的时候，$L_i = -\log(1/C)=\log C$, 其中$C$为类别数，这里为 $\log 3$</p>
<hr>
<h4 id="两类分类器的对比"><a href="#两类分类器的对比" class="headerlink" title="两类分类器的对比"></a>两类分类器的对比</h4><p><img src="/2021/12/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%92%8C%E4%BC%98%E5%8C%96/4.png"></p>
<p>为什么左边的是SVM分类器，右边的是Softmax分类器？</p>
<p>因为SVM有一个boundary，而且并不关注所有类别到这个分类器的距离。他只要求其他类别比正确类别的分数小于1(boundary)即可。因此我们看到，左边的分类器目标是最大化 margin即可，并不需要计算每张图片到中心的距离。</p>
<p>而Softmax分类器，每个图片都参与了关于loss的计算。我们看到右边的分类器，需要一一计算每张图片到超平面的距离。</p>
<h3 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h3><p>正则项的意义：1. 缩小参数空间 2. 调整参数偏好的分布 3. 提高模型泛化能力。我们希望的分类器是下面这张图中的绿色线条。因为蓝色曲线已经过拟合了 ，在其他数据集上的表现会比较糟糕。</p>
<p><img src="/2021/12/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%92%8C%E4%BC%98%E5%8C%96/6.png"></p>
<p>怎么正则化呢？我们可以修改 loss 函数</p>
<script type="math/tex; mode=display">
L(\boldsymbol W) = \frac{1}{N}\sum_{i=1}^N l(f(\boldsymbol W,x_i),y_i) +\lambda R(\boldsymbol W)</script><p>前一部分是数据损失，后一部分是正则项，用来防止模型过拟合训练集。其中$\lambda$是超参数，代表正则化的强度；正则项 $R(\boldsymbol W)$ 有 L1正则，L2正则以及两种混合起来的正则。</p>
<h4 id="L1正则化"><a href="#L1正则化" class="headerlink" title="L1正则化"></a>L1正则化</h4><p>L1正则就是将每个权重的绝对值累加。</p>
<script type="math/tex; mode=display">
L1: \sum_k\sum_l|w_{k,l}|</script><h4 id="L2正则化"><a href="#L2正则化" class="headerlink" title="L2正则化"></a>L2正则化</h4><p>L2正则是将每个权重求平方之后累加：</p>
<script type="math/tex; mode=display">
L2: \sum_k\sum_l|w_{k,l}^2|</script><p>此外还有Dropout, Batch normalization, Stochastic depth 和 Fractional pooling 等方法</p>
<h4 id="L1-vs-L2"><a href="#L1-vs-L2" class="headerlink" title="L1 vs L2"></a>L1 vs L2</h4><p>我们给个例子：</p>
<script type="math/tex; mode=display">
\begin{align}
&x= [1,1,1]\\
&\boldsymbol W_1 = [1,0,0]\\
&\boldsymbol W_2 = [0.3,-0.1,0.8]\\
&\boldsymbol W_1^T x = \boldsymbol W_2^T x = 1\\
\end{align}</script><p>使用$L1$ 正则化，对于$\boldsymbol {W_1,W_2}$， 可得：</p>
<script type="math/tex; mode=display">
\boldsymbol W_1 : \sum_{k}\sum_l|\boldsymbol W_1| = 1\\
\boldsymbol W_2 : \sum_{k}\sum_l|\boldsymbol W_2| = 1.2</script><p>使用$L_2$ 正则化，可得：</p>
<script type="math/tex; mode=display">
\boldsymbol W_1 : \sum_{k}\sum_l|\boldsymbol W^2_1| = 1\\
\boldsymbol W_2 : \sum_{k}\sum_l|\boldsymbol W^2_2| = 0.74</script><p>我们看到，$L_1$ 偏向于是参数集中在少数输入像素上</p>
<p>$L_2$ 偏向于是参数分布在所有像素上</p>
<h3 id="损失函数计算流程"><a href="#损失函数计算流程" class="headerlink" title="损失函数计算流程"></a>损失函数计算流程</h3><ol>
<li>初始化$\boldsymbol W$</li>
<li>计算 $s= f(\boldsymbol W,x_i)$</li>
<li>选择损失函数，计算 $L<em>总 = \frac{1}{N}\sum</em>{i=1}^N L_i+\lambda R(\boldsymbol W)$ 得到 Total Loss</li>
<li>通过优化算法，修改原来的参数矩阵 $\boldsymbol W$ </li>
<li>重复2-4, 直到收敛</li>
</ol>
<h2 id="图像特征抽取"><a href="#图像特征抽取" class="headerlink" title="图像特征抽取"></a>图像特征抽取</h2><p>线性分类器是可以应用于图像的，如果直接用像素点来计算，效果其实是很差的。因此往往需要对原始像素做特征抽取，利用抽取的特征来训练模型，以提高预测性能。如下所示：</p>
<p><img src="/2021/12/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%92%8C%E4%BC%98%E5%8C%96/8.png"></p>
<p>在深度神经网络(DNN)中的前几层，其实就是一个提取图像特征的过程。那么在线性分类器中，我们有什么方法呢？</p>
<h3 id="Hue-Histogram"><a href="#Hue-Histogram" class="headerlink" title="Hue Histogram"></a>Hue Histogram</h3><ol>
<li>建立色相哈希表</li>
<li>哈希每个像素值，并计算每个key中像素的个数</li>
<li>将哈希结果作为模型输入</li>
</ol>
<h3 id="HoG"><a href="#HoG" class="headerlink" title="HoG"></a>HoG</h3><p>HoG 的全称是：Histogram of Oriented Gradients(方向梯度直方图)</p>
<p><img src="/2021/12/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%92%8C%E4%BC%98%E5%8C%96/9.png"></p>
<h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><p>我们的目标是最小化损失函数 $L(\boldsymbol W)$ ，因为这时候预测的最接近于真实值。</p>
<p>假设只有一个参数$w$：</p>
<ul>
<li>导数 $\frac{dL(w)}{dw} = \lim\limits_{h\rightarrow 0}\frac{L(w+h)-L(w)}{h}$ 代表$L$ 在$w$ 的切线斜率，即 $L(w)$ 在该店的变化速率及方向</li>
<li>因此沿导数反方向微调w即可减小$L(w)$</li>
</ul>
<p>如下图所示：</p>
<p><img src="/2021/12/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%92%8C%E4%BC%98%E5%8C%96/10.png"></p>
<p>在多维情况下，即$\boldsymbol W$ 为向量</p>
<ul>
<li><p>偏导数$[\frac{\partial L(\boldsymbol W)}{\partial w<em>1},\frac{L(\boldsymbol W)}{\partial w_2},\cdots,\frac{L(\boldsymbol W)}{\partial w_n}]$ 代表L 在 $\boldsymbol W$ 处沿每个维度的变化速率和方向，称为梯度(gradient).记为 $\nabla</em>{\boldsymbol W}L$ 或者 $grad(L(\boldsymbol W))$</p>
</li>
<li><p>$\nabla_{\boldsymbol W}L$ 和方向向量$\boldsymbol v$ 的点积记为该方向的斜率(方向导数) ,公式如下：</p>
<script type="math/tex; mode=display">
\nabla_{\boldsymbol W}L\cdot v = |\nabla_{\boldsymbol W}L ||v|\cos\theta</script><p>那么，当$\cos\theta =1$ 的时候，达到最大值，即$\boldsymbol v$ 和 $\nabla<em>{\boldsymbol W}L$ 同方向，所以负梯度 $-\nabla</em>{\boldsymbol W}L$ 代表 $L$ 下降最快的方向(最陡峭)。</p>
</li>
<li><p>沿 $-\nabla_{\boldsymbol W}L$ 方向微调$\boldsymbol W$ 即可快速减小 $L(\boldsymbol W)$ </p>
<script type="math/tex; mode=display">
\boldsymbol W_{new} = \boldsymbol W -\lambda\nabla_{\boldsymbol W}L</script><p>超参数$\lambda $ 为 step size 或 learning rate， 代表梯度下降的快慢，如果太小会导致梯度下降过慢，算法效率低下；太大会导致找不到梯度最优点。在<a href="https://jasonxqh.github.io/2021/12/02/计算机视觉-神经网络的训练/">计算机视觉-神经网络的训练</a>中，我们还会仔细探讨这个问题。</p>
</li>
</ul>
<h3 id="数值梯度"><a href="#数值梯度" class="headerlink" title="数值梯度"></a>数值梯度</h3><p>数值梯度就是根据导数的定义去求得梯度。比如说关于权重向量$\boldsymbol W$，手动计算梯度：</p>
<p><img src="/2021/12/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%92%8C%E4%BC%98%E5%8C%96/11.png"></p>
<p>但这样计算开销太大，需要遍历所有参数，并计算损失函数和梯度。显然，当参数过多时采用这种方法是不可行的</p>
<h3 id="解析梯度"><a href="#解析梯度" class="headerlink" title="解析梯度"></a>解析梯度</h3><p>我们可以对损失函数求偏导，编写梯度公式，以此来直接计算梯度.即：</p>
<script type="math/tex; mode=display">
\nabla_{\boldsymbol W}L = [\frac{\partial L(\boldsymbol W)}{\partial w_1},\frac{L(\boldsymbol W)}{\partial w_2},\cdots,\frac{L(\boldsymbol W)}{\partial w_n}]</script><h4 id="Hinge-Loss"><a href="#Hinge-Loss" class="headerlink" title="Hinge Loss"></a>Hinge Loss</h4><p><a href="http://ningyuwhut.github.io/cn/2018/01/gradient-of-svm-loss/" target="_blank" rel="noopener">http://ningyuwhut.github.io/cn/2018/01/gradient-of-svm-loss/</a></p>
<p>实现非向量化的svm还是比较简单的，其实只要两层训练即可，</p>
<p>第一层循环遍历每个样本,第二层循环遍历每个类;</p>
<p>在第二层循环中需要完成两件事: 1.计算当前类的loss， 2.同时计算对<strong>当前类</strong>和<strong>样本正确类</strong>的梯度。</p>
<p>当$i\neq y_j$ 的时候，我们需要对当前类的梯度进行修改</p>
<script type="math/tex; mode=display">
\frac{d L_i}{d w_j} = \mathbb 1(w_j^Tx_i-w^T_{y_i}x_i+\Delta>0)\begin{bmatrix}x_{i1}\\x_{i2}\\\vdots\\ x_{iD} \end{bmatrix} \\
=\mathbb 1(w_j^Tx_i-w^T_{y_i}x_i+\Delta>0) x_i^T</script><p>类似的，对于正确类的样本，我们这么更新：</p>
<script type="math/tex; mode=display">
\frac{d L_i}{d w_{y_j}} = -\sum_{j\neq y_i}\mathbb 1(w_j^Tx_i-w^T_{y_i}x_i+\Delta>0)\begin{bmatrix}x_{i1}\\x_{i2}\\\vdots\\ x_{iD} \end{bmatrix} \\
=-\sum_{j\neq y_i}\mathbb 1(w_j^Tx_i-w^T_{y_i}x_i+\Delta>0) x_i^T</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">svm_loss_naive</span><span class="params">(W, X, y, reg)</span>:</span></span><br><span class="line">		dW = np.zeros(W.shape)  <span class="comment"># initialize the gradient as zero</span></span><br><span class="line">                            <span class="comment"># compute the loss and the gradient</span></span><br><span class="line">    num_classes = W.shape[<span class="number">1</span>]</span><br><span class="line">    num_train = X.shape[<span class="number">0</span>]</span><br><span class="line">    loss = <span class="number">0.0</span></span><br><span class="line">    final_result = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num_train):<span class="comment"># 循环每个样本</span></span><br><span class="line">        scores = X[i].dot(W)</span><br><span class="line">        correct_class_score = scores[y[i]]</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(num_classes): <span class="comment"># 循环每个类别</span></span><br><span class="line">            <span class="keyword">if</span> j == y[i]: <span class="comment"># 如果该样本属于当前类，continue</span></span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            margin = scores[j] - correct_class_score + <span class="number">1</span>  <span class="comment"># 计算svm loss</span></span><br><span class="line">            <span class="keyword">if</span> margin &gt; <span class="number">0</span>:</span><br><span class="line">                loss += margin <span class="comment"># loss是累加</span></span><br><span class="line">                dW[:, j] += X[i].T  <span class="comment"># 更新当前类的梯度</span></span><br><span class="line">                dW[:, y[i]] += -X[i].T  <span class="comment"># 更新正确类的梯度</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Right now the loss is a sum over all training examples, but we want it</span></span><br><span class="line">    <span class="comment"># to be an average instead so we divide by num_train.</span></span><br><span class="line">    loss /= num_train <span class="comment">#需要除以样本数量</span></span><br><span class="line">    dW /= num_train</span><br><span class="line">    <span class="comment"># Add regularization to the loss.</span></span><br><span class="line">    loss += reg * np.sum(W * W) <span class="comment"># 需要加上正则项</span></span><br><span class="line">    dW += reg * W</span><br><span class="line">    <span class="keyword">return</span> loss, dW</span><br></pre></td></tr></table></figure>
<h4 id="Cross-entropy-Loss"><a href="#Cross-entropy-Loss" class="headerlink" title="Cross entropy Loss"></a>Cross entropy Loss</h4><p><a href="https://www.cnblogs.com/makefile/p/softmax.html" target="_blank" rel="noopener">https://www.cnblogs.com/makefile/p/softmax.html</a></p>
<p>和SVM loss一样，我们同时要有两个循环，第一层循环遍历每个样本,第二层循环遍历每个类;我们要分两种情况进行讨论，当当前样本属于当前类的时候，当当前样本不属于当前类的时候。</p>
<p>首先，我们知道每个样本的softmax loss是这么计算的：</p>
<script type="math/tex; mode=display">
L_i = -\log(\frac{e^{f_{y_i}}}{\sum_j e^{f_j}})</script><p>其中，f 即计算来的分数：</p>
<script type="math/tex; mode=display">
f_{y_i} = w_{y_i}^T x\\
f_j = w_j^Tx</script><p>所以，如果我们要计算损失函数关于参数矩阵$w$ 的导数，需要用到高链式法则：</p>
<script type="math/tex; mode=display">
\frac{dL}{dw} = \frac{dL}{df}\cdot\frac{df}{dw}</script><p>其中，$\frac{df}{dw} = x$, 我们主要来看 $\frac{dL}{df}$</p>
<h5 id="当-j-neq-y-i-时"><a href="#当-j-neq-y-i-时" class="headerlink" title="当 $j\neq y_i$ 时"></a>当 $j\neq y_i$ 时</h5><p>我们就不需要计算正确分类时的损失，只需要针对<strong>分母中的错误项</strong>求偏导,因为分母中也包含正确项系数，因此在求导的时候需将其提出，以此计算错误分类时的损失</p>
<script type="math/tex; mode=display">
\begin{align}
\frac{dL_i}{df} &= \Bigg(-\log(\frac{e^{f_{y_i}}}{\sum_je^{f_j}}) \Bigg)' = -\frac{\sum_je^{f_j}}{e^{f_{y_j}}} \cdot e^{f_{y_j}}(\frac{1}{\sum_j e^{f_j}})'\\
&=-\frac{\sum_je^{f_j}}{e^{f_{y_j}}} \cdot e^{f_{y_j}}\cdot(-e^{f_{y_j}})\cdot\frac{1}{(\sum_j e^{f_j})^2}\\
&=\frac{e^{f_{y_i}}}{\sum_je^{f_j}}\\
\end{align}</script><h5 id="当-j-y-i-时"><a href="#当-j-y-i-时" class="headerlink" title="当 $j == y_i$时"></a>当 $j == y_i$时</h5><p>此时，我们需要对分子求偏导，来计算正确类的损失</p>
<script type="math/tex; mode=display">
\begin{align}
\frac{dL_i}{df} &= \Bigg(-\log(\frac{e^{f_{y_i}}}{\sum_je^{f_j}}) \Bigg)' = -\frac{\sum_je^{f_j}}{e^{f_{y_j}}} \cdot (e^{f_{y_j}}\frac{1}{\sum_j e^{f_j}})'\\
&=-\frac{\sum_je^{f_j}}{e^{f_{y_j}}} \cdot [{e^{f_{y_i}}(\sum_j e^{f_j})^{-1}+e^{f_{y_i}}\cdot\frac{(-1\cdot e^{f_{y_i}})}{(\sum_je^{f_j})^2}}]\\
&=\frac{e^{f_{y_j}}}{\sum_j e^{f_j}}-1 \\

\end{align}</script><p>现在，我们已经计算了两种情况下的梯度，我们可以用示性函数将其统一起来：</p>
<script type="math/tex; mode=display">
\frac{dL_i}{df} = \frac{e^{f_{y_j}}}{\sum_j e^{f_j}}- \mathbb 1(j==y_i)</script><p>因此，</p>
<script type="math/tex; mode=display">
\frac{dL}{dW_i} = (\frac{e^{f_{y_j}}}{\sum_j e^{f_j}}- \mathbb 1(j==y_i))x</script><p>Softmax_loss_naive方法代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 第一层循环，遍历样本</span></span><br><span class="line"><span class="keyword">for</span> ii <span class="keyword">in</span> range(num_train):</span><br><span class="line">  current_scores = scores[ii, :]</span><br><span class="line"> </span><br><span class="line">  <span class="comment"># Fix for numerical stability by subtracting max from score vector.</span></span><br><span class="line">  <span class="comment"># important! make them range between infinity to zero</span></span><br><span class="line">  shift_scores = current_scores - np.max(current_scores)</span><br><span class="line"> </span><br><span class="line">  <span class="comment"># Calculate loss for this example.</span></span><br><span class="line">  loss_ii = -shift_scores[y[ii]] + np.log(np.sum(np.exp(shift_scores)))</span><br><span class="line">  loss += loss_ii</span><br><span class="line"><span class="comment"># 第二层循环，遍历类 		</span></span><br><span class="line">  <span class="keyword">for</span> jj <span class="keyword">in</span> range(num_classes):</span><br><span class="line">    softmax_score = np.exp(shift_scores[jj]) / np.sum(np.exp(shift_scores))</span><br><span class="line">		<span class="comment"># 分两类进行权重矩阵的更新</span></span><br><span class="line">    <span class="keyword">if</span> jj == y[ii]:</span><br><span class="line">      dW[:, jj] += (<span class="number">-1</span> + softmax_score) * X[ii]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      dW[:, jj] += softmax_score * X[ii]</span><br><span class="line">      </span><br><span class="line">   <span class="comment"># Average over the batch and add our regularization term.</span></span><br><span class="line">loss /= num_train</span><br><span class="line">loss += reg * np.sum(W*W)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Average over the batch and add derivative of regularization term.</span></span><br><span class="line">dW /= num_train</span><br><span class="line">dW += <span class="number">2</span>*reg*W</span><br></pre></td></tr></table></figure>
<h3 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h3><p>其实梯度下降也有很多种方法，除了正常的梯度下降(GD) 之外，还有批量梯度下降法(Batch Gradiant Descent, BGD) 和 随机梯度下降(Stochastic Gradiant Descent, SGD)</p>
<p>这里主要拿 GD和SGD做一个比较</p>
<h4 id="GD"><a href="#GD" class="headerlink" title="GD"></a>GD</h4><ul>
<li>优势： 每次迭代 loss 下降很快</li>
<li>劣势: 一次迭代需要遍历所有数据，并容易陷入局部最小值，导致梯度无法更新</li>
</ul>
<h4 id="SGD"><a href="#SGD" class="headerlink" title="SGD"></a>SGD</h4><p>随机梯度下降是说，每次选取一个sample集(minibatch，一般大小为32/64/128/256). 然后，利用sample集上的损失来计算近似梯度，进行梯度下降。</p>
<ul>
<li>优势: 迭代更新速度快，并且往往因为 mini-batch含有噪声而避开 local minima</li>
<li>劣势: 每次迭代的 loss 下降很漫</li>
</ul>
<p>由于数据量较大，训练深度神经网络(DNN) 的时候基本使用SGD，以及其他性能更佳的优化方法。</p>

          
        
      
    </div>
    
    
    
    <div>
      
    </div>
    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://jasonxqh.github.io/2021/12/16/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jason">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/%5Bobject%20Object%5D">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jason‘s Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/12/16/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/" itemprop="url">注意力机制</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2021-12-16T18:52:53+08:00">
                2021-12-16
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified&#58;</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2021-12-27T20:24:42+08:00">
                2021-12-27
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="注意力机制"><a href="#注意力机制" class="headerlink" title="注意力机制"></a>注意力机制</h1><h2 id="RNNs-attention"><a href="#RNNs-attention" class="headerlink" title="RNNs+attention"></a>RNNs+attention</h2><p>在写 <a href="https://jasonxqh.github.io/2021/12/16/循环神经网络/#其他例子">循环神经网络</a> 这篇博客的时候，我曾简单讲过注意力机制的原理及其作用。现在我们来详细学习一下注意力机制。</p>
<p>首先，我们要知道注意力机制在RNN中的作用有哪些？</p>
<ul>
<li>计算机视觉中的应用： 图片描述</li>
<li>自然语言处理中的应用：机器翻译</li>
</ul>
<h3 id="不使用注意力机制-图像识别"><a href="#不使用注意力机制-图像识别" class="headerlink" title="不使用注意力机制-图像识别"></a>不使用注意力机制-图像识别</h3><p><img src="/2021/12/16/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/1.png"></p>
<p>我们来讲不使用注意力机制的RNN是如何进行看图说话的。我们看到上图的左半侧是一个encoder，输入的是图片$I$,  右半侧是decoder，输出的是文本</p>
<p>首先，图像经过CNN卷积以后生成一张 feature map，也就是上面绿色的矩阵</p>
<p>然后，我们将feature map 经过 MLP (multi-layer perceptron,多层感知机)后，变成一个D维的$h_0$。 同时，利用 $h_0$ 转化出一个 context vector c(为了方便其实一般就是将$c$设置为整个$h_0$),使其保留了图片中的特征信息，可以用来辅助文本预测。</p>
<p>context vector 是可以作为选择性输入的，有没有都可以。如果将其作为一部分输入，那么神经元既有之前生成的文本信息，又有保留下来的图片信息，可以帮助RNN更好辅助生成单词。</p>
<p>但是这样做是有一个缺陷的，就是我们生成的context vector虽然拥有图片的全部特征，但对于每一个神经元的输入，都是相等的。因此，这并不利于在不同时刻捕捉差异化的图片信息，神经网络说话的时候就”抓不住重点“，导致看图说话效果不好。   </p>
<h3 id="使用注意力机制-图像识别"><a href="#使用注意力机制-图像识别" class="headerlink" title="使用注意力机制-图像识别"></a>使用注意力机制-图像识别</h3><p>因此，看图说话借鉴了机器翻译中的注意力机制来提升看图说话的准确性</p>
<p><img src="/2021/12/16/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/2.png"></p>
<ul>
<li><p>首先，还是图片通过CNN 生成一张feature map，然后通过MLP生成隐层向量$h_0$ </p>
</li>
<li><p>用隐向量和feature map 相乘，生成一张 $H\times W$ 的对齐分数矩阵 $\boldsymbol e$。对齐分数越大，代表应该关注这部分特征越多。</p>
</li>
<li><p>对于对齐分数中的元素，利用 softmax 进行归一化，得到注意力分数矩阵 $\boldsymbol a$ , 这就代表了每一个部分应该被关注的概率</p>
</li>
<li><p>利用注意力分数矩阵和feature map 做对位相乘(加权聚合)，得到加权之后的整张图片的特征向量context vector, 形状为 $D\times 1$</p>
<script type="math/tex; mode=display">
c_t = \sum_{i,j} a_{t,i,j}z_{i,j}</script></li>
<li><p>将 context vector 、输入值、以及上个隐层状态，共同作为下一个神经元的输入。接下来，每一步的$h_{i}$都会和feature map生成一个 context vector，告诉下一个神经元应该关注哪里。</p>
</li>
</ul>
<p>通过这种方法，每个时刻 t 的 context vector 都是不一样的，是随着$h_{t-1}$  变化而来的。因此，每个时刻都可以根据前一时刻的隐层状态去关注图片的不同区域</p>
<p><img src="/2021/12/16/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/3.png"></p>
<p>结果如下：</p>
<p><img src="/2021/12/16/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/4.png"></p>
<h4 id="图像描述注意力计算"><a href="#图像描述注意力计算" class="headerlink" title="图像描述注意力计算"></a>图像描述注意力计算</h4><p>现在我们来具体看一下注意力分数是如何被计算出来的，如下图：</p>
<p><img src="/2021/12/16/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/8.png"></p>
<h3 id="不使用注意力机制-机器翻译"><a href="#不使用注意力机制-机器翻译" class="headerlink" title="不使用注意力机制-机器翻译"></a>不使用注意力机制-机器翻译</h3><p>机器翻译和图片识别的原理大致相同，只不过原本的encoder 是用来处理图片信息的，而现在是用来处理文字流的。因此我们不能使用CNN，而要使用RNN：</p>
<p>在Encoder中，一个一个输入法语单词，生成一个隐向量，聚合后经过MLP得到decoder的初始隐向量$h_0$</p>
<p>还可以保留一个 context vector 包含了这句法语中的所有特征，作为辅助输入来帮助文本预测，</p>
<p><img src="/2021/12/16/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/5.png"></p>
<p>但是因为没有引入attention机制，导致decoder没有关注重点，翻译不准确</p>
<h3 id="使用注意力机制-机器翻译"><a href="#使用注意力机制-机器翻译" class="headerlink" title="使用注意力机制-机器翻译"></a>使用注意力机制-机器翻译</h3><p><img src="/2021/12/16/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/6.png"></p>
<p>在机器翻译中引入注意力机制后，对于每一个输入层的隐向量$z<em>i$ ,都和$h</em>{t-1}$相乘得到对齐分数$\boldsymbol e$ ;</p>
<ul>
<li>再经过 softmax 计算注意力分数$a_{t,i}$,t代表第t个时刻</li>
<li>用得到的$\boldsymbol a$和当前$z_i$ 聚合，得到context vector c， 作为下一层的输入。</li>
</ul>
<p>这样，在decoder中，每个时刻t 的context vector 都会随着$h_{t-1}$的变化而变化，即每个时刻都可以根据前一时刻的隐层状态关注输入文本的不同部分</p>
<p><img src="/2021/12/16/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/7.png"></p>
<h2 id="一般的注意力层结构"><a href="#一般的注意力层结构" class="headerlink" title="一般的注意力层结构"></a>一般的注意力层结构</h2><h3 id="一般注意力层"><a href="#一般注意力层" class="headerlink" title="一般注意力层"></a>一般注意力层</h3><p>之前我们介绍了如何在图像识别中进行注意力计算，现在我们来看看一般注意力层是如何计算的：</p>
<p>首先，因为一般注意力层的输入并不是feature map，而是单个的向量，因此原来的MLP变成了现在的点积，事实证明用点积计算可以在 Transformer 中取得很好的效果</p>
<p><img src="/2021/12/16/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/10.jpg"></p>
<p>然而得到了对齐分数$e_i$，但是在向量长度很长的情况下，会造成对齐分数的方差很大(大的分数很大，小的分数很小)。这样的数据经过softmax层以后(指数运算)，会使得注意力分数只集中在少数几个输入向量上。因此，单单点积还是不够的，我们需要除以$\sqrt D$ 以减轻这种效应，其中$D$为向量长度。</p>
<p><img src="/2021/12/16/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/11.png"></p>
<p>接着，对 对齐分数进行softmax以后，得到了注意力分数。在将注意力分数和输入值$x$做整合：</p>
<p><img src="/2021/12/16/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/9.png"></p>
<p>但是，这种一般注意力层是存在缺点的：输入向量既 作为对齐运算的输入，又 做为注意力运算的输入，有点缺乏输入特征上的变化。</p>
<h3 id="自注意力层"><a href="#自注意力层" class="headerlink" title="自注意力层"></a>自注意力层</h3><p>因此，我们可以通过在计算对齐分数和注意力分数的时候，分别用一个线性层对输入向量进行转化来解决这个问题。这样存在一定的变化之后，可以使得 $y_i$ 的大小和输入$x_i$的大小是不一样的。</p>
<p>如下所示：</p>
<p><img src="/2021/12/16/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/12.png"></p>
<p>对于输入向量，我们可以将其乘以一个 $\boldsymbol W_k$矩阵将其变为 Key 向量，将其和Querie向量相乘得到对齐分数</p>
<p>然后再将输入值 乘以 $\boldsymbol W_v$矩阵相乘，得到 Value 向量，将其和softmax过后的对齐分数聚得到注意力分数</p>
<p>而且从RNN中我们也看到了，Queries 向量也是由输入向量经线性层得到的。</p>
<p>用自己来生成query、key去做对齐分数的计算，再与由自己来生成的value聚合，这就是<strong>自注意力层</strong>命名由来</p>
<p>简单来说，就是对一组输入向量的自我注意力运算，将中间的计算隐藏后，我们可以得到如下结构：</p>
<p><img src="/2021/12/16/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/13.png"></p>
<h3 id="位置编码"><a href="#位置编码" class="headerlink" title="位置编码"></a>位置编码</h3><p>运用自注意力层，可以完全抛弃循环神经网络中的迭代结构。因为在RNN中，context vectors是按照顺序，一个一个生成的，需要借助每一次循环的$h_{t-1}$ 。但是自注意力层只需要自己计算就可以得到 context vectors了。</p>
<p>因此也会导致一个问题，就是生成的编码$y_i$很可能无法学到输入向量的排列顺序信息，这对于处理文本和图片都是不利的。因此，我们要想一个办法，在输入向量中加入其在序列中的位置信息。使其能够表示每个向量的绝对位置和相对位置。</p>
<p>这就是位置编码 (positional encoding)的作用</p>
<p><img src="/2021/12/16/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/14.png"></p>
<p>关于位置编码$p_t$, 需要满足以下特性：</p>
<ul>
<li>唯一性： 每个时刻的编码是唯一的 </li>
<li>一致性：对于所有输入长度，两个时刻之间的距离是一致的</li>
<li>泛化性：对于所有输入长度都可以使用这套编码</li>
</ul>
<p>因此，用三角函数来表示时刻、位置信息就是一个很好地选择。</p>
<script type="math/tex; mode=display">
p_t^i = \begin{cases}\sin(\omega_k\cdot t)&\text{if i=2k} \\~\\\cos(\omega_k\cdot t) & \text{if~i=2k+1} \end{cases}</script><p>其中， $t\geq 0$ 代表时刻；$0\leq i&lt;D$ 代表编码的<strong>第i个位置</strong>; $\omega_k = \frac{1}{10000^{2K/D}}$ </p>
<p>最终，对于在t时刻、长度为D的输入，会得到一个长度为D的位置编码：</p>
<p><img src="/2021/12/16/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/15.png"></p>
<p>因为我们对$\omega_k$ 取得值是很小的，t乘以10000之后，可能会开始循环，但 t 一般只取128、256、512、1024。因此 $p_t$ 所有sin、cos的值都是在一个周期之内的，满足唯一性。</p>
<p>泛化性也很好理解，因为这套编码对任何长度的句子, 都是适用的</p>
<p>对于一致性，两个时刻之间的距离是一致的吗？我们可以用一个简单的方式来证明：我们考虑位置编码中任意一对sin和cos，运算以下公式：</p>
<script type="math/tex; mode=display">
\begin{bmatrix}\cos(\omega_k\cdot\Delta t)&\sin(\omega_k\cdot \Delta t)\\-\sin(\omega_k\cdot\Delta t)&\cos(\omega_k\cdot \Delta t) \end{bmatrix}\cdot\begin{bmatrix}\sin(\omega_k\cdot t)\\ \cos(\omega_k\cdot t) \end{bmatrix} = \begin{bmatrix}\sin(\omega_k\cdot(t+\Delta t))\\\cos(\omega_k\cdot(t+\Delta t)) \end{bmatrix}</script><p>我们发现，其距离只和两个时刻有关，和输入长度无关。因此一致性也会满足</p>
<h3 id="遮挡的自注意力层"><a href="#遮挡的自注意力层" class="headerlink" title="遮挡的自注意力层"></a>遮挡的自注意力层</h3><p>有了位置编码这个工具以后，输入向量就是由顺序性的。但现在又有一个问题，之前的注意力机制，输出结果的时候，后面的输入是看不到的。但现在有了位置编码之后，在输出$y_0$的时候却能看到后面的输入。</p>
<p>这是不可以的，每一个位置的输入编码是<strong>不应该提前看到后面的输入</strong>的，否则会导致过拟合的情况</p>
<p>因此，提出了<strong>遮挡的</strong>自注意力层。也就是说，在encode的时候，将当前向量后面的对齐分数设置为负无穷，在decode 的时候相应的注意力分数设置为0，如下图所示：</p>
<p><img src="/2021/12/16/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/16.png"></p>
<p>我们看到，对于第一个输入位置的$k_0$,我们把$k_1,k_2$的对齐分数置为$-\infty$；对于第二个位置输入的$k_1$,它可以看见$k_0$输入，但是$k_2$ 的对齐分数被设置为$-\infty$ </p>
<h3 id="多头自注意力层"><a href="#多头自注意力层" class="headerlink" title="多头自注意力层"></a>多头自注意力层</h3><p><img src="/2021/12/16/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/17.png"></p>
<p>用多组不同的 $k/q/v$ 来计算多组不同的注意力分数，每组注意力分数关注输入中的不同部分，以提高对子空间的特征捕捉能力。</p>
<p>比如说我可以设置$h=8$，即8个head，每个 head 生成一组输出，最后将8组输出拼接</p>
<h2 id="Transformers"><a href="#Transformers" class="headerlink" title="Transformers"></a>Transformers</h2><p>完全基于注意力机制的全新的神经网络结构</p>

          
        
      
    </div>
    
    
    
    <div>
      
    </div>
    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://jasonxqh.github.io/2021/12/16/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jason">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/%5Bobject%20Object%5D">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jason‘s Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/12/16/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/" itemprop="url">生成模型</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2021-12-16T18:52:41+08:00">
                2021-12-16
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified&#58;</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2022-03-05T18:07:22+08:00">
                2022-03-05
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="生成模型"><a href="#生成模型" class="headerlink" title="生成模型"></a>生成模型</h1><p>到现在为止，我们学习的所有模型都是<strong>有监督学习</strong>。</p>
<ul>
<li>给定数据x和标签y，学习$x\rightarrow y$ 的映射，并以此预测新的数据的标签</li>
<li>应用场景如：图像分类，图像描述，目标检测，语义/实例分割，图像复原，风格转换等等。</li>
</ul>
<p>那么，什么是无监督学习及其应用呢？</p>
<ul>
<li>对于海量数据来讲，是没有标签的(或者标签就是数据本身)，给数据打标签是一件费时费力的工作。</li>
<li>应用场景如：机器学习中的聚类，降维，EM算法，表征学习，生成模型等等</li>
</ul>
<p>这节课，我们主要来学习生成模型。简单来说，就是一个可以生成图像的模型——给定训练图像，生成行的随机图像，如下图所示：</p>
<p>左边是输入的数据，是真实世界里的照片；右边是模型随机生成的照片</p>
<p><img src="/2021/12/16/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/1.png" style="zoom:120%;"></p>
<p>现在给出正式定义：给定观测数据 $X$ 和 目标变量$Y$,模拟联合分布$p(X,Y)$ 或 条件概率分布 $p(X|Y)$ </p>
<p>给定观测数据和目标变量Y，模拟联合分布$p(X,Y)$ 或者条件概率分布$p(X|Y)$. 然后，由 $p(X,Y)$ 或者 $p(X|Y)$ 可以模拟概率密度函数$p(X)$</p>
<p>不管使用哪种方法，其底层逻辑都是<strong>极大似然函数</strong>。 在 <a href="https://jasonxqh.github.io/2021/06/10/概率论第六章/#最大似然估计与EM算法">极大似然估计与EM算法</a> 中，我们已经学过极大似然函数是用来估计参数的。同样的在这里我们可以用到这个方法</p>
<ul>
<li>构建参数模型表示图像的概率密度函数 $p<em>{model}(x|\theta)$，(一般使用神经网络来模拟$p</em>{model}(x|\theta)$ )</li>
<li>使用大量观测图像去估计参数$\theta$ , 使得 $\sum p_{model}(x|\theta)$ 去极大值 (优化目标)</li>
<li>使用估计(训练)好的 $p_{model}(x|\theta)$ 生成新的随机图像</li>
</ul>
<script type="math/tex; mode=display">
\theta ^* = \arg\max_\theta \mathbb E_{x\sim p_{data}}\log p_{\text{model}}(x|\theta)</script><p>现在我们给出常用的生成模型以及他们的分类</p>
<p><img src="/2021/12/16/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/2.png" style="zoom:100%;"></p>
<p>首先，生成模型分为两大类：显示的概率密度函数——即显式定义概率密度函数，然后用观测数据将其最大化；隐式的概率密度函数——预先没有定义，但是通过其他方式使得模型学习得到概率密度函数。</p>
<p>其中，显示概率密度函数又分为两种: 容易计算的概率密度函数和近似的概率密度函数。其中，前者最主要的技术是 完全可见信念网络 (Fully Visible Belif Nest, FVBN)，主要模型是PixelRNN/CNN； 后者主要技术为变分自编码器(Variational Auto Encoder)和马尔科夫链(玻尔兹曼机)</p>
<p>隐式概率密度函数中分为两种模型： GAN和GSN，GAN是我们今天要学习的模型，GSN中使用马尔科夫链，效率比较低。</p>
<h2 id="显式概率密度函数"><a href="#显式概率密度函数" class="headerlink" title="显式概率密度函数"></a>显式概率密度函数</h2><h3 id="FVBN"><a href="#FVBN" class="headerlink" title="FVBN"></a>FVBN</h3><p>首先我们来介绍显示概率密度函数类别下的完全可见信念网络的原理。然后来介绍一下这个网络下的PixelRNN模型</p>
<p>首先，我们令图片 $x ={x_1,x_2,\cdots,x_n}$为一组向量，$p(x)$ 是关于图片中所有像素值的联合概率分布。</p>
<p>其次，我们要计算$p(x)$ ，$p(x)$等于基于链式规则的条件概率乘积，即：</p>
<script type="math/tex; mode=display">
p(x) = \prod_{i=1}^nP(x_i|x_1,\cdots,x_{i-1})</script><ul>
<li>$p(x) $是代表图片x 的概率，我们可以使用神经网络来模拟高维数据的概率分布</li>
<li>$p(x<em>1,\cdots,x</em>{i-1})$ 代表给定前面所有像素的情况想，第i个像素的值$x_i$的概率</li>
</ul>
<p>最后，将联合概率学习转换为顺序预测：</p>
<ul>
<li>根据已生成的像素预测下一个像素值</li>
<li>优化目标：最大化$L = \sum_x\log p(x)$</li>
</ul>
<h3 id="Pixel-RNN-CNN"><a href="#Pixel-RNN-CNN" class="headerlink" title="Pixel RNN/CNN"></a>Pixel RNN/CNN</h3><h4 id="Pixcel-RNN"><a href="#Pixcel-RNN" class="headerlink" title="Pixcel RNN"></a>Pixcel RNN</h4><p>从上面对 FVBN 的介绍，我们发现对像素的预测是呈序列状的，因此很适合用循环网络来解决这个问题。因此我们要定义一个比较规则的序列</p>
<p>最朴素的想法是：从左上角开始每次生成一个像素点，当前点为 output, 左边一个点为 input。如下图所示：</p>
<p><img src="/2021/12/16/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/3.png" style="zoom:100%;"></p>
<p>但这样训练和生成的效率都很低，我们想象一下生成512x512的图像，会导致像素序列非常长，而这么长的序列对RNN来说是非常不利的。</p>
<p>所以，在<a href="http://proceedings.mlr.press/v48/oord16.pdf" target="_blank" rel="noopener">这篇文章</a>中，作者提出了用Row LSTM方法和Diagonal BiLSTM方法来解决Pixel RNN的问题。</p>
<h4 id="Row-LSTM"><a href="#Row-LSTM" class="headerlink" title="Row LSTM"></a>Row LSTM</h4><p>Row LSTM的想法是：从上往下逐行生成像素点，即把前一行的像素全部作为 input ，如下图所示</p>
<p><img src="/2021/12/16/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/4.png" style="zoom:100%;"></p>
<p>这种方法采用LSTM顺序去输出每一个像素点</p>
<script type="math/tex; mode=display">
[o_i, f_i, i_i, g_i] = (K^{ss} * h_{i-1} +K^{is} * x_i)</script><p>其中，$K^{is}*x_i$ 代表 $3\times 1$的卷积运算，训练时还可以让所有row 并行运算</p>
<p>不足之处：</p>
<ul>
<li>每个像素点的 context 知识上面几行组成的三角区域，这和理想状态不符合、</li>
<li>生成时依然是每次只生成一个像素点，会存在一定的效率上的问题</li>
</ul>
<h4 id="Diagonal-BiLSTM"><a href="#Diagonal-BiLSTM" class="headerlink" title="Diagonal BiLSTM"></a>Diagonal BiLSTM</h4><p>要了解对角双向LSTM方法，我们首先要对双向LSTM有一个了解。其结构如下图所示：</p>
<ul>
<li>两层LSTM结构，分别从正反两个方向顺序输入序列数据</li>
<li>同一个时间步的两个hidden state 拼接然后转化为输出</li>
</ul>
<p>通过这个方法，就可以同时捕获当前时间步前面和后面的context，而不像前面Row LSTM方法那样只能捕捉前面的context</p>
<p><img src="/2021/12/16/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/6.png" style="zoom:100%;"></p>
<p>将BiLSTM应用于生成模型中去，我们看到，这里有两层LSTM：第一层从左上到右下；第二层从右上到左下。像素生成的示意图如下所示：</p>
<p><img src="/2021/12/16/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/5.png" style="zoom:100%;"></p>
<p>运用这种方法</p>
<ul>
<li>输入为左边(右边)的像素点</li>
<li>hidden state为左边(右边)和上方像素点的hidden values，并对其做$2\times1$ 卷积</li>
</ul>
<p><img src="/2021/12/16/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/8.png" style="zoom:100%;"></p>
<p>正常来说，输入值是左方和上方的像素点做卷积，但是这样不太方便矩阵计算。因此，我们每一行平移一个pixel的位置，使得左方像素和上方像素对齐，方便卷积计算。</p>
<p>不足之处</p>
<ul>
<li><p>生成时依然每次生成一个像素点</p>
<p><img src="/2021/12/16/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/9.png" style="zoom:100%;"></p>
</li>
</ul>
<p>我们看到Pixel RNN 生成的图片都非常小，因为尺寸一旦大了会导致梯度爆炸、梯度消失等问题。</p>
<h4 id="Pixel-CNN"><a href="#Pixel-CNN" class="headerlink" title="Pixel CNN"></a>Pixel CNN</h4><p>使用CNN，可以用左边和上面的像素卷积后生成新像素点。在训练时可以高度并行来提高训练效率</p>
<p><img src="/2021/12/16/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/7.png" style="zoom:100%;"></p>
<p>使用门结构层来代替 ReLU 层</p>
<ul>
<li>$t = \tanh (\boldsymbol W<em>{k,f}*x)\odot\sigma(\boldsymbol W</em>{k,g}*x)$ </li>
<li>加强网络的 non-linearity</li>
</ul>
<p>不足之处：</p>
<p>生成的时候仍然每次生成一个像素点。</p>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>Pixel RNN和Pixel CNN的优点：</p>
<ul>
<li>显示计算图像生成概率，生成图像直接和原式图像比较，易于优化，训练稳定</li>
</ul>
<p>缺点：</p>
<ul>
<li>虽然训练时候可以利用并行增加效率，但是测试的时候只能一个一个生成咸水沽。</li>
</ul>
<p>改进：</p>
<ul>
<li>Sigmoid 代替 Softmax</li>
<li>将 RGB像素视为整体</li>
<li>Res connections</li>
<li>Dropout</li>
</ul>
<p>总的来说， FVBN就是定义了一个离散的、易处理的(tractable) 密度函数，利用训练集直接优化似然(直接寻找极大似然).</p>
<script type="math/tex; mode=display">
p(x) = \prod_{i=1}^n p(x_i|x_1,\cdots,x_{i-1})</script><h3 id="VAE"><a href="#VAE" class="headerlink" title="VAE"></a>VAE</h3><p>VAE的全称是(Variational Autoencoders) ，相比于FVBN，它定义了一个连续的、不易处理的密度函数，是通过优化似然的下界(lower bound)来逼近极大似然的方法.因此，这里要是用积分来定义公式</p>
<script type="math/tex; mode=display">
p(x) = \int p(z)p(x|z)dz</script><h4 id="自编码器"><a href="#自编码器" class="headerlink" title="自编码器"></a>自编码器</h4><p>那么要了解VAE，首先要对自编码器(Autoencoders ,AE) 有一定的了解。自编码器是一种通过无监督的方式去学习数据内在表征(降维)的神经网络，如下图所示：</p>
<p><img src="/2021/12/16/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/10.png" style="zoom:100%;"></p>
<p>左侧是PCA的方法进行一个降维，右侧是通过自编码器方法对图片进行一个降维。它们的区别是：</p>
<ul>
<li>PCA是将矩阵经过sigmoid激活后保留主成分达到降维的目的，然后通过和$W^T$ 相乘获得新的压缩后的图片</li>
<li>自编码器则是通过一系列神经网络(编码器)将图片变成一个向量，然后再通过一些列神经网络(解码器)将这个向量复原成一张图片</li>
</ul>
<p>他们的效果对比如下，我们看到自编码器相对于PCA有更多的参数，但复原后的图片也更加清晰</p>
<p><img src="/2021/12/16/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/11.png" style="zoom:100%;"></p>
<h5 id="使用自编码器进行预训练"><a href="#使用自编码器进行预训练" class="headerlink" title="使用自编码器进行预训练"></a>使用自编码器进行预训练</h5><p>自编码器有什么应用场景呢？</p>
<p>首先，训练一个能够用于重构输入的隐层向量表示：</p>
<p><img src="/2021/12/16/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/12.png" style="zoom:100%;"></p>
<p>然后，训练完毕后，隐层特征就可以用于其他有监督训练任务(例如有大量数据，却只有少量标签)</p>
<p><img src="/2021/12/16/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/13.png" style="zoom:100%;"></p>
<p>那么我们可不可以随机初始化一个隐层向量，然后通过decoder来生成图像呢？这是比较困难的。因为用固定的自编码器去生成图片的时候，虽然隐层向量空间是连续的，但是每张图片生成的向量是离散的。处于离散向量之外的其他向量，不一定能生成图片。</p>
<p>就如同下图，虽然自编码器可以压缩黑狗还原黑狗，压缩白狗还原白狗，但是处于黑狗和白狗之间的那部分向量，是不一定能生成斑点狗的</p>
<p><img src="/2021/12/16/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/14.png" style="zoom:100%;"></p>
<h4 id="VAE的原理"><a href="#VAE的原理" class="headerlink" title="VAE的原理"></a>VAE的原理</h4><p>由此，我们提出，在自编码器的隐层向量空间中加入一些噪音，使得自编码器也能够生成斑点狗的照片：</p>
<p><img src="/2021/12/16/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/15.png" style="zoom:100%;"></p>
<p>那么既然我们定义在连续空间上，因此VAE的概率密度函数也得是连续的，由此得到了公式</p>
<script type="math/tex; mode=display">
p(x) = \int p(z) p(x|z)dz</script><p>其中：$x$ 是图像，而$z$ 是可以是隐层向量空间里面的一个随机向量(连续变量)。所以对于每一个z可能会生成一张图片。</p>
<h5 id="用VAE模型生成图像"><a href="#用VAE模型生成图像" class="headerlink" title="用VAE模型生成图像"></a>用VAE模型生成图像</h5><p>VAE模型怎么去生成一张图像？</p>
<ul>
<li><p>首先，从高斯分布中生成一个随机变量z，使得 $z\sim N(0,I)~$</p>
</li>
<li><p>让每个$z$ 去生成令一个正态分布 $N(\mu(z),\sigma(z))$</p>
</li>
<li>让 $x|z$ 服从正态分布 $N(\mu(z),\sigma(z))$ </li>
<li>$\mu,\sigma$ 两个函数可以用神经网络表示</li>
<li>因为z可以一直生成，因此理论上$p(x)$ 可以表示成无穷多个正态分布的mixture(即 $p(x) = \int p(z)p(x|z)dz$ ）。但事实上训练的图片是有限的，因此,  训练目标为最大化$\prod_xp(x)$或$\sum_x\log(p(x))$</li>
</ul>
<p><img src="/2021/12/16/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/17.png" style="zoom:100%;"></p>
<p>但事实上z不可能随机生成的，而是要根据我们的输入图片学习而来的(巧妇难为无米之炊)。放在数学层面上解释，就是我们要去寻找后验概率$p(z|x)$</p>
<p>这部分，就是自编码器中 <strong>decoder</strong> 的部分</p>
<h5 id="后验概率"><a href="#后验概率" class="headerlink" title="后验概率"></a>后验概率</h5><p>后验概率其实就是上述步骤反过来，扮演一个 encoder的部分</p>
<p>我们引入近似概率$q(z|x)$,使得：</p>
<ul>
<li>每个x生成一个正态分布 $N(\mu(x),\sigma(x))$</li>
<li>$z|x$ 服从正态分布$N(\mu(x),\sigma(x))$</li>
<li>$\mu,\sigma$ 两个函数可以用神经网络表示，使得 $q(z|x)$尽可能逼近$p(z)$</li>
</ul>
<p>将两部分放在一起看，如下所示</p>
<p><img src="/2021/12/16/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/18.png" style="zoom:100%;"></p>
<p>所以说，VAE和AE的原理是一样的，都是由图片生成向量，再由向量去还原图片。区别在于AE里面中间的向量是固定的，而VAE中间的向量是根据分布随机生成的。</p>
<h5 id="极大似然估计"><a href="#极大似然估计" class="headerlink" title="极大似然估计"></a>极大似然估计</h5><p>因为我们的目标是最大化$L = \sum_x\log p(x)$, 对于概率密度函数$p(x) = \int p(z)p(x|z)dz$ ，直接计算是不易处理的，因此我们需要用近似的方法将其变得更容易处理一点</p>
<script type="math/tex; mode=display">
\begin{align}
\log p(x) &= \log p(x)\int q(z|x)dz\\
&= \int q(z|x)\log p(x)dz\\
&=\int q(z|x)\log (\frac{p(z,x)}{p(z|x)}) dz\\
&=\int q(z|x)\log(\frac{p(z,x)}{q(z|x)}\frac{q(z|x)}{p(z|x)}) dz\\
&=\int q(z|x)\log(\frac{p(z,x)}{q(z|x)})dz+\int q(z|x)\log (\frac{q(z|x)}{p(z|x)})dz
\end{align}</script><p>其中，最后一式的第二部分是$KL$散度， 肯定是大于等于0的，因此</p>
<script type="math/tex; mode=display">
\log p(x) \geq \int q(z|x)\log (\frac{p(x|z)p(z)}{q(z|x)})dz</script><p>这个就是$\log p(x)$ 的下界，我们令其为 $L_b$。 因此，目标函数可以转化为 $L= \sum _x L_b$</p>
<p>下一步，我们知道了$L<em>b$的公式如下，我们就要去寻找$p(x|z)$和$q(z|x)$ ，求得$L_b$的极大似然估计，使得$\sum</em>{x}L_b$最大化</p>
<script type="math/tex; mode=display">
L_b = \int q(z|x) \log(\frac{p(x|z)p(z)}{q(z|x)})dz\\</script><script type="math/tex; mode=display">
\begin{align}
L_b& = \int q(z|x)\log p(x|z) dz + \int q(z|x) \log (\frac{p(z)}{q(z|x)})dz\\
&=\int q(z|x)\log(x|z)dz-\int q(z|x)\log(\frac{q(z|x)}{p(z)})dz\\
& = \text{E}_{q(z|x)}\log p(x|z)-D_{KL}(q(z|x)||p(z))
\end{align}</script><p>我们的目标是最大化前半部分$\text{E}_{q(z|x)}\log p(x|z)$ 重构图像概率，以及最小化后半部分后延概率分布$q(z|x)$和高斯分布$p(z)$之间的差异</p>
<h5 id="VAE-的训练"><a href="#VAE-的训练" class="headerlink" title="VAE 的训练"></a>VAE 的训练</h5><p><img src="/2021/12/16/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/19.png" style="zoom:100%;"></p>
<ul>
<li>最小化 $D<em>{KL}(q</em>\phi(z|x)|| p(z))$ , 即 $\max L<em>{q</em>\phi} = \sum_j 1+\log(\sigma_j^2)-\mu_j^2-\sigma_j^2$</li>
<li>最大化$E<em>{q</em>\phi}\log p<em>\theta(x|z)$ , 即 $\max L</em>{p<em>\theta} = \sum_l\log p</em>\theta(x|z_l)$ </li>
</ul>
<p>我们的目标方程也变成了：$L = \sum_iL_i$, 其中：</p>
<ul>
<li>$L<em>i = \frac{1}{2}L</em>{q<em>\phi}^i+\frac{1}{L}L</em>{p_\theta}^i$</li>
</ul>
<p>我们可以用随机梯度上升的方式来最大化$L$</p>
<h5 id="VAE-图像生成"><a href="#VAE-图像生成" class="headerlink" title="VAE 图像生成"></a>VAE 图像生成</h5><p>训练完毕后，我们已经得到了$q(z|x)$ ，因此可以扔掉 encoder，只保留decoder.</p>
<p>因为我们加了noise，所以对于连续空间里面的每一个随机向量z，都保留了一定的特征，因此都可以生成一张随机的图片。</p>
<p>Input 为：随机向量$z\sim N(0,I)$</p>
<p>Output为：一张随机图像</p>
<p>VAE效果如下</p>
<p><img src="/2021/12/16/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/20.png" style="zoom:100%;"></p>
<h4 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h4><p>VAE 的优点：</p>
<ul>
<li>显示计算图像生成概率，生成图像直接和原始图像进行比较，易于优化，训练稳定</li>
<li>相对于Pixel RNN 训练较快</li>
</ul>
<p>缺点：</p>
<ul>
<li>计算的是极大似然的下界</li>
<li>使用MSE计算原图和生成图像的差异，不能保证复原真实图片，导致生成图像比较模糊 </li>
</ul>
<p>这是因为，VAE只是通过采样正态分布来尝试记住真实图片的样子，将特征重新组合，并不是真正意义上生成新的图片</p>
<p><img src="/2021/12/16/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/21.png" style="zoom:100%;"></p>
<h2 id="隐式的概率密度"><a href="#隐式的概率密度" class="headerlink" title="隐式的概率密度"></a>隐式的概率密度</h2><p>当我们定义了显示的密度函数的话，就永远是根据已经存在的图片去生成新的图片。因此，还有一种方法是不定义显示的概率密度函数了，这样生成器就相当于从未见过真实的图片，只是根据Discriminator(鉴频器) 的反馈去不断逼近真实的图片，所以GAN也被认为是真正意义上的生成模型。</p>
<p>其原理如下所示：</p>
<p>Generator 直接从任何一个先验概率分布中生成图片，然后用一个<em>专家</em> 去判断这个图像是否是真的。直到专家无法分辨图像的真假的时候，就相当于生成了一张新的图片</p>
<p><img src="/2021/12/16/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/22.png" style="zoom:100%;"></p>
<h3 id="GAN"><a href="#GAN" class="headerlink" title="GAN"></a>GAN</h3><h4 id="非正式解释"><a href="#非正式解释" class="headerlink" title="非正式解释"></a>非正式解释</h4><p>用非正式的语言来解释一下Gan的原理：</p>
<p>我们把每一张图片当一个点去看。黑色的点代表训练数据点的分布，而绿色代表GAN模型生成图片的分布。蓝色的县代表生成数据点为真的概率</p>
<p><img src="/2021/12/16/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/23.png" style="zoom:100%;"></p>
<p>因此，我们可以看到，在一开始，数据点为真的概率是不断波动的，前半部分为1，后半部分为0(图2)。我们可以根据这个标准，让绿色的线不断逼近黑色的线，最后让它们重合。此时，蓝色的线停留在0.5处，也就是说，我不能鉴别这个绿色的点是真的还是假的图片。</p>
<h4 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h4><p><img src="/2021/12/16/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/25.png" style="zoom:100%;"></p>
<p>首先，给定一个假的随机向量，交给Generator生成图片，然后将生成图片和真图片共同交给 Discriminator去判断，给出真假判断。最后的训练目标就是，这个Discriminator没有办法区别生成的图片是真的还是假的。</p>
<h4 id="目标函数"><a href="#目标函数" class="headerlink" title="目标函数"></a>目标函数</h4><p>目标函数由两部分,如下：</p>
<p><img src="/2021/12/16/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/26.png" style="zoom:100%;"></p>
<p>第一部分是$\max_D$,即对Discriminator的训练，让其可以尽可能区分真假图片的这个目标。因此他希望对于真的图片，对其的判断要尽量接近于1；而对于生成的图片，要尽量判断出他是假的。因此优化目标是$D(G(z))$尽量接近0</p>
<p><img src="/2021/12/16/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/27.png" style="zoom:100%;"></p>
<p>第二部分是$\min_G$ ，也就是对Generator的训练，让他生成的图片尽可能的逼近真图片，也就是让$D(G(z))$ 尽量接近1</p>
<p><img src="/2021/12/16/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/28.png" style="zoom:100%;"></p>
<p>因此这就是为什么叫做生成对抗网络(GAN)了，因为两者的优化目的是相反的，一个是让 $D(G(z))$尽量接近0；另一个是让$D(G(z))$尽量接近1</p>
<h4 id="GAN-训练方法"><a href="#GAN-训练方法" class="headerlink" title="GAN 训练方法"></a>GAN 训练方法</h4><p>对于GAN，我们要训练n次。在每一次训练中，需要：</p>
<ul>
<li><p>迭代k次 Discriminator：</p>
<ul>
<li>抽取 n 个随机向量${z^{(1)},\cdots,z^{(m)}}\in p(z)$  组成 minibatch</li>
<li>抽取 n 个图像${x^{(1)},\cdots,x^{(m)}}$ 组成minibatch</li>
<li>使用SGA梯度上升算法更新Discriminator的参数：</li>
</ul>
<script type="math/tex; mode=display">
\nabla_{\theta_d}\frac{1}{m} \sum_{i=1}^m[\log D_{\theta_d}(x^{(i)})+\log(1- D_{\theta_d}\Big(G_{\theta_g}\Big(z^{(i)}\Big) )\Big)]</script></li>
<li><p>迭代一次 Generator：</p>
<ul>
<li><p>抽取 n 个随机向量${z^{(1)},z^{(2)},\cdots,z^{(m)} }\in p(z)$ 组成 minibatch</p>
</li>
<li><p>使用SGA 更新Generator的参数：</p>
<script type="math/tex; mode=display">
\nabla_{\theta_g} \frac{1}{m}\sum_{i=1}^m\log(D_{\theta_d}\Big(G_{\theta_g}\Big(z^{(i)}) \Big)\Big)</script></li>
</ul>
</li>
</ul>
<p>我们看到利用GAN生成的图片，每一张都是不一样的，而VAE和原图会比较相似</p>
<p><img src="/2021/12/16/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/24.png" style="zoom:100%;"></p>
<h4 id="总结-2"><a href="#总结-2" class="headerlink" title="总结"></a>总结</h4><p>GAN的优点：</p>
<ul>
<li>GAN可以完美模拟真是数据分布(只要有足够多的图片)</li>
<li>Generator 根据 Discriminator 的反馈进行更新(不是尝试去记忆真实的图片)</li>
<li>生成图片的质量高</li>
</ul>
<p>GAN的缺点</p>
<ul>
<li>没有显示的概率密度函数，生成图像的可解释性比较差</li>
<li>训练具有不稳定性，即Generator 和 Discriminator 较难同步</li>
<li>需要足够的图片和足够的算力，不然可能需要算很久</li>
</ul>

          
        
      
    </div>
    
    
    
    <div>
      
    </div>
    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://jasonxqh.github.io/2021/12/16/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jason">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/%5Bobject%20Object%5D">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jason‘s Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/12/16/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" itemprop="url">循环神经网络</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2021-12-16T18:52:13+08:00">
                2021-12-16
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified&#58;</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2021-12-30T10:23:02+08:00">
                2021-12-30
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="循环神经网络"><a href="#循环神经网络" class="headerlink" title="循环神经网络"></a>循环神经网络</h1><p>循环神经网络和卷积神经网络处理的数据类型是不一样的。卷积神经网络可是用来处理矩阵类型的数据，而生活中有很多数据是序列型的，且没有固定的长度、大小。因此CNN并不是非常适合用来处理这些数据。</p>
<p>因此我们提出了 RNN (Recurrent Neural Networks)，其想法就是，采用重复的结构单元，每次输入序列里的一个数据，后面的结构单元能够记忆前面的输入信息。</p>
<h2 id="RNN的结构"><a href="#RNN的结构" class="headerlink" title="RNN的结构"></a>RNN的结构</h2><h4 id="一对一"><a href="#一对一" class="headerlink" title="一对一"></a>一对一</h4><p>现在我们来看看一个简单的循环神经网络，它由输入层、隐藏层和输出层组成</p>
<p><img src="/2021/12/16/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/1.jpeg" style="zoom: 67%;"></p>
<p>我们现在这样来理解，如果把上面有W的那个带箭头的圈去掉，它就变成了最普通的<strong>全连接神经网络</strong>。x是一个向量，它表示<strong>输入层</strong>的值（这里面没有画出来表示神经元节点的圆圈）；s是一个向量，它表示<strong>隐藏层</strong>的值（这里隐藏层面画了一个节点，你也可以想象这一层其实是多个节点，节点数与向量s的维度相同）；</p>
<p>U是输入层到隐藏层的<strong>权重矩阵</strong>，o也是一个向量，它表示<strong>输出层</strong>的值；V是隐藏层到输出层的<strong>权重矩阵</strong>。</p>
<p>那么，现在我们来看看W是什么。<strong>循环神经网络</strong>的<strong>隐藏层</strong>的值s不仅仅取决于当前这次的输入x，还取决于上一次<strong>隐藏层</strong>的值s。<strong>权重矩阵</strong> W就是<strong>隐藏层</strong>上一次的值作为这一次的输入的权重。</p>
<p>如果我们把上面的图展开，<strong>循环神经网络</strong>也可以画成下面这个样子：</p>
<p><img src="/2021/12/16/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2.jpeg" style="zoom: 67%;"></p>
<p>现在看上去就比较清楚了，这个网络在t时刻接收到输入 $x<em>t$ 之后，隐藏层的值是 $s_t $，输出值是$o_t$。关键一点是，$s_t $的值不仅仅取决于$x_t$，还取决于$s</em>{t-1}$。我们可以用下面的公式来表示<strong>循环神经网络</strong>的计算方法：</p>
<script type="math/tex; mode=display">
O_t = g(\boldsymbol V\cdot S_t)\\
S_t = f(\boldsymbol U\cdot X_t+ \boldsymbol W\cdot S_{t-1})</script><p>如果我们把式2反复带入式1，可得到:</p>
<script type="math/tex; mode=display">
\begin{align}
O_t &= g(V\cdot S_t)\\
&=Vf(U\cdot x_t+W\cdot S_{t-1})\\
&=Vf(U\cdot x_t+Wf(Ux_{t-1}+W\cdot S_{t-2}))\\
&=Vf(U\cdot x_t+Wf(Ux_{t-1}+W(f(Ux_{t-3}+\cdots))))
\end{align}</script><p>其中，最简单的$f(x)$是线性变换加激活，比如说 $f(x) = \tanh(U\cdot X<em>t+W\cdot S</em>{t-1})$ </p>
<p>因此我们说，隐藏层包含了过去的历史信息，用来预测下一时刻的目标</p>
<h4 id="多对多"><a href="#多对多" class="headerlink" title="多对多"></a>多对多</h4><p>在进行文本改写等情况下，可能会用到</p>
<p><img src="/2021/12/16/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/5.png" style="zoom: 67%;"></p>
<h4 id="多对一"><a href="#多对一" class="headerlink" title="多对一"></a>多对一</h4><p>比如说，在情感分类的时候，输入可能是一个句子，输出代表这个情感的类型或者情感的等级。那么这就是多对一的情况</p>
<p>又比如说，在输入一连串文本的时候，通过神经网络生成一张图像的场景</p>
<p><img src="/2021/12/16/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/3.png" style="zoom: 67%;"></p>
<h4 id="一对多"><a href="#一对多" class="headerlink" title="一对多"></a>一对多</h4><p>在看图说话这个应用场景中，输入一张图片，可能会有多个单词的输出。</p>
<p><img src="/2021/12/16/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/4.png" style="zoom: 67%;"></p>
<h4 id="特殊多对多"><a href="#特殊多对多" class="headerlink" title="特殊多对多"></a>特殊多对多</h4><p><img src="/2021/12/16/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/6.png" style="zoom: 67%;"></p>
<p>还有一种特殊的多对多循环神经网络，常常用来做机器翻译。比如输入的是红色框框代表的英语，经过循环神经网络处理，输出一个向量$h_T$,里面包含了这句话中所有的语义信息。然后，$h_T$ 作为下面一个循环神经网络序列的输入，解码器将这个向量输出成一个德语序列</p>
<p>这样设计的原因是，因为不同语言之间的语法结构是不同的，因此如果采用一边输入、一边输出的方式，会造成翻译不准确、语义丢失等情况</p>
<h4 id="多层RNN"><a href="#多层RNN" class="headerlink" title="多层RNN"></a>多层RNN</h4><p>上面说的RNN例子，都属于一层神经网络，只是在不断堆叠时间步。那么，要训练深层神经网络的话，仅靠一层RNN是不够的，因此提出了多层RNN结构</p>
<p><img src="/2021/12/16/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/13.png" style="zoom: 67%;"></p>
<p>从第二层开始，隐藏层的生成是通过本层上一时刻的权重矩阵和上层本时刻的权重矩阵共同生成的。即：</p>
<script type="math/tex; mode=display">
S_t^l = \tanh W^l
\begin{pmatrix} s_{t}^{l-1} \\ s_{t-1}^l \end{pmatrix}\\
\text{l代表层数,t代表时刻}</script><h3 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h3><h4 id="BPTT"><a href="#BPTT" class="headerlink" title="BPTT"></a>BPTT</h4><p>学习博客：<a href="https://blog.csdn.net/lzw66666/article/details/113132149?utm_source=app&amp;app_version=4.20.0" target="_blank" rel="noopener">https://blog.csdn.net/lzw66666/article/details/113132149?utm_source=app&amp;app_version=4.20.0</a></p>
<p>BPTT（back-propagation through time）算法是常用的训练RNN的方法，其实本质还是BP算法，只不过RNN处理时间序列数据，所以要基于时间反向传播，故叫随时间反向传播。BPTT的中心思想和BP算法相同，沿着需要优化的参数的负梯度方向不断寻找更优的点直至收敛。综上所述，BPTT算法本质还是BP算法，BP算法本质还是梯度下降法，那么求各个参数的梯度便成了此算法的核心。</p>
<p>首先，我们还是要看这张图：</p>
<p><img src="/2021/12/16/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2.jpeg" style="zoom: 67%;"></p>
<p>一共有三个权重矩阵： $\boldsymbol {U,V,W}$ 需要在反向传播中更新</p>
<script type="math/tex; mode=display">
O_t = g(\boldsymbol V\cdot S_t)\\
S_t = f(\boldsymbol U\cdot X_t+ \boldsymbol W\cdot S_{t-1})</script><p>反向传播的计算说到底分三部分：1. 定义损失函数 2. 求出损失函数对参数的偏导数 3. 更新参数</p>
<h5 id="定义损失函数"><a href="#定义损失函数" class="headerlink" title="定义损失函数"></a>定义损失函数</h5><p>假设在时刻 $t$ 的损失函数为：</p>
<script type="math/tex; mode=display">
L_t = \frac{1}{2}(Y_t - O_t)^2</script><p>损失函数可以用均方误差、Softmax，这里用的是前者</p>
<p>因为有多个时刻，所以总损失函数为所有时刻的损失函数之和：$L = \sum_{t=0}^T{L_t}$</p>
<h5 id="求损失函数对参数的偏导"><a href="#求损失函数对参数的偏导" class="headerlink" title="求损失函数对参数的偏导"></a>求损失函数对参数的偏导</h5><ol>
<li>我们来看最主要的权重(参数)矩阵：$\boldsymbol W$, 在RNN中的每一时刻都出现了，因此 $\boldsymbol W$ 在时刻t的梯度 等于<strong>时刻t的损失函数</strong>对所有时刻的 $\boldsymbol W$ 的<strong>梯度和</strong></li>
</ol>
<script type="math/tex; mode=display">
\frac{\partial L_t}{\partial \boldsymbol W} = \sum_{s=0}^T \frac{\partial L_t}{\partial \boldsymbol W_s}</script><ol>
<li><p>将 $\frac{\partial L_t}{\partial \boldsymbol W}$ 带入损失函数，可得$\boldsymbol W$ 的总梯度 $\frac{\partial L}{\partial \boldsymbol W}$ 等于$\boldsymbol W$ 在所有时刻的梯度和</p>
<script type="math/tex; mode=display">
\frac{\partial L}{\partial \boldsymbol W} = \sum_{t=0}^T\frac{\partial L_t}{\partial w} \\
=\sum_{t=0}^T\sum_{s=0}^T\frac{\partial L_t}{\partial w_s}</script></li>
<li><p>有了梯度，我们就可以用来更新参数了</p>
</li>
</ol>
<script type="math/tex; mode=display">
\boldsymbol W = \boldsymbol W-\alpha\frac{\partial L }{\partial \boldsymbol W}</script><p>以上三步就是针对参数$\boldsymbol W$ 的反向传播</p>
<h4 id="truncated-BPTT"><a href="#truncated-BPTT" class="headerlink" title="truncated BPTT"></a>truncated BPTT</h4><p>但是BPTT有个问题，当输入序列边长的时候，BPTT非常容易出现梯度爆炸和梯度消失的问题。因此，为了缓解这个问题，有人突出了 TBPTT，也就是前向传播 $k_1$ 步，然后反向传播$k_2$步，通过这个方式使得传播序列变短。通常$k_1=k_2 &lt; n$ </p>
<p><img src="/2021/12/16/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/31.png" style="zoom: 67%;"></p>
<h2 id="RNN的应用"><a href="#RNN的应用" class="headerlink" title="RNN的应用"></a>RNN的应用</h2><h3 id="训练语言模型"><a href="#训练语言模型" class="headerlink" title="训练语言模型"></a>训练语言模型</h3><p>RNN的一大应用就是来构建语言模型. 它捕捉了一些人类语言的语法结构和语义信息，能够进行生成文字、自动回复等功能。现在我们用最简单的例子(character-level )来看一下模型是怎么被训练的.</p>
<p>我们用的语料库就是一个单词： hello； 词汇表为 [h,e,l,o]；</p>
<p>我们用 独热编码来编写词汇，输入到循环神经网络中，通过权重计算、激活，得到隐藏层如下：</p>
<p><img src="/2021/12/16/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/7.png"></p>
<p>现在，隐藏层需要输出一个值，这个值就代表当前时刻输入值的下一个预测值。输出值和输入值的维度需要保持一致。在这个例子中，输出一个长度为4的向量，每个值代表词汇表中对应词出现的概率。</p>
<p>推理过程如下图所示：</p>
<p><img src="/2021/12/16/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/8.png" style="zoom:120%;"></p>
<p>如果我们使用莎士比亚的著作当做语料库，基于character-level 训练，那么只要给神经网络输入一个字母，他就会自己写一部莎士比亚风格的著作了</p>
<h3 id="其他例子"><a href="#其他例子" class="headerlink" title="其他例子"></a>其他例子</h3><ul>
<li>此外，RNN还可以用来写诗，比如说：</li>
</ul>
<p><img src="/2021/12/16/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/9.png" style="zoom:120%;"></p>
<ul>
<li>用来写代码，用整个 linux 内核来训练，虽然肯定有语法错误。更多的是像 tabline 一样给出代码提示，或者是代码的克隆检测、代码分类等。</li>
</ul>
<p><img src="/2021/12/16/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/10.png" style="zoom:100%;"></p>
<ul>
<li>使用多对多神经网络，也常常被IDE用来进行代码纠错：</li>
</ul>
<p><img src="/2021/12/16/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/11.png" style="zoom: 67%;"></p>
<p>前面讲的都是自然与语言处理相关的内容，其实RNN在cv里面的应用也十分广泛。比如说看图说话：</p>
<p><img src="/2021/12/16/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/12.png" style="zoom: 67%;"></p>
<p>其原理如下图所示，首先输入图像，由CNN处理后，提取特征，然后变成RNN的输入向量：</p>
<p><img src="/2021/12/16/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/14.png" style="zoom: 67%;"></p>
<p>但这个模型并不是百分百正确的，会出现很多识别错误的例子。</p>
<p>因此，我们可以引入注意力机制，提高RNN的识别率：</p>
<p>在没有引入注意力机制的时候，读入的是一个长度为D的特征 。那么现在，我们让CNN训练一张图片，得到一个 $L\times D$ 的矩阵(即feature map)，一共L行，每行代表图片里的L个区域，如下所示：</p>
<p><img src="/2021/12/16/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/15.png" style="zoom: 67%;"></p>
<ul>
<li><p>作为输入$h_0$，一般是一个向量，我们可以通过平均池化的方式获得。这样D列就会变成一个长度为D的向量，作为整个图片的特征向量</p>
</li>
<li><p>然后，通过 $L\times D$  和 $h_0$ (长度为D)相乘，可以得到一个长度为 $L$ 的向量。</p>
<ul>
<li>将$L$里面的元素进行一个softmax求出加权特征向量$Z_1$——里面的每一个元素就是对这一个区域的注意力分数。</li>
<li>将这个$Z_1$ 向量作为$h_1$ 的输入，为其指明观察的方向。</li>
</ul>
</li>
<li>在$h_1$ 输出了预测值straw以后，由 $h_1$和feature map相乘，softmax后得到$Z_2$。并将$Z_2$和$h_1$得到的输出值straw 共同输入到 $h_2$ 。 $h_2$ 预测值又将和$Z_3$ 共同输入给 $h_3$ 预测，以此类推</li>
</ul>
<p><img src="/2021/12/16/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/17.png" style="zoom: 67%;"></p>
<p>$a_i$ 代表  feature map 里面的第i行特征</p>
<p>$\alpha_{ti}$ 代表t时刻的这个注意力向量的第i个注意力分数</p>
<p>在没有引入注意力机制的时候，每次输入的特征是一样的；但是引入了注意力机制的话，相当于，每一个时间节点，都会要求RNN去观察图片中的一个重点的区域。如下图所示：</p>
<p><img src="/2021/12/16/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/16.png" style="zoom: 67%;"></p>
<p>此外，这里还提到了 soft attention 和 hard attention，前者是说，直接保留输出的注意力分数，而后者是确立一个阈值，将超过阈值的注意力分数置为1，否则设为0。</p>
<h2 id="RNN的缺点及解决办法"><a href="#RNN的缺点及解决办法" class="headerlink" title="RNN的缺点及解决办法"></a>RNN的缺点及解决办法</h2><p>RNN 是有一个非常明显的缺点的——训练长数据的时候容易出现梯度爆炸和梯度消失的问题。为了搞明白这个问题。在前面，我们已经学习了前向传播和BPTT，现在我们再来复习一下：</p>
<p>前向传播公式：</p>
<script type="math/tex; mode=display">
O_t = g(\boldsymbol V\cdot S_t)\\
S_t = f(\boldsymbol U\cdot X_t+ \boldsymbol W\cdot S_{t-1})</script><p>这里我们为了简化，就不添加偏置项了</p>
<p>我们用三次循环为例，示意图如下：</p>
<p><img src="/2021/12/16/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/30.jpeg"></p>
<p>现在来计算前向传播的 $s_1,s_2,s_3,o_1,o_2,o_3$</p>
<script type="math/tex; mode=display">
s_1 = f(\boldsymbol Ux_1+\boldsymbol W s_0)~~~~~o_1 = g(\boldsymbol Vs_1)\\
s_2 = f(\boldsymbol Ux_2+\boldsymbol W s_1)~~~~~o_2 = g(\boldsymbol Vs_2)\\
s_3 = f(\boldsymbol Ux_3+\boldsymbol W s_2)~~~~~o_2 = g(\boldsymbol Vs_3)\\</script><p>现在来计算 $t=3$ 时刻，损失函数$L_3$ 对 $\boldsymbol {U、V、W}$ 的偏导</p>
<script type="math/tex; mode=display">
\begin{align}
&\frac{\partial L_3}{\partial \boldsymbol V} = \frac{\partial L_3}{\partial S_3}\frac{\partial S_3}{\partial \boldsymbol V}\\
&\frac{\partial L_3}{\partial \boldsymbol U} = \frac{\partial L_3}{\partial O_3}\frac{\partial O_3}{\partial \boldsymbol U}+\frac{\partial L_3}{\partial O_3}\frac{\partial O_3}{\partial S_3}\frac{\partial S_3}{\partial S_2}\frac{\partial S_2}{\partial  \boldsymbol U}+\frac{\partial L_3}{\partial O_3}\frac{\partial O_3}{\partial S_3}\frac{\partial S_3}{\partial S_2}\frac{\partial S_2}{\partial S_1}\frac{\partial S_1}{ \boldsymbol U} \\
&\frac{\partial L_3}{\partial \boldsymbol W} = \frac{\partial L_3}{\partial O_3}\frac{\partial O_3}{\partial \boldsymbol W}+\frac{\partial L_3}{\partial O_3}\frac{\partial O_3}{\partial S_3}\frac{\partial S_3}{\partial S_2}\frac{\partial S_2}{\partial  \boldsymbol W}+\frac{\partial L_3}{\partial O_3}\frac{\partial O_3}{\partial S_3}\frac{\partial S_3}{\partial S_2}\frac{\partial S_2}{\partial S_1}\frac{\partial S_1}{ \boldsymbol W}
\end{align}</script><p>根据上述推导，我们可以得出在任意时刻 $t$, $L$ 对 $\boldsymbol {U,V,W}$ 的偏导公式，以$W$为例：</p>
<script type="math/tex; mode=display">
\frac{\partial L_t}{\partial W} = \sum_{k=0}^t \frac{\partial L_t}{\partial O_t}\frac{\partial O_t}{\partial S_t}(\prod_{j=k+1}^t\frac{\partial S_j}{\partial S_{j-1}})\frac{\partial S_j}{\partial \boldsymbol W}</script><p>我   $S<em>j = \tanh(\boldsymbol Ux_i+\boldsymbol WS</em>{j-1})$ ，那么 $\frac{\partial S<em>j}{\partial S</em>{j-1}} = \tanh’ \boldsymbol W$ ，而$\prod<em>{j=k+1}^t\frac{\partial S_j}{\partial S</em>{j-1}}=\boldsymbol W^t\cdot\prod_{j=k+1}^t \tanh’$ </p>
<p>从上式可知，在回传梯度的时候，我们需要连续不断地乘以 $\boldsymbol W$ </p>
<script type="math/tex; mode=display">
W= Q\Lambda Q^{-1}\rightarrow (W)^n = Q\Lambda^n Q^{-1}</script><p>因此，当特征值大于1的时候，只要循环次数过多，就会造成梯度爆炸</p>
<p>同理，当特征值小于1的时候，只要循环次数过多，会造成梯度消失</p>
<h3 id="梯度裁剪"><a href="#梯度裁剪" class="headerlink" title="梯度裁剪"></a>梯度裁剪</h3><p>为了解决这个问题，我们们可以用梯度裁剪的方法。当特征值&gt;1,造成梯度爆炸、或者梯度的L2范数过大的时候，我们需要对梯度进行缩小</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">grad_norm = np.sum(grad*grad)</span><br><span class="line"><span class="keyword">if</span> grad_norm &gt; threshold:</span><br><span class="line">	grad *= (threshold / grad_norm)</span><br></pre></td></tr></table></figure>
<h3 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h3><p>学习博客： <a href="https://www.jianshu.com/p/9dc9f41f0b29" target="_blank" rel="noopener">https://www.jianshu.com/p/9dc9f41f0b29</a></p>
<p>但是梯度裁剪对于梯度消失的情况效果并不好，因此我们需要使用更高级的结构，也就是长短期记忆(Long short-Term Memory, LSTM) </p>
<p>因为在RNN中主要是 $h_i$会出现梯度爆炸和梯度消失，在LSTM中就主要做了一项中间步骤，使得回传以后$h$不再是永远为$W^T$，从而避免了梯度爆炸、和消失的问题</p>
<h4 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a>核心思想</h4><p>所有 RNN 都具有一种重复神经网络模块的链式的形式。在标准的 RNN 中，这个重复的模块只有一个非常简单的结构，例如一个 <code>tanh</code> 层。 LSTM 同样是这样的结构，但是重复的模块拥有一个不同的结构。不同于 单一神经网络层，这里是有四个，以一种非常特殊的方式进行交互。</p>
<p>LSTM 的关键就是<strong>细胞状态 $C_t$</strong>，水平线在图上方贯穿运行。</p>
<p>细胞状态类似于传送带。直接在整个链上运行，只有一些少量的线性交互。信息在上面流传保持不变会很容易。</p>
<p><img src="/2021/12/16/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/24.jpg"></p>
<p>LSTM 有通过精心设计的称作为“门”的结构来去除或者增加信息到细胞状态的能力。门是一种让信息选择式通过的方法。他们包含一个 <code>sigmoid</code> 神经网络层和一个按位的乘法操作。</p>
<p><img src="/2021/12/16/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/25.jpg"></p>
<p>Sigmoid 层输出0到1之间的数值，描述每个部分有多少量可以通过。 0代表“不许任何量通过”，1 就指“允许任意量通过”</p>
<p>LSTM 拥有三个门，来保护和控制细胞状态。</p>
<h4 id="逐步理解-LSTM"><a href="#逐步理解-LSTM" class="headerlink" title="逐步理解 LSTM"></a>逐步理解 LSTM</h4><p>LSTM一开始需要计算4个向量：</p>
<ul>
<li>i : input gate , 控制在 $c_t$ 中写入哪些信息</li>
<li>f : forget gate , 控制从$c_{t-1}$  中擦除哪些信息</li>
<li>o : output gate ，控制从$c_t$输出哪些信息</li>
<li>g：激活输入</li>
</ul>
<p><img src="/2021/12/16/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/21.png"></p>
<h5 id="决定丢弃信息"><a href="#决定丢弃信息" class="headerlink" title="决定丢弃信息"></a>决定丢弃信息</h5><p>在LSTM中的第一步是决定我们会从细胞状态中丢弃什么信息。这个决定通过上面所说的 forget gate 完成。该门会读取$h<em>{t-1}$ 和$x_t$ ，并输出一个在0到1之间的数值给每个在细胞状态$C</em>{t-1}$中的数字。1表示完全保留而0代表完全舍弃。</p>
<p>计算公式如下：</p>
<script type="math/tex; mode=display">
f_t = \sigma(W_f\cdot[h_{t-1},x_t]+b_f)</script><p><img src="/2021/12/16/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/26.png" style="zoom: 67%;"></p>
<h5 id="确定更新信息"><a href="#确定更新信息" class="headerlink" title="确定更新信息"></a>确定更新信息</h5><p>下一步，是确定什么样的新信息会被存放在细胞状态中。这里包含两个部分。第一，一个<code>sigmoid</code> 层(即input gate) 决定我们将要更新什么值。然后一个 <code>tanh</code>层(gate)创建一个新的候选值向量 $\widetilde C_t$. 这个向量将会被加入到细胞状态中。</p>
<p> 计算公式如下：</p>
<script type="math/tex; mode=display">
i_t = \sigma(W_i\cdot[h_{t-1},x_t]+b_i)\\
\widetilde C_t = \tanh (W_C\cdot[h_{t-1},x_t]+b_C)\\</script><p><img src="/2021/12/16/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/27.png" style="zoom: 67%;"></p>
<h5 id="更新细胞状态"><a href="#更新细胞状态" class="headerlink" title="更新细胞状态"></a>更新细胞状态</h5><p>现在是更新旧细胞状态的时间了，$C_{t-1}$ 更新为 $C_t$ 。</p>
<p>我们把旧状态 与 $f_t$ 相乘，来丢弃掉我们确定需要丢弃的信息。接着加上 $i_t*\widetilde C_t$,即新的候选值。</p>
<p>公式如下：</p>
<script type="math/tex; mode=display">
c_t = f_t\odot C_{t-1}+i_t\odot \widetilde C_t</script><p><img src="/2021/12/16/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/28.png" style="zoom: 67%;"></p>
<h5 id="输出信息"><a href="#输出信息" class="headerlink" title="输出信息"></a>输出信息</h5><p>最终，我们需要确定输出什么值。这个输出将会基于我们的细胞状态。</p>
<ul>
<li>首先，我们运行一个 <code>sigmoid</code> 来确定细胞状态的哪个部分将输出出去。得到输出门 output gate</li>
<li>接着，我们把细胞状态通过 <code>tanh</code>进行处理，得到一个 -1~1 之间的值，并将它和<code>sigmoid</code>的输出相乘。最终我们仅仅会输出我们确定输出的那部分。</li>
</ul>
<script type="math/tex; mode=display">
o_t = \sigma(W_o[h_{t-1},x_t]+b_o)\\
h_t = o_t * \tanh(C_t)</script><p><img src="/2021/12/16/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/29.png" style="zoom: 67%;"></p>
<h4 id="梯度回传"><a href="#梯度回传" class="headerlink" title="梯度回传"></a>梯度回传</h4><p> <strong>LSTM 中梯度的传播有很多条路径</strong>，$c<em>{t-1}\rightarrow c_t = f_t\odot c</em>{t-1}+i_t\odot \hat c_t$ 这条路径上只有<strong>逐元素相乘和相加</strong>的操作，梯度流最稳定；</p>
<p>但是在<strong>其他路径</strong>上，LSTM 的梯度流和普通 RNN 没有太大区别，照样会发生相同的权重矩阵反复连乘的情况，依然会爆炸或者消失。由于<strong>总的远距离梯度 = 各条路径的远距离梯度之和</strong>，即便其他远距离路径梯度消失了，只要保证有一条远距离路径（就是上面说的那条高速公路）梯度不消失，总的远距离梯度就不会消失（正常梯度 + 消失梯度= 正常梯度）。因此 LSTM 通过改善<strong>一条路径</strong>上的梯度问题拯救了<strong>总体的远距离梯度</strong> </p>
<p>同样，因为总的远距离梯度 = 各条路径的远距离梯度之和，高速公路上梯度流比较稳定，但其他路径上梯度有可能爆炸，此时总的远距离梯度 = 正常梯度 + 爆炸梯度 = 爆炸梯度，因此 <strong>LSTM 仍然有可能发生梯度爆炸</strong>。不过，由于 LSTM 的其他路径非常崎岖，和普通 RNN 相比多经过了很多次激活函数（导数都小于 1），因此 <strong>LSTM 发生梯度爆炸的频率要低得多</strong>。实践中仍然可以通过梯度裁剪来解决。</p>
<p><img src="/2021/12/16/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/22.png"></p>
<h3 id="GRU"><a href="#GRU" class="headerlink" title="GRU"></a>GRU</h3><p>GRU是对 LSTM的进一步简化</p>
<p><img src="/2021/12/16/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/23.png"></p>

          
        
      
    </div>
    
    
    
    <div>
      
    </div>
    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://jasonxqh.github.io/2021/12/16/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jason">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/%5Bobject%20Object%5D">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jason‘s Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/12/16/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" itemprop="url">计算机视觉-卷积神经网络</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2021-12-16T18:39:45+08:00">
                2021-12-16
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified&#58;</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2022-06-25T22:51:20+08:00">
                2022-06-25
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="计算机视觉-卷积神经网络"><a href="#计算机视觉-卷积神经网络" class="headerlink" title="计算机视觉-卷积神经网络"></a>计算机视觉-卷积神经网络</h1><p>在<a href="https://jasonxqh.github.io/2020/11/24/卷积神经网路理论/">卷积神经网路理论</a>中，我们简单介绍了一下卷积神经网络的原理，现在我们来系统学习神经网络的相关知识。</p>
<h2 id="正向传播"><a href="#正向传播" class="headerlink" title="正向传播"></a>正向传播</h2><p>在 <a href="https://jasonxqh.github.io/2021/12/02/神经网络和反向传播/">神经网络和反向传播</a> 中，我们学习了全连接层，那么，全连接层有什么缺陷呢？</p>
<p>第一层假设是 $x\in \mathbb R^{100\times100\times 3}$ ，第二层假设有4096个神经元，那么这全连接一下，就需要第一层有$30000 \times 4096\approx 1.2\text{亿}$ 个参数，这是不能承受之重啊——因此我们需要用到新的方法。</p>
<p>其实我们也提出了解决的方法：</p>
<ul>
<li><p>局部pattern：每个神经元捕获局部pattern，以减少权重参数。相当于每个神经元<strong>各司其职</strong></p>
<p><img src="/2021/12/16/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2.png" style="zoom:67%;"></p>
</li>
<li><p>相似pattern：功能相似的神经元可以共享权重参数，比如两个神经元都是处理鼻子特征的，那么可以使用一套参数</p>
<p><img src="/2021/12/16/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/1.png" style="zoom:67%;"></p>
</li>
<li><p>像素采样：可以通过压缩等方式，将像素下采样，以进一步减少参数数量</p>
</li>
</ul>
<p><img src="/2021/12/16/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/3.png" style="zoom:67%;"></p>
<h3 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h3><p>那么，把这三者结合起来，就是卷积神经网络的作用。首先，伸进网络最重要的就是理解卷积核(kernel/filter)的作用，卷积核就是一个权重矩阵(参数矩阵)，用来捕捉局部的特征，其深度和图像深度(信道数)是一样的。比如说 ,现在有一个 $32\times32\times3$ 的图像矩阵，卷积核一般很小，比如说$5\times 5$,那么其深度一定是3。</p>
<p>用这个卷积核和图像在$5\times 5\times3$的区域内做点积，这样就会得到一共75个值，然后<strong>将其求和</strong>，输出得到第一个神经元$a_1$ ，然后用ReLU函数激活——这整个过程就叫做一次卷积。这样一来，就避免了$32\times32\times3$的超大型权重矩阵，只需要一个小型权重矩阵即可。</p>
<p><img src="/2021/12/16/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/4.png" style="zoom:67%;"></p>
<p>此外，由于一张图片多次出现同一个特征，因此一个卷积核对图片做一次卷积是远远不够的，需要<strong>扫描</strong>整张图片。那么该隔远扫描一次呢？这个距离就叫做步长(stride)，一般这个长度不会超过3。横向扫描一遍，接着跳到下一行再扫描一遍。整张图扫描下来，像素就会<strong>缩水</strong>一点。</p>
<p>比如，对$32\times32\times3$的图片用$5\times 5\times3$的卷积核卷积一遍，就会得到一张$28\times28\times1$的图片：</p>
<p><img src="/2021/12/16/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/5.png" style="zoom:67%;"></p>
<p>但是，一张图片不仅仅只有这一个特征，因此我们需要多个卷积核共同作用，每一个卷积核捕获不同的特征(在训练神经网络的时候会自动学习到不同特征)最后得到k层activation map</p>
<p>因此我们要记住：卷积核的深度和输入图片的信道数有关，而activation maps的深度适合卷积核的个数有关的</p>
<p><img src="/2021/12/16/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/6.png" style="zoom:67%;"></p>
<h3 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h3><p>上面得到的activation maps其实就是一个卷积层，而对于这个卷积层，又会有其他卷积核对其进行卷积，最后达成对原始图片进行不断地降维的目标。</p>
<h4 id="FC层-vs-卷积层"><a href="#FC层-vs-卷积层" class="headerlink" title="FC层 vs 卷积层"></a>FC层 vs 卷积层</h4><p>现在我们来看看全连接层(仿射层/FC层)和卷积层的对比。为了方便，我们拿$5\times5\times1$的输入图像作为例子；全连接层拿9个神经元作为例子，卷积核以$3\times3\times1$为例</p>
<p>如果是全连接层，要得到一个神经元的输入值，需要每个位置的像素点和权重做乘积后求和，那么这一层就一共需要$5\times5\times9=225$个参数。但是对于卷积层来说，不是一行一行去做卷积的，而是一个区域一个区域去做卷积。因此对整张图扫描一遍后会得到$3\times3\times1$的卷积层，同样是九个神经元。但是，因为使用同一个卷积核，其参数是不会变的——9个，也就是卷积核的大小。要达到和仿射层一样的参数水平，我们需要用到25个卷积核，但一般来说并不需要那么多捕捉特征的卷积核。</p>
<p>因此通过权重共享和局部全连接两种方式，可以明显减少参数的数量。</p>
<p><img src="/2021/12/16/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/7.png" style="zoom:67%;"></p>
<p>那么，如果当stride取2的时候，对于上述例子，一共只需要输出4个神经元就可以了，为后续减少了更多负担(当然也不可避免的失去一些信息)</p>
<h4 id="Zero-Padding"><a href="#Zero-Padding" class="headerlink" title="Zero Padding"></a>Zero Padding</h4><p>细心的同学们可能发现，图像边缘的像素做的卷积次数要比图像中间像素做的要少很多。因此有可能导致边缘的pattern无法被卷积核有效捕捉。为了解决这个问题，我们可以用0对图像的边缘进行补充，使得整张图片都位于图像里面：</p>
<p><img src="/2021/12/16/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/8.png"></p>
<p>比如说，对于$N\times N$ 的图片，$F\times F$的卷积核，步长为1，padding为1，最终得到的activation map 的边长为：</p>
<script type="math/tex; mode=display">
(N+1\times2-F)/1+1</script><p>这是因为，padding会给图像的左右两边同时加上一列，因此我们要乘以2.</p>
<p>事实上，由于卷积核的大小不同，为了保持卷积后activation map的大小不变，一般我们会取不同的padding。</p>
<ul>
<li>当F=3, padding 大小可取1， $2\times1-3=-1$</li>
<li>当F=5, padding 大小可取2， $2\times2-5=-1$</li>
<li>当F=7, padding 大小可取3， $2\times3-7=-1$</li>
</ul>
<h4 id="Activation-Maps"><a href="#Activation-Maps" class="headerlink" title="Activation Maps"></a>Activation Maps</h4><p>现在我们来做一个小练习：考虑两层的卷积神经网络。输入层图像的大小为$32\times 32\times3$, 第一层一共有6个$7\times7 \times3$的卷积核，第二层是10个$5\times5\times6$的卷积核。第一层有大小为2的padding，两层的stride均为1。请给出每层的activation maps的大小、深度, 以及每一层参数的个数。</p>
<p>首先，我们计算第一个activation maps的边长：</p>
<script type="math/tex; mode=display">
(32+2\times2-7)/1+1=30</script><p>第一个activation maps的深度等于该层卷积核的个数，也就是6</p>
<p>因此，第一个activation map的大小为：$30\times30\times6$</p>
<p>参数个数为<strong>卷积核的个数</strong> 乘以 <strong>卷积核的大小加上偏置项(一般为1)</strong>，即 $6\times(7\times7\times3+1)=888$</p>
<p>然后计算第二层activation maps的边长：</p>
<script type="math/tex; mode=display">
(30-5)/1+1=26</script><p>第二层activation maps的深度等于该层卷积核的个数，也就是10</p>
<p>因此，第二个activation maps的大小为：$26\times26\times10$</p>
<p>参数个数为$10\times(5\times5\times 6+1)=1510$ </p>
<h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>现在我们对卷积层做一个小结，并总结出一套通用的计算公式</p>
<ul>
<li>设当前层的输入矩阵为： $W_1\times H_1\times D_1$</li>
<li>设置4个必要的超参数：<ul>
<li>filter的个数$K$, 大小(边长)为 $F$, 因此可以确定有 $K$ 个偏置项</li>
<li>stride的大小为$S$</li>
<li>Zero padding的数量为 $P$</li>
</ul>
</li>
</ul>
<p>那么由上述数据，我们可以计算得到下一层的 activation maps 的大小为:</p>
<ul>
<li>$W_2 = \frac{W_1-F+2P}{S}+1$</li>
<li>$H_2=\frac{H_1-F+2P}{S}+1$</li>
<li>$D_2=K$</li>
</ul>
<p>第 d 个activation map是第d个filter与输入层做卷积后的结果(每个卷积都加上第d个偏置量)</p>
<p>最后，我们给出常用的超参数设置：</p>
<ul>
<li>K=32,64,128,256 ……</li>
<li>F=3,S=1,P=1</li>
<li>F=5,S=1,P=1或2</li>
<li>F=5,S=2,P=满足整除的数</li>
<li>F=1,S=1,P=0 (这个就相当于全连接，但是参数都是一样的)</li>
</ul>
<h3 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h3><p>池化（Pooling）：也称为欠采样或下采样。主要用于<strong>特征降维</strong>，压缩数据和参数的数量，减小过拟合，同时提高模型的容错性。因为卷积过后 activation map可能还是具有较强的线性，使用池化可以有效降低这种线性</p>
<p>一般来说，每隔几个 Conv+ReLU 层后，会又一层 Pooling，以有效减小参数(像素采样)</p>
<p><img src="/2021/12/16/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/9.png"></p>
<p>那么池化层该怎么做呢？</p>
<p>Pooling就相当于一个<strong>没有参数的卷积核</strong>，它对activation map中的一部分区域做mean、sum或者max操作，得到新的map。比如说，Max Pooling就是取一个部分中的最大值：(实际意义就是保留最突出的特征)</p>
<p><img src="/2021/12/16/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/10.png"></p>
<h4 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h4><p>假设 Conv+ReLU层的输出为 $W_1\times H_1\times D_1$</p>
<ul>
<li><p>我们设置两个超参数</p>
<ul>
<li>filter的大小(边长)为 $F$ ，只需要一个没有参数的 filter</li>
<li>Stride 大小为 $S$ </li>
<li>一般不做padding</li>
</ul>
</li>
<li><p>一般，我们常用的设置为： </p>
<ul>
<li>$F=2,S=2$</li>
<li>$F=3,S=2$</li>
</ul>
</li>
<li><p>最后生成大小为 $W_2\times H_2\times D_2$的 feature maps</p>
<ul>
<li>$W_2 = \frac{W_1-F}{S}+1$</li>
<li>$H_2=\frac{H_1-F}{S}+1$</li>
<li>$D_2=D_1$</li>
</ul>
</li>
</ul>
<h3 id="FC层"><a href="#FC层" class="headerlink" title="FC层"></a>FC层</h3><p>当缩小到一定程度之后，我们对图像进行扁平化，将其压平成一列，并进行全连接，最后得到图像分类的结果</p>
<p><img src="/2021/12/16/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/11.png"></p>
<p>完整的CNN如下：</p>
<p><img src="/2021/12/16/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/12.png"></p>
<h2 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h2><p>反向传播我们倒过来看, 首先是池化层，然后是激活函数层(ReLU),最后看卷积层</p>
<h3 id="Max-Pooling"><a href="#Max-Pooling" class="headerlink" title="Max Pooling"></a>Max Pooling</h3><p>首先，最大池化的操作就是把一部分区域的最大值传给下一层。那么这就相当于<a href="https://jasonxqh.github.io/2021/12/02/神经网络和反向传播/#梯度流的常见模式">梯度流的常见模式</a>中的max gate。那么，在反向传播时，上游梯度就会回传到input最大的位置：</p>
<p><img src="/2021/12/16/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/13.png"></p>
<h3 id="ReLU"><a href="#ReLU" class="headerlink" title="ReLU"></a>ReLU</h3><p>ReLU的反向传播也很简单，如果输入层的像素大于0，那么就回传梯度，否则就回传0</p>
<p><img src="/2021/12/16/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/14.png"></p>
<h3 id="Conv"><a href="#Conv" class="headerlink" title="Conv"></a>Conv</h3><p>比较复杂的反向传播就是卷积层的反向传播，其实卷积层的反向传播也需要做一次卷积。</p>
<p>我们既要算权重的梯度，也要算输入的梯度</p>
<p>参考博客： <a href="https://www.cnblogs.com/pinard/p/6494810.html" target="_blank" rel="noopener">https://www.cnblogs.com/pinard/p/6494810.html</a></p>
<p>我们用一个例子来推导，然后再一般化得到公式：</p>
<p>假设我们 $l-1$ 层的输出值 $a^{l-1}$是一个$3\times 3$的矩阵，第$l$ 层的卷积核 $W^{l}$ 是一个$2\times2$的矩阵，步长为1，那么输出的矩阵边长大小为$(3-2)/1+1=2$ 。我们不考虑偏置项，则有：</p>
<script type="math/tex; mode=display">
a^{l-1}\times W^l = z^l</script><p>我们列出 $a,W,z$的矩阵表达式如下：</p>
<script type="math/tex; mode=display">
\begin{pmatrix} a_{11} & a_{12} & a_{13} \\ a_{21} & a_{22} & a_{23}\\a_{31}&a_{23}&a_{33} \end{pmatrix}*\begin{pmatrix}w_{11}&w_{12}\\w_{21}&w_{22} \end{pmatrix} = \begin{pmatrix}z_{11}&z_{12}\\z_{21}&z_{22} \end{pmatrix}</script><p>根据卷积的定义，我们很容易得出：</p>
<script type="math/tex; mode=display">
z_{11} = a_{11}w_{11}+a_{12}w_{12}+a_{21}w_{21}+a_{22}w_{22}\\
z_{12}= a_{12}w_{11}+a_{13}w_{12}+a_{22}w_{21}+a_{23}w_{22}\\
z_{21} = a_{21}w_{11}+a_{22}w_{12}+a_{31}w_{21}+a_{32}w_{22}\\
z_{22} = a_{22}w_{11}+a_{23}w_{12}+a_{32}w_{21}+a_{33}w_{22}</script><p>接着，我们模拟反向求导：</p>
<script type="math/tex; mode=display">
\nabla a^{l-1} = \frac{\partial J(\boldsymbol W,b)}{\partial a^{l-1}} = (\frac{\partial z^l}{\partial a^{l-1}})^T\frac{\partial J(\boldsymbol W,b)}{\partial z} = (\frac{\partial z^l}{\partial a^{l-1}})^T\delta^l</script><p>从上式可以看出，对于 $a^{l-1}$ 的梯度误差 $\nabla a^{l-1}$ ,等于第l层的梯度误差乘以 $\frac{\partial z^l}{\partial a^{l-1}}$ , 而 $\frac{\partial z^l}{\partial a^{l-1}}$ 对应上面的例子中相关联的 w 的值。假设我们的z矩阵对应的反向传播误差是 $\delta<em>{11},\delta</em>{12},\delta<em>{21},\delta</em>{22}$组成的$2\times 2$矩阵，则利用上面梯度的式子和4个等式，我们可以分别写出 $\nabla a^{l-1}$ 的9个标量梯度。</p>
<p>比如对于 $a<em>{11}$ 的梯度，由于在4个等始终，$a</em>{11}$只和$z_{11}$有关，从而我们有：</p>
<script type="math/tex; mode=display">
\nabla a_{11} = \delta_{11}w_{11}</script><p>以此类推，我们可以得到：</p>
<script type="math/tex; mode=display">
\begin{align}
&\nabla a_{12} = \delta_{11}w_{12}+\delta_{12}w_{11}\\
&\nabla a_{13} = \delta_{12}w_{12}\\
&\nabla a_{21} = \delta_{11}w_{21}+\delta_{21}w_{11} \\
&\nabla a_{22} = \delta_{11}w_{22}+\delta_{12}w_{21}+\delta_{21}w_{12}+\delta_{22}w_{11} \\
&\nabla a_{23} = \delta_{12}w_{22}+\delta_{22}w_{12}\\
&\nabla a_{31} = \delta_{21}w_{21}\\
&\nabla a_{32} = \delta_{21}w_{22}+\delta_{22}w_{21} \\
&\nabla a_{33} = \delta_{22}w_{22}\\
\end{align}</script><p>　这上面9个式子其实可以用一个矩阵卷积的形式表示，即：</p>
<script type="math/tex; mode=display">
\begin{pmatrix}0&0&0&0\\ 0&\delta_{11} & \delta_{12} & 0 \\ 0 & \delta_{21} & \delta_{22}&0\\0&0&0&0 \end{pmatrix}*\begin{pmatrix}w_{22}&w_{21}\\w_{12}&w_{11} \end{pmatrix} =\begin{pmatrix} \nabla a_{11} & \nabla a_{12} & \nabla a_{13} \\ \nabla a_{21} & \nabla a_{22} & \nabla a_{23}\\\nabla a_{31}&\nabla a_{23}&\nabla a_{33} \end{pmatrix}</script><p>为了符合梯度计算，我们在误差矩阵周围填充了一圈0，此时我们将<strong>卷积核翻转后</strong>和<strong>反向传播的梯度误差</strong>进行卷积，就得到了前一次的梯度误差。 </p>
<p>因此，我们可以将其一般化：</p>
<p>首先，在DNN中，我们知道$\delta^{l-1}$和 $\delta^{l}$(由后向前推)的递推关系为：</p>
<script type="math/tex; mode=display">
\delta^{l-1} = \frac{\partial J(\boldsymbol W,b)}{\partial z^{l-1}} = (\frac{\partial z^{l}}{\partial z^{l-1}})^T\frac{\partial J(\boldsymbol W,b)}{\partial z^{l-1}} = (\frac{\partial z^{l}}{\partial z^{l-1}})^T\delta^{l}</script><p>因此，要推得到 $\delta^{l-1}$ ，必须要先计算 $\frac{\partial z^l}{\partial z^{l-1}}$ </p>
<p>因为 $z^{l-1}$ 和$z^{l}$是前向传播得到的，其关系为：</p>
<script type="math/tex; mode=display">
z^l = a^{l-1}*\boldsymbol W^l +b^l = \sigma(z^{l-1})*\boldsymbol W^l+b^l</script><p>因此：</p>
<script type="math/tex; mode=display">
\frac{\partial z^l}{\partial z^{l-1}} = rot180(\boldsymbol W')\odot \sigma'(z^{l-1})</script><script type="math/tex; mode=display">
\delta^{l-1}=(\frac{\partial z^l}{\partial z^{l-1}})\delta^l =\delta^l*rot180(\boldsymbol W')\odot \sigma'(z^{l-1})</script><p>这里的式子其实和DNN的类似，区别在于对于含有卷积的式子求导时，卷积核被旋转了180度。即式子中的$rot180$，翻转180度的意思是上下翻转一次，接着左右翻转一次。在DNN中这里只是矩阵的转置。那么为什么呢？由于这里都是张量，直接推演参数太多了。我们以一个简单的例子说明为啥这里求导后卷积核要翻转。</p>
<h4 id="已知卷积层的-delta-l-，推导该层的W-b的梯度"><a href="#已知卷积层的-delta-l-，推导该层的W-b的梯度" class="headerlink" title="已知卷积层的$\delta^l$，推导该层的W,b的梯度"></a>已知卷积层的$\delta^l$，推导该层的W,b的梯度</h4><p>好了，我们现在已经可以递推出每一层的梯度误差$\delta^l$ 了，对于全连接层，可以按DNN的反向传播算法求该层W,b的梯度，而卷积层的W,b需要求出。</p>
<p>在第l层，某个卷积核矩阵 $\boldsymbol W$ 的导数可以表示如下：</p>
<script type="math/tex; mode=display">
\frac{\partial J(\boldsymbol W,b)}{\partial W_{pq}^l} = \sum_{i}\sum_j(\delta_{i,j}^la^{l-1}_{i+p-1,j+q-1})</script><p>假设输入的a是$4\times 4$矩阵，卷积核 $\boldsymbol W$是$3\times3$的矩阵，输出z是$2\times2$的矩阵，那么反向传播的z的梯度误差$\delta$ 也是$2\times 2$的矩阵。</p>
<p>那么根据上面的例子，我们有：</p>
<script type="math/tex; mode=display">
\frac{\partial J(\boldsymbol W,b)}{\partial \boldsymbol W_{11}^l} = a_{11}\delta_{11}+a_{12}\delta_{12}+a_{21}\delta_{21}+a_{22}\delta_{22}\\
\frac{\partial J(\boldsymbol W,b)}{\partial \boldsymbol W_{12}^l} = a_{12}\delta_{11}+a_{13}\delta_{12}+a_{22}\delta_{21}+a_{23}\delta_{22}\\

\frac{\partial J(\boldsymbol W,b)}{\partial \boldsymbol W_{13}^l} = a_{13}\delta_{11}+a_{14}\delta_{12}+a_{23}\delta_{21}+a_{24}\delta_{22}\\
(...)</script><p>最终一共得到9个式子，整理后可得：</p>
<script type="math/tex; mode=display">
\frac{\partial J(\boldsymbol W,b)}{\partial \boldsymbol W^l} =\begin{pmatrix}a_{11}&a_{12}&a_{13}&a_{14}\\ a_{21}&a_{22} & a_{23} & a_{24} \\ a_{31} & a_{32} & a_{33}&a_{34}\\a_{41}&a_{42}&a_{43}&a_{44} \end{pmatrix}*\begin{pmatrix}\delta_{11}&\delta_{12}\\\delta_{21}&\delta_{22} \end{pmatrix}</script><p>从而可以清楚的看到这次我们为什么没有反转的原因。</p>
<p>而对于b,则稍微有些特殊，因为$\delta^l$是高维张量，而$b$只是一个向量，不能像DNN那样直接和$\delta^l$相等。通常的做法是将$\delta^l$的各个子矩阵的项分别求和，得到一个误差向量，即为$b$的梯度</p>
<script type="math/tex; mode=display">
\frac{\partial J(\boldsymbol W,b)}{\partial b^l} =\sum_{u,v}(\delta^l)_{u,v}</script><h4 id="总结CNN"><a href="#总结CNN" class="headerlink" title="总结CNN"></a>总结CNN</h4><p>现在我们总结下CNN的反向传播算法，以最基本的批量梯度下降法为例来描述反向传播算法。</p>
<p>输入：m个图片样本，CNN模型的层数L和所有隐藏层的类型，对于卷积层，要定义卷积核的大小K，卷积核子矩阵的维度F，填充大小P，步幅S。对于池化层，要定义池化区域大小k和池化标准（MAX或Average），对于全连接层，要定义全连接层的激活函数（输出层除外）和各层的神经元个数。梯度迭代参数迭代步长$\alpha$,最大迭代次数MAX与停止迭代阈值$\epsilon$</p>
<p>输出：CNN模型各隐藏层与输出层的𝑊,𝑏</p>
<p><img src="/2021/12/16/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/15.png"></p>

          
        
      
    </div>
    
    
    
    <div>
      
    </div>
    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/6/">&lt;i class&#x3D;&quot;fa fa-angle-left&quot;&gt;&lt;&#x2F;i&gt;</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><span class="page-number current">7</span><a class="page-number" href="/page/8/">8</a><span class="space">&hellip;</span><a class="page-number" href="/page/44/">44</a><a class="extend next" rel="next" href="/page/8/">&lt;i class&#x3D;&quot;fa fa-angle-right&quot;&gt;&lt;&#x2F;i&gt;</a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/%5Bobject%20Object%5D"
                alt="Jason" />
            
              <p class="site-author-name" itemprop="name">Jason</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/%20%7C%7C%20fa%20fa-archive">
              
                  <span class="site-state-item-count">435</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">11</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">61</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart" aria-hidden="true"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Jason</span>
 <!--
  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>







-->
        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>




















  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v="></script>

  <script type="text/javascript" src="/js/src/motion.js?v="></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v="></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
